from dagster import op, job
import pandas as pd
import numpy as np
import os
from dotenv import load_dotenv
from sqlalchemy import create_engine, MetaData, Table, inspect, text
from sqlalchemy.dialects.postgresql import insert as pg_insert

# ‚úÖ Load environment variables
load_dotenv()

# ‚úÖ DB source: MariaDB
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance"
)

# ‚úÖ DB target: PostgreSQL
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance"
)

@op
def extract_card_agent_data() -> pd.DataFrame:
    query = """
        SELECT 
            ic_ins.cuscode AS agent_id,
            ic_ins.title,
            CONCAT(ic_ins.name, ' ', ic_ins.lastname) AS agent_name,

            ic_ins.card_no AS id_card_ins,
            ic_ins.type AS type_ins,
            ic_ins.revoke_type_code AS revoke_type_ins,
            ic_ins.company AS company_ins,
            CASE 
                WHEN ic_ins.create_date IS NULL OR ic_ins.create_date = '0000-00-00' THEN NULL
                ELSE ic_ins.create_date
            END AS card_issued_date_ins,
            CASE 
                WHEN ic_ins.expire_date IS NULL OR ic_ins.expire_date = '0000-00-00' THEN NULL
                ELSE ic_ins.expire_date
            END AS card_expiry_date_ins,

            ic_life.card_no AS id_card_life,
            ic_life.type AS type_life,
            ic_life.revoke_type_code AS revoke_type_life,
            ic_life.company AS company_life,
            CASE 
                WHEN ic_life.create_date IS NULL OR ic_life.create_date = '0000-00-00' THEN NULL
                ELSE ic_life.create_date
            END AS card_issued_date_life,
            CASE 
                WHEN ic_life.expire_date IS NULL OR ic_life.expire_date = '0000-00-00' THEN NULL
                ELSE ic_life.expire_date
            END AS card_expiry_date_life

        FROM tbl_ins_card ic_ins
        LEFT JOIN tbl_ins_card ic_life
            ON ic_life.cuscode = ic_ins.cuscode AND ic_life.ins_type = 'LIFE'
        WHERE ic_ins.ins_type = 'INS'
            AND ic_ins.cuscode LIKE 'FNG%%'
            AND ic_ins.name NOT LIKE '%%‡∏ó‡∏î‡∏™‡∏≠‡∏ö%%'
            AND ic_ins.name NOT LIKE '%%test%%'
            AND ic_ins.name NOT LIKE '%%‡πÄ‡∏ó‡∏™‡∏£‡∏∞‡∏ö‡∏ö%%'
            AND ic_ins.name NOT LIKE '%%Tes ‡∏£‡∏∞‡∏ö‡∏ö%%'
            AND ic_ins.name NOT LIKE '%%‡∏ó‡∏î‡πà‡∏ó%%'
            AND ic_ins.name NOT LIKE '%%‡∏ó‡∏î ‡∏™‡∏≠‡∏ö%%'
    """
    df = pd.read_sql(query, source_engine)

    print("üì¶ df:", df.shape)

    return df

@op
def clean_card_agent_data(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = df.columns.str.lower()

    # ‚úÖ Replace string 'NaN', 'nan', 'None' with actual np.nan
    df.replace(['NaN', 'nan', 'None'], np.nan, inplace=True)

    # ‚úÖ Handle date columns properly
    date_columns = [col for col in df.columns if 'date' in col.lower()]
    for col in date_columns:
        # convert to datetime and force errors to NaT
        df[col] = pd.to_datetime(df[col], errors='coerce')
        # convert NaT to None for PostgreSQL compatibility
        df[col] = df[col].where(pd.notnull(df[col]), None)

    # ‚úÖ Clean up ID card columns
    id_card_columns = ['id_card_ins', 'id_card_life']
    for col in id_card_columns:
        if col in df.columns:
            df[col] = df[col].astype(str)
            df[col] = df[col].replace(['None', 'nan', 'NaN'], None)
            df[col] = df[col].str.replace(r'\D+', '', regex=True)  # remove non-digit
            df[col] = df[col].replace('', None)

    # ‚úÖ Convert all NaN values to None for PostgreSQL compatibility
    df = df.where(pd.notnull(df), None)

    print("\nüìä Cleaning completed")
    return df

@op
def load_card_agent_data(df: pd.DataFrame):
    table_name = 'dim_card_agent'
    pk_column = 'agent_id'

    # ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á agent_id ‡∏ã‡πâ‡∏≥‡∏à‡∏≤‡∏Å DataFrame ‡πÉ‡∏´‡∏°‡πà
    df = df[~df[pk_column].duplicated(keep='first')].copy()
    
    # ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà agent_id ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô None
    df = df[df[pk_column].notna()].copy()
    
    if df.empty:
        print("‚ö†Ô∏è No valid data to process")
        return

    # ‚úÖ ‡πÉ‡∏ä‡πâ temporary table ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
    temp_table_name = f'temp_{table_name}_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}'
    
    # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á temporary table ‡πÅ‡∏•‡∏∞ insert ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
    with target_engine.begin() as conn:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á temporary table
        create_temp_table_sql = f"""
            CREATE TEMP TABLE {temp_table_name} AS 
            SELECT * FROM {table_name} WHERE 1=0
        """
        conn.execute(text(create_temp_table_sql))
        
        # Insert ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏•‡∏á temporary table (‡∏Å‡∏£‡∏≠‡∏á duplicate ‡∏Å‡πà‡∏≠‡∏ô)
        if not df.empty:
            # ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô records
            records = []
            current_time = pd.Timestamp.now()
            seen_agent_ids = set()  # ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö duplicate
            
            for _, row in df.iterrows():
                agent_id = row[pk_column]
                
                # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤ agent_id ‡∏ã‡πâ‡∏≥
                if agent_id in seen_agent_ids:
                    continue
                seen_agent_ids.add(agent_id)
                
                record = {}
                for col, value in row.items():
                    if pd.isna(value) or value == pd.NaT or value == '':
                        record[col] = None
                    else:
                        record[col] = value
                # ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ audit fields ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö insert
                record['create_at'] = current_time
                record['update_at'] = current_time
                records.append(record)
            
            # Insert ‡πÅ‡∏ö‡∏ö batch ‡∏•‡∏á temporary table (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å)
            if records:
                # ‡πÉ‡∏ä‡πâ temporary table metadata ‡πÅ‡∏ó‡∏ô
                temp_metadata = Table(temp_table_name, MetaData(), autoload_with=target_engine)
                conn.execute(temp_metadata.insert(), records)

    # ‚úÖ ‡πÉ‡∏ä‡πâ SQL ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ records ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á insert ‡πÅ‡∏•‡∏∞ update
    with target_engine.connect() as conn:
        # ‡∏´‡∏≤ records ‡πÉ‡∏´‡∏°‡πà (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å)
        insert_query = f"""
            SELECT t.* 
            FROM {temp_table_name} t
            LEFT JOIN {table_name} m ON t.{pk_column} = m.{pk_column}
            WHERE m.{pk_column} IS NULL
        """
        df_to_insert = pd.read_sql(text(insert_query), conn)
        
        # ‡∏´‡∏≤ records ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á update (‡∏°‡∏µ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏ï‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô)
        update_query = f"""
            SELECT t.*, m.{pk_column} as existing_{pk_column}
            FROM {temp_table_name} t
            INNER JOIN {table_name} m ON t.{pk_column} = m.{pk_column}
            WHERE (
                COALESCE(t.title, '') != COALESCE(m.title, '') OR
                COALESCE(t.agent_name, '') != COALESCE(m.agent_name, '') OR
                COALESCE(t.id_card_ins, '') != COALESCE(m.id_card_ins, '') OR
                COALESCE(t.type_ins, '') != COALESCE(m.type_ins, '') OR
                COALESCE(t.revoke_type_ins, '') != COALESCE(m.revoke_type_ins, '') OR
                COALESCE(t.company_ins, '') != COALESCE(m.company_ins, '') OR
                COALESCE(t.card_issued_date_ins::text, '') != COALESCE(m.card_issued_date_ins::text, '') OR
                COALESCE(t.card_expiry_date_ins::text, '') != COALESCE(m.card_expiry_date_ins::text, '') OR
                COALESCE(t.id_card_life, '') != COALESCE(m.id_card_life, '') OR
                COALESCE(t.type_life, '') != COALESCE(m.type_life, '') OR
                COALESCE(t.revoke_type_life, '') != COALESCE(m.revoke_type_life, '') OR
                COALESCE(t.company_life, '') != COALESCE(m.company_life, '') OR
                COALESCE(t.card_issued_date_life::text, '') != COALESCE(m.card_issued_date_life::text, '') OR
                COALESCE(t.card_expiry_date_life::text, '') != COALESCE(m.card_expiry_date_life::text, '')
            )
        """
        df_to_update = pd.read_sql(text(update_query), conn)

    print(f"üìä New data: {len(df)} rows")
    print(f"üÜï Insert: {len(df_to_insert)} rows")
    print(f"üîÑ Update: {len(df_to_update)} rows")

    # ‚úÖ Insert records ‡πÉ‡∏´‡∏°‡πà
    if not df_to_insert.empty:
        with target_engine.begin() as conn:
            # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå existing_agent_id ‡∏≠‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            if 'existing_agent_id' in df_to_insert.columns:
                df_to_insert = df_to_insert.drop('existing_agent_id', axis=1)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô records
            records = df_to_insert.to_dict('records')
            metadata = Table(table_name, MetaData(), autoload_with=target_engine)
            conn.execute(metadata.insert(), records)

    # ‚úÖ Update records ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß - ‡πÉ‡∏ä‡πâ batch UPDATE
    if not df_to_update.empty:
        with target_engine.begin() as conn:
            # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå existing_agent_id ‡∏≠‡∏≠‡∏Å
            if 'existing_agent_id' in df_to_update.columns:
                df_to_update = df_to_update.drop('existing_agent_id', axis=1)
            
            # ‡πÉ‡∏ä‡πâ batch UPDATE ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ó‡∏µ‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß
            update_columns = [
                'title', 'agent_name', 'id_card_ins', 'type_ins', 'revoke_type_ins', 
                'company_ins', 'card_issued_date_ins', 'card_expiry_date_ins',
                'id_card_life', 'type_life', 'revoke_type_life', 'company_life',
                'card_issued_date_life', 'card_expiry_date_life', 'update_at'
            ]
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á batch UPDATE statement
            set_clause = ', '.join([f"{col} = t.{col}" for col in update_columns if col != 'update_at'])
            set_clause += ", update_at = NOW()"
            
            # ‡πÉ‡∏ä‡πâ CASE WHEN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö batch update
            agent_ids = df_to_update[pk_column].tolist()
            if agent_ids:
                # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô chunks ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á query ‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                chunk_size = 1000
                for i in range(0, len(agent_ids), chunk_size):
                    chunk_ids = agent_ids[i:i+chunk_size]
                    ids_str = ','.join([f"'{id}'" for id in chunk_ids])
                    
                    update_sql = f"""
                        UPDATE {table_name} m
                        SET {set_clause}
                        FROM {temp_table_name} t
                        WHERE m.{pk_column} = t.{pk_column}
                        AND m.{pk_column} IN ({ids_str})
                    """
                    conn.execute(text(update_sql))

    # ‚úÖ ‡∏•‡∏ö temporary table
    with target_engine.begin() as conn:
        conn.execute(text(f"DROP TABLE IF EXISTS {temp_table_name}"))

    print("‚úÖ Insert/update completed.")

@job
def dim_card_agent_etl():
    load_card_agent_data(clean_card_agent_data(extract_card_agent_data()))

# if __name__ == "__main__":
#     df_raw = extract_card_agent_data()

#     df_clean = clean_card_agent_data((df_raw))
#     print("‚úÖ Cleaned columns:", df_clean.columns)

#     # output_path = "dim_card_agent.csv"
#     # df_clean.to_csv(output_path, index=False, encoding='utf-8-sig')
#     # print(f"üíæ Saved to {output_path}")

#     # output_path = "dim_card_agent.xlsx"
#     # df_clean.to_excel(output_path, index=False, engine='openpyxl')
#     # print(f"üíæ Saved to {output_path}")

#     load_card_agent_data(df_clean)
#     print("üéâ completed! Data upserted to dim_card_agent.")