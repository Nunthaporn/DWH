from dagster import op, job
import pandas as pd
import numpy as np
import os
import re
from dotenv import load_dotenv
from sqlalchemy import create_engine, text, MetaData, Table, inspect
from sqlalchemy.dialects.postgresql import insert as pg_insert
from datetime import datetime, timedelta

# ‚úÖ Load .env
load_dotenv()

# ‚úÖ DB source (MariaDB)
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance"
)

# ‚úÖ DB target (PostgreSQL)
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance?connect_timeout=60"
)

@op
def extract_payment_data():
    now = datetime.now()

    start_time = now.replace(minute=0, second=0, microsecond=0)
    end_time = now.replace(minute=59, second=59, microsecond=999999)

    start_str = start_time.strftime('%Y-%m-%d %H:%M:%S')
    end_str = end_time.strftime('%Y-%m-%d %H:%M:%S')

    query1 = """
        SELECT quo_num, chanel_main, clickbank, chanel, numpay, condition_install
        FROM fin_system_pay
        WHERE update_at BETWEEN '{start_str}' AND '{end_str}'
        AND type_insure IN ('‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏£‡∏ñ', '‡∏ï‡∏£‡∏≠')
    """
    df_pay = pd.read_sql(query1, source_engine)

    query2 = """
        SELECT quo_num, status_paybill
        FROM fininsurance_task.fin_order
        WHERE type_insure IN ('‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏£‡∏ñ', '‡∏ï‡∏£‡∏≠')
    """
    df_order = pd.read_sql(query2, source_engine)

    df = pd.merge(df_pay, df_order, on='quo_num', how='left')

    print("üì¶ df_pay:", df_pay.shape)
    print("üì¶ df_order:", df_order.shape)
    print("üì¶ df:", df.shape)

    return df

@op
def clean_payment_data(df: pd.DataFrame):
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á string "NaN", " nan ", "NaN " ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô np.nan
    df = df.map(lambda x: np.nan if isinstance(x, str) and x.strip().lower() == "nan" else x)

    # ‚úÖ ‡πÄ‡∏ï‡∏¥‡∏°‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô '' ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô type ‚Üí str
    for col in ['chanel', 'chanel_main', 'clickbank']:
        df[col] = df[col].fillna('').astype(str).str.strip()
        
    ch = df['chanel'].str.lower()
    chm = df['chanel_main'].str.lower()
    cb = df['clickbank'].str.lower()

    conditions = [
        ch == '‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏¥‡∏ô',
        ch == '‡πÄ‡∏Ç‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô',
        (chm.isin(['‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï', '‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£']) & cb.isin(['creditcard', '']) & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.isin(['']) & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô') & cb.isin(['qrcode']) & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.isin(['creditcard', '']) & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.isin(['qrcode','creditcard','']) & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡πÇ‡∏≠‡∏ô‡πÄ‡∏á‡∏¥‡∏ô') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.eq('') & ch.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ä‡∏≥‡∏£‡∏∞') & (cb.isin(['qrcode', '']) | cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£')) & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô')),
    ]

    choices = [
        '‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏¥‡∏ô',
        '‡πÄ‡∏Ç‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô',
        *(['‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏¥‡∏ô'] * (len(conditions) - 2)),
    ]

    df['chanel'] = np.select(conditions, choices, default=df['chanel'])

    # ‚úÖ Generate payment_channel (‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ apply ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ logic ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô)
    def determine_payment_channel(row):
        ch_main = str(row['chanel_main']).strip().lower()
        cb_raw = row['clickbank']
        cb = str(cb_raw).strip().lower()
        is_cb_empty = pd.isna(cb_raw) or cb == ''

        if ch_main in ['‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï', '‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£', '‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï', '‡∏ú‡πà‡∏≠‡∏ô‡∏ä‡∏≥‡∏£‡∏∞']:
            if 'qrcode' in cb:
                return 'QR Code'
            elif 'creditcard' in cb:
                return '2C2P'
            else:
                return '‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡∏Å‡∏±‡∏ö‡∏ü‡∏¥‡∏ô'
        if ch_main in ['‡πÇ‡∏≠‡∏ô‡πÄ‡∏á‡∏¥‡∏ô', '‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô']:
            if 'qrcode' in cb:
                return 'QR Code'
            else:
                return '‡πÇ‡∏≠‡∏ô‡πÄ‡∏á‡∏¥‡∏ô'
        if ch_main and is_cb_empty:
            return row['chanel_main']
        elif not ch_main and not is_cb_empty:
            if 'qrcode' in cb:
                return 'QR Code'
            elif 'creditcard' in cb:
                return '2C2P'
            else:
                return row['clickbank']
        elif not is_cb_empty:
            if 'qrcode' in cb:
                return 'QR Code'
            elif 'creditcard' in cb:
                return '2C2P'
            else:
                return row['clickbank']
        else:
            return ''

    df['payment_channel'] = df.apply(determine_payment_channel, axis=1)

    # ‚úÖ Clean + rename
    df.drop(columns=['chanel_main', 'clickbank', 'condition_install'], inplace=True)
    df = df.rename(columns={
        'quo_num': 'quotation_num',
        'numpay': 'installment_number',
        'chanel': 'payment_reciever',
        'status_paybill': 'payment_type'
    })

    # ‚úÖ Clean values
    df = df[~df['quotation_num'].str.endswith('-r', na=False)]
    df['installment_number'] = pd.to_numeric(df['installment_number'], errors='coerce').fillna(0).astype(int)
    df['installment_number'] = df['installment_number'].replace({0: 1})

    # ‚úÖ Remove test records
    query_del = """
        SELECT quo_num FROM fininsurance.fin_system_select_plan
        WHERE name IN ('‡∏ó‡∏î‡∏™‡∏≠‡∏ö','test')
        AND type_insure IN ('‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏£‡∏ñ', '‡∏ï‡∏£‡∏≠')
    """
    df_del = pd.read_sql(query_del, source_engine)
    df = df[~df['quotation_num'].isin(df_del['quo_num'])]
    df = df[df['quotation_num'] != 'FQ2505-24999']

    print("\nüìä Cleaning completed")

    return df.replace(['', np.nan], None)

@op
def load_payment_data(df: pd.DataFrame):
    table_name = 'dim_payment_plan'
    pk_column = 'quotation_num'

    # Ensure the unique constraint on quotation_num
    with target_engine.connect() as conn:
        # Check if the unique constraint exists, and add if not
        conn.execute(text(f"""
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT 1 FROM pg_constraint WHERE conname = 'unique_quotation_num') THEN
                    ALTER TABLE {table_name} ADD CONSTRAINT unique_quotation_num UNIQUE ({pk_column});
                END IF;
            END $$;
        """))
        conn.commit()

    df = df[~df[pk_column].duplicated(keep='first')].copy()

    # ‚úÖ ‡∏ß‡∏±‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ 00:00:00)
    today_str = datetime.now().strftime('%Y-%m-%d')

    # ‚úÖ Load ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å PostgreSQL
    with target_engine.connect() as conn:
        df_existing = pd.read_sql(
            f"SELECT * FROM {table_name} WHERE update_at >= '{today_str}'",
            conn
        )

    df_existing = df_existing[~df_existing[pk_column].duplicated(keep='first')].copy()

    new_ids = set(df[pk_column]) - set(df_existing[pk_column])
    df_to_insert = df[df[pk_column].isin(new_ids)].copy()

    common_ids = set(df[pk_column]) & set(df_existing[pk_column])
    df_common_new = df[df[pk_column].isin(common_ids)].copy()
    df_common_old = df_existing[df_existing[pk_column].isin(common_ids)].copy()

    merged = df_common_new.merge(df_common_old, on=pk_column, suffixes=('_new', '_old'))

    exclude_columns = [pk_column, 'payment_plan_id', 'create_at', 'update_at']

    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì column ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á df ‡πÅ‡∏•‡∏∞ df_existing ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    all_columns = set(df_common_new.columns) & set(df_common_old.columns)
    compare_cols = [
        col for col in all_columns
        if col not in exclude_columns
        and f"{col}_new" in merged.columns
        and f"{col}_old" in merged.columns
    ]

    def is_different(row):
        for col in compare_cols:
            val_new = row.get(f"{col}_new")
            val_old = row.get(f"{col}_old")
            if pd.isna(val_new) and pd.isna(val_old):
                continue
            if val_new != val_old:
                return True
        return False

    # Filter rows that have differences
    df_diff = merged[merged.apply(is_different, axis=1)].copy()

    if not df_diff.empty and compare_cols:
        update_cols = [f"{col}_new" for col in compare_cols]
        all_cols = [pk_column] + update_cols

        # ‚úÖ ‡πÄ‡∏ä‡πá‡∏Ñ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏ß‡∏£‡πå‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á
        existing_cols = [c for c in all_cols if c in df_diff.columns]
        
        if len(existing_cols) > 1:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ pk_column ‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏∑‡πà‡∏ô
            df_diff_renamed = df_diff.loc[:, existing_cols].copy()
            # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠ column ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á
            new_col_names = [pk_column] + [col.replace('_new', '') for col in existing_cols if col != pk_column]
            df_diff_renamed.columns = new_col_names
        else:
            df_diff_renamed = pd.DataFrame()
    else:
        df_diff_renamed = pd.DataFrame()

    print(f"üÜï Insert: {len(df_to_insert)} rows")
    print(f"üîÑ Update: {len(df_diff_renamed)} rows")

    metadata = Table(table_name, MetaData(), autoload_with=target_engine)

    # Insert only the new records
    if not df_to_insert.empty:
        df_to_insert_valid = df_to_insert[df_to_insert[pk_column].notna()].copy()
        dropped = len(df_to_insert) - len(df_to_insert_valid)
        if dropped > 0:
            print(f"‚ö†Ô∏è Skipped {dropped}")
        if not df_to_insert_valid.empty:
            with target_engine.begin() as conn:
                conn.execute(metadata.insert(), df_to_insert_valid.to_dict(orient='records'))

    # Update only the records where there is a change
    if not df_diff_renamed.empty and compare_cols:
        with target_engine.begin() as conn:
            for record in df_diff_renamed.to_dict(orient='records'):
                stmt = pg_insert(metadata).values(**record)
                update_columns = {
                    c.name: stmt.excluded[c.name]
                    for c in metadata.columns
                    if c.name not in [pk_column, 'payment_plan_id', 'create_at', 'update_at']
                }
                # update_at ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                update_columns['update_at'] = datetime.now()
                stmt = stmt.on_conflict_do_update(
                    index_elements=[pk_column],
                    set_=update_columns
                )
                conn.execute(stmt)

    print("‚úÖ Insert/update completed.")


@job
def dim_payment_plan_etl():
    load_payment_data(clean_payment_data(extract_payment_data()))

# if __name__ == "__main__":
#     df_raw = extract_payment_data()
#     print("‚úÖ Extracted logs:", df_raw.shape)

#     df_clean = clean_payment_data((df_raw))
#     print("‚úÖ Cleaned columns:", df_clean.columns)

#     # output_path = "dim_payment_plan.csv"
#     # df_clean.to_csv(output_path, index=False, encoding='utf-8-sig')
#     # print(f"üíæ Saved to {output_path}")

#     # output_path = "dim_payment_plan.xlsx"
#     # df_clean.to_excel(output_path, index=False, engine='openpyxl')
#     # print(f"üíæ Saved to {output_path}")

#     load_payment_data(df_clean)
#     print("üéâ completed! Data upserted to dim_payment_plan.")