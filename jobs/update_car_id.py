from dagster import op, job
import os
import re
import pandas as pd
import numpy as np
from dotenv import load_dotenv
from sqlalchemy import create_engine, text, MetaData, Table
from sqlalchemy.dialects.postgresql import insert as pg_insert

# =========================
# üîß ENV & DB CONNECTIONS
# =========================
load_dotenv()

# MariaDB (source)
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@"
    f"{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance",
    pool_pre_ping=True,
    pool_recycle=3600,
)

# PostgreSQL (target)
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@"
    f"{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance",
    connect_args={
        "keepalives": 1,
        "keepalives_idle": 30,
        "keepalives_interval": 10,
        "keepalives_count": 5,
        "options": "-c statement_timeout=300000",
    },
    pool_pre_ping=True,
    pool_recycle=3600,
)

# =========================
# üîß HELPERS
# =========================
NULL_TOKENS = {"", "nan", "none", "null", "undefined", "nat"}

def normalize_str(s: pd.Series) -> pd.Series:
    s = s.astype("string")
    s = s.str.strip()
    s = s.mask(s.str.len() == 0)
    s = s.mask(s.str.lower().isin(NULL_TOKENS))
    return s

def clean_engine_number(v):
    if pd.isna(v):
        return None
    cleaned = re.sub(r"[^A-Za-z0-9]", "", str(v))
    return cleaned.upper() if cleaned else None

def has_thai_chars(v):
    if pd.isna(v):
        return False
    return bool(re.search(r"[‡∏Å-‡πô]", str(v)))

# =========================
# üß≤ EXTRACT & CLEAN (‡∏à‡∏≤‡∏Å MariaDB)
# =========================
@op
def extract_and_clean_vin_keys() -> pd.DataFrame:
    """
    ‡∏î‡∏∂‡∏á quo_num, id_motor1(‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á), id_motor2(VIN) ‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
    ‡∏Ñ‡∏∑‡∏ô DataFrame: [quotation_num, car_vin, engine_number]
    """
    # pay
    df_pay = pd.read_sql(
        """
        SELECT quo_num, TRIM(id_motor1) AS id_motor1, TRIM(id_motor2) AS id_motor2
        FROM fin_system_pay
        """,
        source_engine,
    )

    # plan (‡∏°‡∏µ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠ ensure ‡∏ß‡πà‡∏≤ quo_num ‡∏ô‡∏µ‡πâ‡πÄ‡∏Ñ‡∏¢‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏£‡∏¥‡∏á)
    df_plan = pd.read_sql(
        """
        SELECT quo_num
        FROM fin_system_select_plan
        """,
        source_engine,
    )

    # dedup ‡∏î‡πâ‡∏ß‡∏¢ quo_num ‡∏Å‡πà‡∏≠‡∏ô
    df_pay = df_pay.drop_duplicates(subset=["quo_num"], keep="first")
    df_plan = df_plan.drop_duplicates(subset=["quo_num"], keep="first")

    # merge
    df = pd.merge(df_pay, df_plan, on="quo_num", how="left")

    # rename
    df = df.rename(
        columns={"quo_num": "quotation_num", "id_motor2": "car_vin", "id_motor1": "engine_number"}
    )

    # ensure columns exist
    if "car_vin" not in df.columns:
        df["car_vin"] = None
    if "engine_number" not in df.columns:
        df["engine_number"] = None

    # normalize
    df["car_vin"] = normalize_str(df["car_vin"]).str.upper()
    df["engine_number"] = df["engine_number"].apply(clean_engine_number)

    # ‡∏Å‡∏£‡∏≠‡∏á VIN ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á/‡∏°‡∏µ‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÑ‡∏ó‡∏¢
    df = df[df["car_vin"].notna()]
    df = df[~df["car_vin"].apply(has_thai_chars)]

    # ‡πÄ‡∏Å‡πá‡∏ö record ‡∏ó‡∏µ‡πà field ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏¢‡∏≠‡∏∞‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ã‡πâ‡∏≥ VIN
    df["_nonnull"] = df[["car_vin", "engine_number", "quotation_num"]].notna().sum(axis=1)
    df = df.sort_values("_nonnull", ascending=False).drop_duplicates(subset=["car_vin"], keep="first")
    df = df.drop(columns=["_nonnull"])

    # ‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢ 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
    df = df[["quotation_num", "car_vin", "engine_number"]].copy()
    print(f"‚úÖ keys cleaned: {len(df):,} rows")
    return df

# =========================
# üè≠ LOAD dim_car (‡∏à‡∏≤‡∏Å PostgreSQL)
# =========================
@op
def fetch_dim_car_min() -> pd.DataFrame:
    df_car = pd.read_sql(text("SELECT car_id, car_vin, engine_number FROM dim_car"), target_engine)
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô
    df_car["car_vin"] = normalize_str(df_car["car_vin"]).str.upper()
    df_car["engine_number"] = df_car["engine_number"].apply(clean_engine_number)
    df_car = df_car.dropna(subset=["car_vin"])  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ VIN
    print(f"‚úÖ dim_car loaded: {len(df_car):,} rows")
    return df_car[["car_id", "car_vin", "engine_number"]].drop_duplicates()

# =========================
# üîó BUILD MAPPING (VIN+ENGINE -> car_id)
# =========================
@op
def build_car_mapping(df_keys: pd.DataFrame, df_dim: pd.DataFrame) -> pd.DataFrame:
    """
    join ‡πÅ‡∏ö‡∏ö strict ‡∏î‡πâ‡∏ß‡∏¢ (car_vin, engine_number)
    ‡∏Ñ‡∏∑‡∏ô DataFrame: [quotation_num, car_id]
    """
    # inner join
    df_map = pd.merge(
        df_keys, df_dim, on=["car_vin", "engine_number"], how="inner"
    )  # ‡πÑ‡∏î‡πâ [quotation_num, car_vin, engine_number, car_id]

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 2 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ ‡πÅ‡∏•‡∏∞‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥ quotation_num
    df_map = df_map[["quotation_num", "car_id"]].copy()
    df_map = df_map.drop_duplicates(subset=["quotation_num"], keep="first")
    print(f"‚úÖ mapping built (strict VIN+ENGINE): {len(df_map):,} rows")
    return df_map

# =========================
# üßπ FILTER ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô fact
# =========================
@op
def restrict_to_existing_quotes(df_map: pd.DataFrame) -> pd.DataFrame:
    df_fact = pd.read_sql(text("SELECT quotation_num FROM fact_sales_quotation"), target_engine)
    out = pd.merge(df_map, df_fact, on="quotation_num", how="inner")
    out = out.drop_duplicates(subset=["quotation_num"])
    print(f"‚úÖ mapping filtered by existing facts: {len(out):,} rows")
    return out[["quotation_num", "car_id"]]

# =========================
# üßº STAGE TEMP TABLE
# =========================
@op
def stage_dim_car_temp(df_map: pd.DataFrame) -> str:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß dim_car_temp (quotation_num, car_id)
    """
    if df_map.empty:
        # ‡πÉ‡∏´‡πâ‡∏°‡∏µ schema ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏°‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        df_map = pd.DataFrame(
            {"quotation_num": pd.Series(dtype="string"), "car_id": pd.Series(dtype="Int64")}
        )

    # sanitize
    df_map = df_map.copy()
    df_map["quotation_num"] = normalize_str(df_map["quotation_num"])
    # car_id ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô int/float; ‡πÅ‡∏Ñ‡∏™‡∏ï‡πå‡πÄ‡∏õ‡πá‡∏ô Int64 (nullable) ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ to_sql
    df_map["car_id"] = pd.to_numeric(df_map["car_id"], errors="coerce").astype("Int64")

    df_map.to_sql("dim_car_temp", target_engine, if_exists="replace", index=False, method="multi", chunksize=20000)
    print(f"‚úÖ staged dim_car_temp: {len(df_map):,} rows")
    return "dim_car_temp"

# =========================
# üöÄ APPLY UPDATE TO FACT
# =========================
@op
def update_fact_car_id(temp_table_name: str) -> int:
    """
    ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï fact_sales_quotation.car_id ‡∏à‡∏≤‡∏Å temp
    ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤ '‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á' (NULL-safe)
    """
    if not temp_table_name:
        print("‚ö†Ô∏è temp table name missing; skip update.")
        return 0

    update_sql = text(f"""
        UPDATE fact_sales_quotation fsq
        SET car_id = dc.car_id
        FROM {temp_table_name} dc
        WHERE fsq.quotation_num = dc.quotation_num;
    """)

    with target_engine.begin() as conn:
        res = conn.execute(update_sql)
        print(f"‚úÖ fact_sales_quotation updated: {res.rowcount} rows")
        return res.rowcount or 0

# =========================
# üßπ DROP TEMP
# =========================
@op
def drop_dim_car_temp(temp_table_name: str) -> None:
    if not temp_table_name:
        return
    with target_engine.begin() as conn:
        conn.execute(text(f"DROP TABLE IF EXISTS {temp_table_name};"))
    print("üóëÔ∏è dropped dim_car_temp")

# =========================
# üß± DAGSTER JOB
# =========================
@job
def fix_car_id_on_fact():
    keys = extract_and_clean_vin_keys()
    dimc = fetch_dim_car_min()
    mapping = build_car_mapping(keys, dimc)
    mapping_in_fact = restrict_to_existing_quotes(mapping)
    temp = stage_dim_car_temp(mapping_in_fact)
    _ = update_fact_car_id(temp)
    drop_dim_car_temp(temp)

# =========================
# ‚ñ∂Ô∏è LOCAL RUN (optional)
# =========================
if __name__ == "__main__":
    k = extract_and_clean_vin_keys()
    d = fetch_dim_car_min()
    m = build_car_mapping(k, d)
    mf = restrict_to_existing_quotes(m)
    t = stage_dim_car_temp(mf)
    updated = update_fact_car_id(t)
    drop_dim_car_temp(t)
    print(f"üéâ done. updated rows = {updated}")
