from dagster import op, job
import pandas as pd
import numpy as np
import os
import re
import time
from datetime import datetime
from dotenv import load_dotenv
from sqlalchemy import create_engine
from sqlalchemy import create_engine, MetaData, Table, inspect
from sqlalchemy.dialects.postgresql import insert as pg_insert
from datetime import datetime, timedelta

# ‚úÖ Load env
load_dotenv()

# ‚úÖ DB connections
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance",
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,
    pool_pre_ping=True,
    echo=False
)
task_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance_task",
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,
    pool_pre_ping=True,
    echo=False
)
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance",
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,
    pool_pre_ping=True,
    echo=False,
    connect_args={
        "connect_timeout": 30,
        "application_name": "fact_installment_payments_etl",
        "options": "-c statement_timeout=300000 -c idle_in_transaction_session_timeout=300000"
    }
)

@op
def extract_installment_data():
    now = datetime.now()

    start_time = now.replace(minute=0, second=0, microsecond=0)  
    end_time = now.replace(minute=59, second=59, microsecond=999999) 

    start_str = start_time.strftime('%Y-%m-%d %H:%M:%S')
    end_str = end_time.strftime('%Y-%m-%d %H:%M:%S')

    try:
        print("üîÑ Loading data from databases...")
        
        # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° WHERE clause ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        df_plan = pd.read_sql(f"""
            SELECT quo_num
            FROM fin_system_select_plan
            WHERE datestart BETWEEN '{start_str}' AND '{end_str}'
            AND type_insure IN ('‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏£‡∏ñ', '‡∏ï‡∏£‡∏≠')
        """, source_engine)

        # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ quo_num ‡πÉ‡∏ô df_plan
        if not df_plan.empty:
            quo_nums = "','".join(df_plan['quo_num'].dropna().astype(str))
            df_installment = pd.read_sql(f"""
                SELECT quo_num, money_one, money_two, money_three, money_four,
                       money_five, money_six, money_seven, money_eight, money_nine,
                       money_ten, money_eleven, money_twelve,
                       date_one, date_two, date_three, date_four, date_five,
                       date_six, date_seven, date_eight, date_nine, date_ten,
                       date_eleven, date_twelve, numpay
                FROM fin_installment
                WHERE quo_num IN ('{quo_nums}')
            """, source_engine)
        else:
            df_installment = pd.DataFrame()

        df_order = pd.read_sql("""
            SELECT quo_num, order_number
            FROM fin_order
            WHERE type_insure IN ('‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏£‡∏ñ', '‡∏ï‡∏£‡∏≠')
        """, task_engine)

        # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ order_number ‡πÉ‡∏ô df_order
        if not df_order.empty:
            order_nums = "','".join(df_order['order_number'].dropna().astype(str))
            df_finance = pd.read_sql(f"""
                SELECT order_number, datepay_one, datepay_two, datepay_three, datepay_four,
                       datepay_five, datepay_six, datepay_seven, datepay_eight,
                       datepay_nine, datepay_ten, datepay_eleven, datepay_twelve,
                       moneypay_one, moneypay_two, moneypay_three, moneypay_four,
                       moneypay_five, moneypay_six, moneypay_seven, moneypay_eight,
                       moneypay_nine, moneypay_ten, moneypay_eleven, moneypay_twelve,
                       numpay
                FROM fin_finance
                WHERE order_number IN ('{order_nums}')
            """, task_engine)

            df_bill = pd.read_sql(f"""
                SELECT order_number, bill_receipt, bill_receipt2, bill_receipt3,
                       bill_receipt4, bill_receipt5, bill_receipt6, bill_receipt7,
                       bill_receipt8, bill_receipt9, bill_receipt10, bill_receipt11, bill_receipt12
                FROM fin_bill
                WHERE order_number IN ('{order_nums}')
            """, task_engine)
        else:
            df_finance = pd.DataFrame()
            df_bill = pd.DataFrame()

        df_late_fee = pd.read_sql("""
            SELECT orderNumber, penaltyPay, numPay
            FROM FIN_Account_AttachSlip_PathImageSlip
            WHERE checkPay IN ('‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏±‡∏ö', '‡∏Ñ‡πà‡∏≤‡∏á‡∏ß‡∏î/‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏±‡∏ö')
        """, task_engine)

        df_test = pd.read_sql("""
            SELECT quo_num
            FROM fin_system_select_plan
            WHERE name IN ('‡∏ó‡∏î‡∏™‡∏≠‡∏ö','test')
              AND type_insure IN ('‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏£‡∏ñ', '‡∏ï‡∏£‡∏≠')
        """, source_engine)
        
        # ‚úÖ ‡∏•‡∏î memory usage ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        import gc
        gc.collect()
        
    except Exception as e:
        print(f"‚ùå Error during data extraction: {e}")
        # ‚úÖ Rollback connections ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ PendingRollbackError
        for engine_name, engine in [("source", source_engine), ("task", task_engine), ("target", target_engine)]:
            try:
                with engine.connect() as conn:
                    conn.rollback()
                print(f"‚úÖ Rollback successful for {engine_name} engine")
            except Exception as rollback_error:
                print(f"‚ö†Ô∏è Rollback failed for {engine_name} engine: {rollback_error}")
        
        # ‚úÖ ‡∏õ‡∏¥‡∏î connections ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        try:
            source_engine.dispose()
            task_engine.dispose()
            target_engine.dispose()
            print("‚úÖ All engines disposed successfully")
        except Exception as dispose_error:
            print(f"‚ö†Ô∏è Engine disposal failed: {dispose_error}")
        
        raise e

    # ‚úÖ ‡∏•‡∏î debug prints ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏Ñ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    print(f"üì¶ Data loaded: plan({df_plan.shape[0]}), installment({df_installment.shape[0]}), "
          f"order({df_order.shape[0]}), finance({df_finance.shape[0]}), "
          f"bill({df_bill.shape[0]}), late_fee({df_late_fee.shape[0]}), test({df_test.shape[0]})")

    return df_plan, df_installment, df_order, df_finance, df_bill, df_late_fee, df_test

@op
def clean_installment_data(inputs):
    df_plan, df_inst, df_order, df_fin, df_bill, df_fee, df_test = inputs

    print("üîÑ Processing installment data...")

    # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏á‡∏ß‡∏î + ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    df_inst['numpay'] = pd.to_numeric(df_inst['numpay'], errors='coerce')
    df_filtered = df_inst[df_inst['numpay'].notna() & (df_inst['numpay'] > 0)]

    money_cols = [f'money_{n}' for n in ['one', 'two', 'three', 'four', 'five', 'six',
                                         'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve']]
    date_cols = [f'date_{n}' for n in ['one', 'two', 'three', 'four', 'five', 'six',
                                       'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve']]

    # ‚úÖ ‡∏•‡∏î debug prints ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏Ñ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    print(f"üìä Processing {df_filtered.shape[0]} installment records")

    df_money = df_filtered.melt(id_vars=['quo_num', 'numpay'], value_vars=money_cols,
                                 var_name='installment_period', value_name='installment_amount')
    df_date = df_filtered.melt(id_vars=['quo_num', 'numpay'], value_vars=date_cols,
                                var_name='due_date_period', value_name='due_date')

    df_combined = pd.concat([df_money.reset_index(drop=True), df_date['due_date']], axis=1)
    df_combined['installment_number'] = df_combined.groupby('quo_num').cumcount() + 1
    df_combined = df_combined[df_combined['installment_number'] <= df_combined['numpay']]
    df_combined = df_combined.sort_values(by=['quo_num', 'due_date'])
    df_combined['installment_number'] = df_combined.groupby('quo_num').cumcount() + 1

    print(f"üìä Combined {df_combined.shape[0]} installment records")

    # 2. ‡∏ú‡∏π‡∏Å order_number
    df_join = pd.merge(df_combined, df_order, on='quo_num', how='left')
    print(f"üìä Joined with orders: {df_join.shape[0]} records")

    # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞
    num_to_name = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight',
                   'nine', 'ten', 'eleven', 'twelve']
    
    df_fin['numpay'] = pd.to_numeric(df_fin['numpay'], errors='coerce')
    df_fin = df_fin[df_fin['numpay'].notna() & (df_fin['numpay'] > 0)]

    print(f"üìä Processing {df_fin.shape[0]} finance records")

    # ‡πÉ‡∏ä‡πâ vectorized operations ‡πÅ‡∏ó‡∏ô iterrows()
    rows_list = []
    for i, sfx in enumerate(num_to_name, start=1):
        money_col = f'moneypay_{sfx}'
        date_col = f'datepay_{sfx}'
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ installment
        temp_df = df_fin[['order_number', money_col, date_col]].copy()
        temp_df['installment_number'] = i
        temp_df['payment_amount'] = temp_df[money_col]
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        temp_df['raw_date'] = temp_df[date_col].astype(str)
        temp_df['payment_date'] = pd.to_datetime(
            temp_df['raw_date'].str.extract(r'(\d{4}-\d{1,2}-\d{1,2})')[0], 
            errors='coerce'
        )
        
        # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏µ 2026 ‡πÄ‡∏õ‡πá‡∏ô 2025 - ‡πÉ‡∏ä‡πâ vectorized operations
        mask_2026 = temp_df['payment_date'].dt.year == 2026
        if mask_2026.any():
            # ‡πÉ‡∏ä‡πâ pd.to_datetime() ‡πÅ‡∏ó‡∏ô apply
            temp_df.loc[mask_2026, 'payment_date'] = pd.to_datetime(
                temp_df.loc[mask_2026, 'payment_date'].dt.strftime('2025-%m-%d'),
                errors='coerce'
            )
        
        rows_list.append(temp_df[['order_number', 'payment_amount', 'payment_date', 'installment_number']])

    df_payment = pd.concat(rows_list, ignore_index=True)
    print(f"üìä Created {df_payment.shape[0]} payment records")

    # 4. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° payment proof
    df_proof = df_bill.melt(id_vars=['order_number'],
        value_vars=[f'bill_receipt{i if i > 1 else ""}' for i in range(1, 13)],
        value_name='payment_proof')
    df_proof = df_proof[df_proof['payment_proof'].notna()].reset_index()
    df_proof['installment_number'] = df_proof.groupby('order_number').cumcount() + 1
    df_proof = df_proof[['order_number', 'installment_number', 'payment_proof']]

    print(f"üìä Created {df_proof.shape[0]} proof records")

    # 5. ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    df = pd.merge(df_join, df_payment, on=['order_number', 'installment_number'], how='left')
    df = pd.merge(df, df_proof, on=['order_number', 'installment_number'], how='left')

    print(f"üìä Final merged data: {df.shape[0]} records")

    # 6. ‡πÄ‡∏û‡∏¥‡πà‡∏° late_fee
    df_fee = df_fee.rename(columns={
        'orderNumber': 'order_number',
        'penaltyPay': 'late_fee',
        'numPay': 'installment_number'
    })
    df_fee = df_fee.drop_duplicates()
    df['installment_number'] = pd.to_numeric(df['installment_number'], errors='coerce')
    df_fee['installment_number'] = pd.to_numeric(df_fee['installment_number'], errors='coerce')
    df = pd.merge(df, df_fee, on=['order_number', 'installment_number'], how='left')
    df['late_fee'] = df['late_fee'].fillna(0).astype(int)
    
    # 7. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì total_paid - ‡πÉ‡∏ä‡πâ vectorized operations ‡πÅ‡∏ó‡∏ô apply
    # ‚úÖ ‡∏•‡∏ö comma ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numeric
    if df['payment_amount'].dtype == 'object':
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö comma
        df['payment_amount'] = df['payment_amount'].astype(str)
        
        # ‡∏•‡∏ö comma ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà NaN string
        mask_not_nan = ~df['payment_amount'].str.lower().isin(['nan', 'null', 'none', 'undefined'])
        df.loc[mask_not_nan, 'payment_amount'] = df.loc[mask_not_nan, 'payment_amount'].str.replace(',', '')
    
    if df['installment_amount'].dtype == 'object':
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö comma
        df['installment_amount'] = df['installment_amount'].astype(str)
        
        # ‡∏•‡∏ö comma ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà NaN string
        mask_not_nan = ~df['installment_amount'].str.lower().isin(['nan', 'null', 'none', 'undefined'])
        df.loc[mask_not_nan, 'installment_amount'] = df.loc[mask_not_nan, 'installment_amount'].str.replace(',', '')
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numeric ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ NaN
    df['payment_amount'] = pd.to_numeric(df['payment_amount'], errors='coerce')
    df['payment_amount'] = df['payment_amount'].where(pd.notna(df['payment_amount']), None)
    
    df['installment_amount'] = pd.to_numeric(df['installment_amount'], errors='coerce')
    df['late_fee'] = pd.to_numeric(df['late_fee'], errors='coerce').fillna(0)
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None
    df['installment_amount'] = df['installment_amount'].where(pd.notna(df['installment_amount']), None)
    df['late_fee'] = df['late_fee'].where(pd.notna(df['late_fee']), None)
    
    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Infinity ‡∏´‡∏£‡∏∑‡∏≠ -Infinity
    df['payment_amount'] = df['payment_amount'].replace([np.inf, -np.inf], np.nan)
    df['installment_amount'] = df['installment_amount'].replace([np.inf, -np.inf], np.nan)
    df['late_fee'] = df['late_fee'].replace([np.inf, -np.inf], 0)
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Infinity
    df['payment_amount'] = df['payment_amount'].where(pd.notna(df['payment_amount']), None)
    df['installment_amount'] = df['installment_amount'].where(pd.notna(df['installment_amount']), None)
    df['late_fee'] = df['late_fee'].where(pd.notna(df['late_fee']), None)
    
    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì total_paid ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
    df['total_paid'] = np.where(
        df['late_fee'] == 0,
        df['installment_amount'].fillna(0),
        # ‡∏ñ‡πâ‡∏≤ late_fee != 0 ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ payment_amount + late_fee ‡∏´‡∏£‡∏∑‡∏≠ installment_amount + late_fee
        np.where(
            df['payment_amount'].notna(),
            df['payment_amount'].fillna(0) + df['late_fee'],
            df['installment_amount'].fillna(0) + df['late_fee']
        )
    )
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö total_paid
    df['total_paid'] = df['total_paid'].where(pd.notna(df['total_paid']), None)

    print(f"üìä Calculated total_paid for {df['total_paid'].notna().sum()} records")

    # 8. payment_status
    df['due_date'] = pd.to_datetime(df['due_date'], errors='coerce')
    df['payment_date'] = pd.to_datetime(df['payment_date'], errors='coerce')
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ï‡πà‡∏≤‡∏á‡πÜ
    no_payment = df['payment_amount'].isna() & df['payment_date'].isna() & df['payment_proof'].isna()
    has_payment = df['payment_amount'].notna() | df['payment_proof'].notna()
    has_due_date = df['due_date'].notna()
    has_payment_date = df['payment_date'].notna()
    is_overdue = has_due_date & (datetime.now().date() > df['due_date'].dt.date)
    is_late_payment = has_payment_date & has_due_date & (df['payment_date'].dt.date > df['due_date'].dt.date)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î payment_status
    df['payment_status'] = '‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ä‡∏≥‡∏£‡∏∞'  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    df.loc[no_payment & is_overdue, 'payment_status'] = '‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏≥‡∏£‡∏∞'
    df.loc[has_payment & ~is_late_payment, 'payment_status'] = '‡∏ä‡∏≥‡∏£‡∏∞‡πÅ‡∏•‡πâ‡∏ß'
    df.loc[has_payment & is_late_payment, 'payment_status'] = '‡∏ä‡∏≥‡∏£‡∏∞‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤'

    # 9. ‡∏•‡πâ‡∏≤‡∏á test ‡πÅ‡∏•‡∏∞ undefined
    df = df[~df['quo_num'].isin(df_test['quo_num'])]
    
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ quo_num ‡πÄ‡∏õ‡πá‡∏ô undefined
    df = df[df['quo_num'] != 'undefined']
    df = df[df['quo_num'].notna()]  # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ quo_num ‡πÄ‡∏õ‡πá‡∏ô null/NaN ‡∏î‡πâ‡∏ß‡∏¢
    
    df = df.rename(columns={'quo_num': 'quotation_num'})
    df['installment_number'] = df['installment_number'].replace({'0': '1'})
    df['installment_number'] = pd.to_numeric(df['installment_number'], errors='coerce')
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö installment_number
    df['installment_number'] = df['installment_number'].where(pd.notna(df['installment_number']), None)
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
    df['due_date'] = pd.to_datetime(df['due_date'], errors='coerce')
    df['due_date'] = df['due_date'].dt.strftime('%Y%m%d')
    df['due_date'] = df['due_date'].where(pd.notna(df['due_date']), None)
    
    df['payment_date'] = pd.to_datetime(df['payment_date'], errors='coerce')
    df['payment_date'] = df['payment_date'].dt.strftime('%Y%m%d')
    df['payment_date'] = df['payment_date'].where(pd.notna(df['payment_date']), None)
    
    # ‚úÖ ‡πÉ‡∏ä‡πâ sanitize_dataframe function ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°
    df = sanitize_dataframe(df.copy())

    # ‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
    final_columns = [
        'quotation_num', 'installment_number', 'due_date', 'installment_amount',
        'payment_date', 'payment_amount', 'late_fee', 'total_paid', 
        'payment_proof', 'payment_status', 'order_number'
    ]
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    available_columns = [col for col in final_columns if col in df.columns]
    missing_columns = [col for col in final_columns if col not in df.columns]
    
    if missing_columns:
        print(f"‚ö†Ô∏è Missing columns: {missing_columns}")
    
    df_final = df[available_columns].copy()
    print(f"üìä Final data ready: {df_final.shape[0]} records")
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN string ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PostgreSQL
    for col in df_final.columns:
        if df_final[col].dtype == 'object':
            df_final[col] = df_final[col].replace(['nan', 'null', 'none', 'undefined', 'NaN', 'NULL', 'NONE', 'UNDEFINED'], None)
    
    # ‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ - ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    for col in df_final.columns:
        if df_final[col].dtype in ['float64', 'int64']:
            # ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö numeric columns
            df_final[col] = df_final[col].where(pd.notna(df_final[col]), None)
        elif df_final[col].dtype == 'object':
            # ‡πÅ‡∏õ‡∏•‡∏á string 'nan', 'null' ‡πÄ‡∏õ‡πá‡∏ô None
            df_final[col] = df_final[col].astype(str)
            nan_mask = df_final[col].str.lower().isin(['nan', 'null', 'none', 'undefined'])
            df_final.loc[nan_mask, col] = None

    print("‚úÖ Data cleaning completed for PostgreSQL")

    return df_final

def sanitize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤ 'NaN', 'null', 'none' string ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô None ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á float NaN ‡πÄ‡∏õ‡πá‡∏ô None - ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
    
    # üîÅ ‡∏™‡∏£‡πâ‡∏≤‡∏á copy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
    df_clean = df.copy()
    
    # üîÅ ‡πÅ‡∏õ‡∏•‡∏á float NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏Å‡πà‡∏≠‡∏ô
    df_clean = df_clean.where(pd.notna(df_clean), None)
    
    # üîÅ ‡∏•‡πâ‡∏≤‡∏á string columns ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
    string_columns = df_clean.select_dtypes(include=['object']).columns
    
    for col in string_columns:
        if col in df_clean.columns:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            non_null_count_before = df_clean[col].notna().sum()
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô string ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            df_clean[col] = df_clean[col].astype(str)
            
            # ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            nan_mask = (
                df_clean[col].str.lower().isin(['nan', 'null', 'none', 'nonetype', 'nulltype', 'undefined']) |
                df_clean[col].str.strip().isin(['', '[null]', 'undefined']) |
                df_clean[col].str.contains('^\\[null\\]$', case=False, na=False) |
                df_clean[col].str.contains('^undefined$', case=False, na=False)
            )
            
            # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤ NaN string ‡∏î‡πâ‡∏ß‡∏¢ None
            df_clean.loc[nan_mask, col] = None
            
            # ‡∏•‡∏ö whitespace ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà None
            mask_not_none = df_clean[col].notna()
            if mask_not_none.any():
                df_clean.loc[mask_not_none, col] = df_clean.loc[mask_not_none, col].str.strip()
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å strip
                nan_mask_after = (
                    df_clean[col].str.lower().isin(['nan', 'null', 'none', '', 'undefined']) |
                    df_clean[col].str.contains('^\\[null\\]$', case=False, na=False) |
                    df_clean[col].str.contains('^undefined$', case=False, na=False)
                )
                df_clean.loc[nan_mask_after, col] = None
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            non_null_count_after = df_clean[col].notna().sum()
            if non_null_count_before != non_null_count_after:
                print(f"‚ö†Ô∏è Column {col}: {non_null_count_before} ‚Üí {non_null_count_after} non-null values")

    # üîÅ ‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏°‡∏µ comma - ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    numeric_cols = ['installment_amount', 'payment_amount', 'total_paid', 'late_fee']
    for col in numeric_cols:
        if col in df_clean.columns:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            non_null_count_before = df_clean[col].notna().sum()
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô numeric column ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if df_clean[col].dtype in ['int64', 'float64']:
                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô numeric ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None
                df_clean[col] = df_clean[col].where(pd.notna(df_clean[col]), None)
                print(f"üîç Column {col} is numeric, converted NaN to None")
                continue
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö comma
            df_clean[col] = df_clean[col].astype(str)
            
            # ‡∏•‡∏ö comma ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà NaN string
            mask_not_nan = ~df_clean[col].str.lower().isin(['nan', 'null', 'none', 'undefined'])
            mask_has_comma = df_clean[col].str.contains(',', na=False)
            mask_to_clean = mask_not_nan & mask_has_comma
            
            if mask_to_clean.any():
                df_clean.loc[mask_to_clean, col] = df_clean.loc[mask_to_clean, col].str.replace(',', '')
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numeric ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
            # ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None
            df_clean[col] = df_clean[col].where(pd.notna(df_clean[col]), None)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            non_null_count_after = df_clean[col].notna().sum()
            if non_null_count_before != non_null_count_after:
                print(f"‚ö†Ô∏è Numeric column {col}: {non_null_count_before} ‚Üí {non_null_count_after} non-null values")

    return df_clean

def clean_records_for_db(records: list) -> list:
    """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î records ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    cleaned_records = []
    
    for i, record in enumerate(records):
        cleaned_record = {}
        for key, value in record.items():
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡πà‡∏≤
            if pd.isna(value):
                cleaned_record[key] = None
            elif isinstance(value, str):
                if value.lower() in ['nan', 'null', 'none', 'undefined', '']:
                    cleaned_record[key] = None
                else:
                    cleaned_record[key] = value.strip()
            elif isinstance(value, (int, float)):
                if pd.isna(value) or value in [np.inf, -np.inf]:
                    cleaned_record[key] = None
                else:
                    cleaned_record[key] = value
            else:
                cleaned_record[key] = value
        
        cleaned_records.append(cleaned_record)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 3 records ‡πÅ‡∏£‡∏Å
        if i < 3:
            print(f"    üîç Record {i} cleaned: {cleaned_record}")
    
    return cleaned_records

@op
def load_installment_data(df: pd.DataFrame):
    table_name = 'fact_installment_payments'
    pk_column = ['quotation_num', 'installment_number']

    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î
    print(f"üîç Before loading - DataFrame shape: {df.shape}")
    print(f"üîç Before loading - Columns: {list(df.columns)}")
    
    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö NaN values ‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î
    print("\nüîç NaN check before loading:")
    for col in df.columns:
        nan_count = df[col].isna().sum()
        if nan_count > 0:
            print(f"  - {col}: {nan_count} NaN values")
    
    # ‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÇ‡∏´‡∏•‡∏î - ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None
    print("\nüßπ Final data cleaning before loading...")
    df_clean = df.copy()
    for col in df_clean.columns:
        if df_clean[col].dtype in ['float64', 'int64']:
            # ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö numeric columns
            nan_count = df_clean[col].isna().sum()
            if nan_count > 0:
                print(f"  üîÑ Converting {nan_count} NaN values to None in {col}")
                df_clean[col] = df_clean[col].where(pd.notna(df_clean[col]), None)
        elif df_clean[col].dtype == 'object':
            # ‡πÅ‡∏õ‡∏•‡∏á string 'nan', 'null' ‡πÄ‡∏õ‡πá‡∏ô None
            df_clean[col] = df_clean[col].astype(str)
            nan_mask = df_clean[col].str.lower().isin(['nan', 'null', 'none', 'undefined'])
            nan_count = nan_mask.sum()
            if nan_count > 0:
                print(f"  üîÑ Converting {nan_count} string NaN values to None in {col}")
                df_clean.loc[nan_mask, col] = None
    
    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
    print("\nüîç NaN check after cleaning:")
    for col in df_clean.columns:
        nan_count = df_clean[col].isna().sum()
        if nan_count > 0:
            print(f"  - {col}: {nan_count} NaN values")
    
    # ‡πÉ‡∏ä‡πâ df_clean ‡πÅ‡∏ó‡∏ô df ‡∏ï‡πà‡∏≠‡πÑ‡∏õ
    df = df_clean
    
    # ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á‡∏ã‡πâ‡∏≥‡∏à‡∏≤‡∏Å DataFrame ‡πÉ‡∏´‡∏°‡πà
    df = df[~df[pk_column].duplicated(keep='first')].copy()
    print(f"üîç After removing duplicates: {len(df)} rows")

    # ‚úÖ ‡∏ß‡∏±‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ 00:00:00)
    today_str = datetime.now().strftime('%Y-%m-%d')

    # ‚úÖ Load ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å PostgreSQL - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ connection
    df_existing = pd.DataFrame()
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            print(f"üîÑ Attempting to load existing data (attempt {retry_count + 1}/{max_retries})...")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á connection ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
            with target_engine.connect() as conn:
                # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ timeout ‡πÅ‡∏•‡∏∞ connection parameters
                conn.execute("SET statement_timeout = 300000")  # 5 minutes
                conn.execute("SET idle_in_transaction_session_timeout = 300000")  # 5 minutes
                
                df_existing = pd.read_sql(
                    f"SELECT * FROM {table_name} WHERE update_at >= '{today_str}'",
                    conn
                )
            
            print(f"üìä Existing data loaded successfully: {len(df_existing)} rows")
            break
            
        except Exception as e:
            retry_count += 1
            print(f"‚ùå Error loading existing data (attempt {retry_count}/{max_retries}): {e}")
            
            if retry_count >= max_retries:
                print("‚ö†Ô∏è Max retries reached. Proceeding without existing data comparison.")
                df_existing = pd.DataFrame()
                break
            
            # ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
            time.sleep(2 ** retry_count)  # Exponential backoff

    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á dtype ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á df ‡πÅ‡∏•‡∏∞ df_existing
    for col in pk_column:
        if col in df.columns and col in df_existing.columns:
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô string ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
            df[col] = df[col].astype(str)
            df_existing[col] = df_existing[col].astype(str)

    # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á composite key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    df['composite_key'] = df[pk_column[0]] + '|' + df[pk_column[1]]
    df_existing['composite_key'] = df_existing[pk_column[0]] + '|' + df_existing[pk_column[1]]

    # ‚úÖ ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    existing_keys = set(df_existing['composite_key'])
    df_to_insert = df[~df['composite_key'].isin(existing_keys)].copy()

    # ‚úÖ ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    common_keys = set(df['composite_key']) & existing_keys
    df_common_new = df[df['composite_key'].isin(common_keys)].copy()
    df_common_old = df_existing[df_existing['composite_key'].isin(common_keys)].copy()

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if not df_common_new.empty and not df_common_old.empty:
        # ‡∏ï‡∏±‡πâ‡∏á index ‡∏î‡πâ‡∏ß‡∏¢ composite_key
        df_common_new.set_index('composite_key', inplace=True)
        df_common_old.set_index('composite_key', inplace=True)

        # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° pk columns ‡πÅ‡∏•‡∏∞ composite_key)
        compare_cols = [col for col in df_common_new.columns if col not in pk_column + ['composite_key']]
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á DataFrame ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        available_cols = [col for col in compare_cols if col in df_common_old.columns]
        
        if available_cols:
            df_common_new_compare = df_common_new[available_cols]
            df_common_old_compare = df_common_old[available_cols]

            # ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
            df_diff_mask = ~(df_common_new_compare.eq(df_common_old_compare, axis=1).all(axis=1))
            df_diff = df_common_new[df_diff_mask].reset_index()
        else:
            df_diff = pd.DataFrame()
    else:
        df_diff = pd.DataFrame()

    print(f"üÜï Insert: {len(df_to_insert)} rows")
    print(f"üîÑ Update: {len(df_diff)} rows")

    # ‚úÖ Load table metadata
    metadata = Table(table_name, MetaData(), autoload_with=target_engine)

    # ‚úÖ Insert - ‡πÉ‡∏ä‡πâ Batch UPSERT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
    if not df_to_insert.empty:
        df_to_insert = df_to_insert.drop(columns=['composite_key'])
        
        # ‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô insert - ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None
        for col in df_to_insert.columns:
            if df_to_insert[col].dtype in ['float64', 'int64']:
                df_to_insert[col] = df_to_insert[col].where(pd.notna(df_to_insert[col]), None)
            elif df_to_insert[col].dtype == 'object':
                df_to_insert[col] = df_to_insert[col].astype(str)
                nan_mask = df_to_insert[col].str.lower().isin(['nan', 'null', 'none', 'undefined'])
                df_to_insert.loc[nan_mask, col] = None
        
        df_to_insert_valid = df_to_insert[df_to_insert[pk_column].notna().all(axis=1)].copy()
        dropped = len(df_to_insert) - len(df_to_insert_valid)
        if dropped > 0:
            print(f"‚ö†Ô∏è Skipped {dropped} rows with null primary keys")
        
        if not df_to_insert_valid.empty:
            print(f"üì§ Inserting {len(df_to_insert_valid)} new records...")
            
            # ‡πÉ‡∏ä‡πâ batch size ‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ connection
            batch_size = 1000
            total_batches = (len(df_to_insert_valid) + batch_size - 1) // batch_size
            
            # ‚úÖ ‡πÉ‡∏ä‡πâ connection ‡πÅ‡∏¢‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ batch
            for i in range(0, len(df_to_insert_valid), batch_size):
                batch_df = df_to_insert_valid.iloc[i:i+batch_size]
                batch_num = (i // batch_size) + 1
                print(f"  üì¶ Processing batch {batch_num}/{total_batches} ({len(batch_df)} records)")
                
                # ‡πÉ‡∏ä‡πâ executemany ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö batch insert
                records = batch_df.to_dict(orient='records')
                
                # ‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î records ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                records = clean_records_for_db(records)
                
                # ‚úÖ ‡πÉ‡∏ä‡πâ connection ‡πÅ‡∏¢‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ batch ‡∏û‡∏£‡πâ‡∏≠‡∏° retry logic
                max_retries = 3
                retry_count = 0
                
                while retry_count < max_retries:
                    try:
                        with target_engine.begin() as conn:
                            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ timeout
                            conn.execute("SET statement_timeout = 300000")  # 5 minutes
                            conn.execute("SET idle_in_transaction_session_timeout = 300000")  # 5 minutes
                            
                            stmt = pg_insert(metadata).values(records)
                            update_columns = {
                                c.name: stmt.excluded[c.name]
                                for c in metadata.columns
                                if c.name not in pk_column
                            }
                            update_columns["update_at"] = datetime.now()  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡πâ update timestamp ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á

                            stmt = stmt.on_conflict_do_update(
                                index_elements=pk_column,
                                set_=update_columns
                            )
                            conn.execute(stmt)
                        
                        print(f"    ‚úÖ Batch {batch_num} inserted successfully")
                        break
                        
                    except Exception as e:
                        retry_count += 1
                        print(f"    ‚ùå Error inserting batch {batch_num} (attempt {retry_count}/{max_retries}): {e}")
                        
                        if retry_count >= max_retries:
                            print(f"    ‚ö†Ô∏è Max retries reached for batch {batch_num}. Skipping this batch.")
                            break
                        
                        # ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
                        time.sleep(2 ** retry_count)  # Exponential backoff

    # ‚úÖ Update - ‡πÉ‡∏ä‡πâ Batch UPSERT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
    if not df_diff.empty:
        df_diff = df_diff.drop(columns=['composite_key'])
        
        # ‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô update - ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None
        for col in df_diff.columns:
            if df_diff[col].dtype in ['float64', 'int64']:
                df_diff[col] = df_diff[col].where(pd.notna(df_diff[col]), None)
            elif df_diff[col].dtype == 'object':
                df_diff[col] = df_diff[col].astype(str)
                nan_mask = df_diff[col].str.lower().isin(['nan', 'null', 'none', 'undefined'])
                df_diff.loc[nan_mask, col] = None
        
        print(f"üìù Updating {len(df_diff)} existing records...")
        
        # ‡πÉ‡∏ä‡πâ batch size ‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ connection
        batch_size = 1000
        total_batches = (len(df_diff) + batch_size - 1) // batch_size
        
        # ‚úÖ ‡πÉ‡∏ä‡πâ connection ‡πÅ‡∏¢‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ batch
        for i in range(0, len(df_diff), batch_size):
            batch_df = df_diff.iloc[i:i+batch_size]
            batch_num = (i // batch_size) + 1
            print(f"  üì¶ Processing update batch {batch_num}/{total_batches} ({len(batch_df)} records)")
            
            # ‡πÉ‡∏ä‡πâ executemany ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö batch update
            records = batch_df.to_dict(orient='records')
            
            # ‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î records ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            records = clean_records_for_db(records)
            
            # ‚úÖ ‡πÉ‡∏ä‡πâ connection ‡πÅ‡∏¢‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ batch ‡∏û‡∏£‡πâ‡∏≠‡∏° retry logic
            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    with target_engine.begin() as conn:
                        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ timeout
                        conn.execute("SET statement_timeout = 300000")  # 5 minutes
                        conn.execute("SET idle_in_transaction_session_timeout = 300000")  # 5 minutes
                        
                        stmt = pg_insert(metadata).values(records)
                        update_columns = {
                            c.name: stmt.excluded[c.name]
                            for c in metadata.columns
                            if c.name not in pk_column
                        }
                        stmt = stmt.on_conflict_do_update(
                            index_elements=pk_column,
                            set_=update_columns
                        )
                        conn.execute(stmt)
                    
                    print(f"    ‚úÖ Update batch {batch_num} completed successfully")
                    break
                    
                except Exception as e:
                    retry_count += 1
                    print(f"    ‚ùå Error updating batch {batch_num} (attempt {retry_count}/{max_retries}): {e}")
                    
                    if retry_count >= max_retries:
                        print(f"    ‚ö†Ô∏è Max retries reached for update batch {batch_num}. Skipping this batch.")
                        break
                    
                    # ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
                    time.sleep(2 ** retry_count)  # Exponential backoff

    print("‚úÖ Insert/update completed.")
    
    # ‚úÖ ‡∏õ‡∏¥‡∏î connections ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô
    try:
        source_engine.dispose()
        task_engine.dispose()
        target_engine.dispose()
        print("‚úÖ All database connections closed successfully")
    except Exception as e:
        print(f"‚ö†Ô∏è Error closing database connections: {e}")

@job
def fact_installment_payments_etl():
    load_installment_data(clean_installment_data(extract_installment_data()))
        
# if __name__ == "__main__":
#     df_raw = extract_installment_data()

#     df_clean = clean_installment_data((df_raw))

#     output_path = "fact_installment_payments.csv"
#     df_clean.to_csv(output_path, index=False, encoding='utf-8-sig')
#     print(f"üíæ Saved to {output_path}")

#     load_installment_data(df_clean)
#     print("üéâ completed! Data upserted to fact_installment_payments.")