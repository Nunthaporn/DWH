from dagster import op, job
import pandas as pd
import numpy as np
import os
import re
import time
import gc
from datetime import datetime, timedelta
from dotenv import load_dotenv
from sqlalchemy import create_engine, MetaData, Table, inspect, text, func, or_
from sqlalchemy.dialects.postgresql import insert as pg_insert
from sqlalchemy.sql.elements import TextClause
from typing import Union, List
from sqlalchemy import or_, func

# ‚úÖ Load env
load_dotenv()

# ‚úÖ DB connections
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance",
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,
    pool_pre_ping=True,
    echo=False
)
task_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance_task",
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,
    pool_pre_ping=True,
    echo=False
)
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance",
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,
    pool_pre_ping=True,
    echo=False,
    connect_args={
        "connect_timeout": 30,
        "application_name": "fact_installment_payments_etl",
        "options": "-c statement_timeout=300000 -c idle_in_transaction_session_timeout=300000"
    }
)

def chunk_list(lst, chunk_size):
    for i in range(0, len(lst), chunk_size):
        yield lst[i:i + chunk_size]

def load_query_raw(engine, query: str) -> pd.DataFrame:
    raw_conn = None
    try:
        raw_conn = engine.raw_connection()
        cursor = raw_conn.cursor()
        cursor.execute(query)
        return pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])
    except Exception as e:
        print(f"‚ùå Error loading query: {e}")
        return pd.DataFrame()
    finally:
        if raw_conn:
            try: raw_conn.close()
            except Exception as e: print(f"‚ö†Ô∏è Error closing: {e}")
        engine.dispose()

def load_data_in_batches(engine, table_name: str, order_numbers: List[str], batch_size=10000) -> pd.DataFrame:
    all_results = []
    for batch in chunk_list(order_numbers, batch_size):
        formatted = "', '".join(batch)
        query = f"SELECT * FROM {table_name} WHERE order_number IN ('{formatted}')"
        df_batch = load_query_raw(engine, query)
        all_results.append(df_batch)
    return pd.concat(all_results, ignore_index=True) if all_results else pd.DataFrame()

@op
def extract_installment_data():
    from sqlalchemy import create_engine

    def create_fresh_engine(engine_url, engine_name):
        try:
            return create_engine(
                engine_url,
                pool_size=1,
                max_overflow=2,
                pool_timeout=30,
                pool_recycle=300,
                pool_pre_ping=True,
                echo=False,
                connect_args={
                    'connect_timeout': 60,
                    'autocommit': False,
                    'charset': 'utf8mb4',
                    'sql_mode': 'STRICT_TRANS_TABLES,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO'
                }
            )
        except Exception as e:
            print(f"‚ùå Error creating {engine_name} engine: {e}")
            return None

    source_url = f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance"
    task_url = f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance_task"

    print("üìä Loading plan data...")
    fresh_source_1 = create_fresh_engine(source_url, "source_1")
    if fresh_source_1:
        try:
            df_plan = pd.read_sql("""
                SELECT quo_num
                FROM fin_system_select_plan
                WHERE datestart BETWEEN '2025-01-01' AND '2025-09-08'
            """, fresh_source_1)
        except Exception as e:
            print(f"‚ùå Error loading plan data: {e}")
            df_plan = pd.DataFrame()
        finally:
            fresh_source_1.dispose()
    else:
        df_plan = pd.DataFrame()

    df_installment = pd.DataFrame()
    if not df_plan.empty:
        print("üìä Loading installment data...")
        fresh_source_2 = create_fresh_engine(source_url, "source_2")
        if fresh_source_2:
            try:
                quo_nums = "','".join(df_plan['quo_num'].dropna().astype(str))
                df_installment = pd.read_sql(f"""
                    SELECT quo_num, money_one, money_two, money_three, money_four,
                           money_five, money_six, money_seven, money_eight, money_nine,
                           money_ten, money_eleven, money_twelve,
                           date_one, date_two, date_three, date_four, date_five,
                           date_six, date_seven, date_eight, date_nine, date_ten,
                           date_eleven, date_twelve, numpay
                    FROM fin_installment
                    WHERE quo_num IN ('{quo_nums}')
                """, fresh_source_2)
            except Exception as e:
                print(f"‚ùå Error loading installment data: {e}")
                df_installment = pd.DataFrame()
            finally:
                fresh_source_2.dispose()

    print("üìä Loading order data...")
    df_order = pd.DataFrame()
    fresh_task_1 = create_fresh_engine(task_url, "task_1")
    if fresh_task_1:
        try:
            with fresh_task_1.begin() as conn:
                df_order = pd.read_sql("""
                    SELECT quo_num, order_number
                    FROM fin_order
                """, conn)
                print(f"‚úÖ Loaded {len(df_order)} order records")
        except Exception as e:
            print(f"‚ùå Error loading order data: {e}")
        finally:
            fresh_task_1.dispose()

    order_list = list(df_order["order_number"].dropna().astype(str).unique())
    print(f"üì¶ Loading bill data in batches... ({len(order_list)} orders)")

    df_finance = pd.DataFrame()
    if not df_order.empty:
        print("üìä Loading finance and bill data...")
        task_engine_finance = create_fresh_engine(task_url, "task_engine_finance")
        df_finance = load_data_in_batches(task_engine_finance, "fin_finance", order_list)
        print(f"‚úÖ Loaded {len(df_finance)} finance records")

    print("üìä Loading bill data...")
    df_bill = pd.DataFrame()
    task_engine_bill = create_fresh_engine(task_url, "task_engine_bill")
    if task_engine_bill:
        try:
            df_bill = load_data_in_batches(task_engine_bill, "fin_bill", order_list)
            print(f"‚úÖ Loaded {len(df_bill)} bill records")
        except Exception as e:
            print(f"‚ùå Error loading bill data: {e}")
        finally:
            task_engine_bill.dispose()

    print("üìä Loading late fee data...")
    df_late_fee = pd.DataFrame()
    fresh_task_3 = create_fresh_engine(task_url, "task_3")
    if fresh_task_3:
        try:
            with fresh_task_3.begin() as conn:
                df_late_fee = pd.read_sql("""
                    SELECT orderNumber, penaltyPay, numPay
                    FROM FIN_Account_AttachSlip_PathImageSlip
                    WHERE checkPay IN ('‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏±‡∏ö', '‡∏Ñ‡πà‡∏≤‡∏á‡∏ß‡∏î/‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏±‡∏ö')
                """, conn)
                print(f"‚úÖ Loaded {len(df_late_fee)} late fee records")
        except Exception as e:
            print(f"‚ùå Error loading late fee data: {e}")
        finally:
            fresh_task_3.dispose()

    print("üìä Loading test data...")
    df_test = pd.DataFrame()
    fresh_source_3 = create_fresh_engine(source_url, "source_3")
    if fresh_source_3:
        try:
            with fresh_source_3.begin() as conn:
                df_test = pd.read_sql("""
                    SELECT quo_num
                    FROM fin_system_select_plan
                    WHERE name IN ('‡∏ó‡∏î‡∏™‡∏≠‡∏ö', 'test')
                """, conn)
                print(f"‚úÖ Loaded {len(df_test)} test records")
        except Exception as e:
            print(f"‚ùå Error loading test data: {e}")
        finally:
            fresh_source_3.dispose()

    print(f"üì¶ Data loaded: plan({df_plan.shape[0]}), installment({df_installment.shape[0]}), order({df_order.shape[0]}), finance({df_finance.shape[0]}), bill({df_bill.shape[0]}), late_fee({df_late_fee.shape[0]}), test({df_test.shape[0]})")

    return df_plan, df_installment, df_order, df_finance, df_bill, df_late_fee, df_test

@op
def clean_installment_data(inputs):
    df_plan, df_inst, df_order, df_fin, df_bill, df_fee, df_test = inputs

    print("üîÑ Processing installment data...")
    
    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö
    print(f"üìä Input data summary:")
    print(f"  - Plan: {df_plan.shape[0]} records, columns: {list(df_plan.columns) if not df_plan.empty else 'empty'}")
    print(f"  - Installment: {df_inst.shape[0]} records, columns: {list(df_inst.columns) if not df_inst.empty else 'empty'}")
    print(f"  - Order: {df_order.shape[0]} records, columns: {list(df_order.columns) if not df_order.empty else 'empty'}")
    print(f"  - Finance: {df_fin.shape[0]} records, columns: {list(df_fin.columns) if not df_fin.empty else 'empty'}")
    print(f"  - Bill: {df_bill.shape[0]} records, columns: {list(df_bill.columns) if not df_bill.empty else 'empty'}")
    print(f"  - Late fee: {df_fee.shape[0]} records, columns: {list(df_fee.columns) if not df_fee.empty else 'empty'}")
    print(f"  - Test: {df_test.shape[0]} records, columns: {list(df_test.columns) if not df_test.empty else 'empty'}")

    # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏á‡∏ß‡∏î + ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    if df_inst.empty:
        print("‚ö†Ô∏è Installment DataFrame is empty. Creating empty combined records.")
        df_combined = pd.DataFrame(columns=['quo_num', 'numpay', 'installment_period', 'installment_amount', 'due_date', 'installment_number'])
    elif 'numpay' not in df_inst.columns:
        print("‚ö†Ô∏è Installment DataFrame does not have 'numpay' column. Creating empty combined records.")
        df_combined = pd.DataFrame(columns=['quo_num', 'numpay', 'installment_period', 'installment_amount', 'due_date', 'installment_number'])
    elif 'quo_num' not in df_inst.columns:
        print("‚ö†Ô∏è Installment DataFrame does not have 'quo_num' column. Creating empty combined records.")
        df_combined = pd.DataFrame(columns=['quo_num', 'numpay', 'installment_period', 'installment_amount', 'due_date', 'installment_number'])
    else:
        df_inst['numpay'] = pd.to_numeric(df_inst['numpay'], errors='coerce')
        df_filtered = df_inst[df_inst['numpay'].notna() & (df_inst['numpay'] > 0)]

        money_cols = [f'money_{n}' for n in ['one', 'two', 'three', 'four', 'five', 'six',
                                             'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve']]
        date_cols = [f'date_{n}' for n in ['one', 'two', 'three', 'four', 'five', 'six',
                                           'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve']]

        # ‚úÖ ‡∏•‡∏î debug prints ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏Ñ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        print(f"üìä Processing {df_filtered.shape[0]} installment records")

        df_money = df_filtered.melt(id_vars=['quo_num', 'numpay'], value_vars=money_cols,
                                     var_name='installment_period', value_name='installment_amount')
        df_date = df_filtered.melt(id_vars=['quo_num', 'numpay'], value_vars=date_cols,
                                    var_name='due_date_period', value_name='due_date')

        df_combined = pd.concat([df_money.reset_index(drop=True), df_date['due_date']], axis=1)
        df_combined['installment_number'] = df_combined.groupby('quo_num').cumcount() + 1
        df_combined = df_combined[df_combined['installment_number'] <= df_combined['numpay']]
        df_combined = df_combined.sort_values(by=['quo_num', 'due_date'])
        df_combined['installment_number'] = df_combined.groupby('quo_num').cumcount() + 1

        print(f"üìä Combined {df_combined.shape[0]} installment records")

    # 2. ‡∏ú‡∏π‡∏Å order_number
    if df_order.empty:
        print("‚ö†Ô∏è Order DataFrame is empty. Creating empty joined records.")
        df_join = df_combined.copy()
        df_join['order_number'] = None
    elif 'quo_num' not in df_order.columns:
        print("‚ö†Ô∏è Order DataFrame does not have 'quo_num' column. Creating empty joined records.")
        df_join = df_combined.copy()
        df_join['order_number'] = None
    elif 'order_number' not in df_order.columns:
        print("‚ö†Ô∏è Order DataFrame does not have 'order_number' column. Creating empty joined records.")
        df_join = df_combined.copy()
        df_join['order_number'] = None
    else:
        df_join = pd.merge(df_combined, df_order, on='quo_num', how='left')
        print(f"üìä Joined with orders: {df_join.shape[0]} records")

    # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ä‡∏≥‡∏£‡∏∞
    num_to_name = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight',
                   'nine', 'ten', 'eleven', 'twelve']
    
    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ df_fin ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if df_fin.empty:
        print("‚ö†Ô∏è Finance DataFrame is empty. Creating empty payment records.")
        df_payment = pd.DataFrame(columns=['order_number', 'payment_amount', 'payment_date', 'installment_number'])
    elif 'numpay' not in df_fin.columns:
        print("‚ö†Ô∏è Finance DataFrame does not have 'numpay' column. Creating empty payment records.")
        df_payment = pd.DataFrame(columns=['order_number', 'payment_amount', 'payment_date', 'installment_number'])
    elif 'order_number' not in df_fin.columns:
        print("‚ö†Ô∏è Finance DataFrame does not have 'order_number' column. Creating empty payment records.")
        df_payment = pd.DataFrame(columns=['order_number', 'payment_amount', 'payment_date', 'installment_number'])
    else:
        df_fin['numpay'] = pd.to_numeric(df_fin['numpay'], errors='coerce')
        df_fin = df_fin[df_fin['numpay'].notna() & (df_fin['numpay'] > 0)]

        print(f"üìä Processing {df_fin.shape[0]} finance records")

        # ‡πÉ‡∏ä‡πâ vectorized operations ‡πÅ‡∏ó‡∏ô iterrows()
        rows_list = []
        for i, sfx in enumerate(num_to_name, start=1):
            money_col = f'moneypay_{sfx}'
            date_col = f'datepay_{sfx}'
            
            # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if money_col not in df_fin.columns or date_col not in df_fin.columns:
                print(f"‚ö†Ô∏è Missing columns {money_col} or {date_col} in finance data. Skipping installment {i}.")
                continue
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ installment
            temp_df = df_fin[['order_number', money_col, date_col]].copy()
            temp_df['installment_number'] = i
            temp_df['payment_amount'] = temp_df[money_col]
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
            temp_df['raw_date'] = temp_df[date_col].astype(str)
            temp_df['payment_date'] = pd.to_datetime(
                temp_df['raw_date'].str.extract(r'(\d{4}-\d{1,2}-\d{1,2})')[0], 
                errors='coerce'
            )
            
            # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏µ 2026 ‡πÄ‡∏õ‡πá‡∏ô 2025 - ‡πÉ‡∏ä‡πâ vectorized operations
            mask_2026 = temp_df['payment_date'].dt.year == 2026
            if mask_2026.any():
                # ‡πÉ‡∏ä‡πâ pd.to_datetime() ‡πÅ‡∏ó‡∏ô apply
                temp_df.loc[mask_2026, 'payment_date'] = pd.to_datetime(
                    temp_df.loc[mask_2026, 'payment_date'].dt.strftime('2025-%m-%d'),
                    errors='coerce'
                )
            
            rows_list.append(temp_df[['order_number', 'payment_amount', 'payment_date', 'installment_number']])

        df_payment = pd.concat(rows_list, ignore_index=True)
        print(f"üìä Created {df_payment.shape[0]} payment records")

    # 4. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° payment proof
    if df_bill.empty:
        print("‚ö†Ô∏è Bill DataFrame is empty. Creating empty proof records.")
        df_proof = pd.DataFrame(columns=['order_number', 'installment_number', 'payment_proof'])
    elif 'order_number' not in df_bill.columns:
        print("‚ö†Ô∏è Bill DataFrame does not have 'order_number' column. Creating empty proof records.")
        df_proof = pd.DataFrame(columns=['order_number', 'installment_number', 'payment_proof'])
    else:
        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå bill_receipt ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        bill_receipt_cols = [f'bill_receipt{i if i > 1 else ""}' for i in range(1, 13)]
        missing_cols = [col for col in bill_receipt_cols if col not in df_bill.columns]
        if missing_cols:
            print(f"‚ö†Ô∏è Bill DataFrame missing columns: {missing_cols}. Creating empty proof records.")
            df_proof = pd.DataFrame(columns=['order_number', 'installment_number', 'payment_proof'])
        else:
            df_proof = df_bill.melt(id_vars=['order_number'],
                value_vars=[f'bill_receipt{i if i > 1 else ""}' for i in range(1, 13)],
                value_name='payment_proof')
            df_proof = df_proof[df_proof['payment_proof'].notna()].reset_index()
            df_proof['installment_number'] = df_proof.groupby('order_number').cumcount() + 1
            df_proof = df_proof[['order_number', 'installment_number', 'payment_proof']]

            print(f"üìä Created {df_proof.shape[0]} proof records")

    # 5. ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    df = pd.merge(df_join, df_payment, on=['order_number', 'installment_number'], how='left')
    df = pd.merge(df, df_proof, on=['order_number', 'installment_number'], how='left')

    print(f"üìä Final merged data: {df.shape[0]} records")

    # 6. ‡πÄ‡∏û‡∏¥‡πà‡∏° late_fee
    if df_fee.empty:
        print("‚ö†Ô∏è Late fee DataFrame is empty. Adding empty late_fee column.")
        df['late_fee'] = 0
    elif 'orderNumber' not in df_fee.columns or 'penaltyPay' not in df_fee.columns or 'numPay' not in df_fee.columns:
        print("‚ö†Ô∏è Late fee DataFrame missing required columns. Adding empty late_fee column.")
        df['late_fee'] = 0
    else:
        df_fee = df_fee.rename(columns={
            'orderNumber': 'order_number',
            'penaltyPay': 'late_fee',
            'numPay': 'installment_number'
        })
        df_fee = df_fee.drop_duplicates()
        df['installment_number'] = pd.to_numeric(df['installment_number'], errors='coerce')
        df_fee['installment_number'] = pd.to_numeric(df_fee['installment_number'], errors='coerce')
        df = pd.merge(df, df_fee, on=['order_number', 'installment_number'], how='left')
        df['late_fee'] = df['late_fee'].fillna(0).astype(int)
    
    # 7. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì total_paid - ‡πÉ‡∏ä‡πâ vectorized operations ‡πÅ‡∏ó‡∏ô apply
    # ‚úÖ ‡∏•‡∏ö comma ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numeric
    if df['payment_amount'].dtype == 'object':
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö comma
        df['payment_amount'] = df['payment_amount'].astype(str)
        
        # ‡∏•‡∏ö comma ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà NaN string
        mask_not_nan = ~df['payment_amount'].str.lower().isin(['nan', 'null', 'none', 'undefined'])
        df.loc[mask_not_nan, 'payment_amount'] = df.loc[mask_not_nan, 'payment_amount'].str.replace(',', '')
    
    if df['installment_amount'].dtype == 'object':
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö comma
        df['installment_amount'] = df['installment_amount'].astype(str)
        
        # ‡∏•‡∏ö comma ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà NaN string
        mask_not_nan = ~df['installment_amount'].str.lower().isin(['nan', 'null', 'none', 'undefined'])
        df.loc[mask_not_nan, 'installment_amount'] = df.loc[mask_not_nan, 'installment_amount'].str.replace(',', '')
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numeric ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ NaN
    df['payment_amount'] = pd.to_numeric(df['payment_amount'], errors='coerce')
    df['payment_amount'] = df['payment_amount'].where(pd.notna(df['payment_amount']), None)
    
    df['installment_amount'] = pd.to_numeric(df['installment_amount'], errors='coerce')
    df['late_fee'] = pd.to_numeric(df['late_fee'], errors='coerce').fillna(0)
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None
    df['installment_amount'] = df['installment_amount'].where(pd.notna(df['installment_amount']), None)
    df['late_fee'] = df['late_fee'].where(pd.notna(df['late_fee']), None)
    
    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Infinity ‡∏´‡∏£‡∏∑‡∏≠ -Infinity
    df['payment_amount'] = df['payment_amount'].replace([np.inf, -np.inf], np.nan)
    df['installment_amount'] = df['installment_amount'].replace([np.inf, -np.inf], np.nan)
    df['late_fee'] = df['late_fee'].replace([np.inf, -np.inf], 0)
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Infinity
    df['payment_amount'] = df['payment_amount'].where(pd.notna(df['payment_amount']), None)
    df['installment_amount'] = df['installment_amount'].where(pd.notna(df['installment_amount']), None)
    df['late_fee'] = df['late_fee'].where(pd.notna(df['late_fee']), None)
    
    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì total_paid ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
    df['total_paid'] = np.where(
        df['late_fee'] == 0,
        df['installment_amount'].fillna(0),
        # ‡∏ñ‡πâ‡∏≤ late_fee != 0 ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ payment_amount + late_fee ‡∏´‡∏£‡∏∑‡∏≠ installment_amount + late_fee
        np.where(
            df['payment_amount'].notna(),
            df['payment_amount'].fillna(0) + df['late_fee'],
            df['installment_amount'].fillna(0) + df['late_fee']
        )
    )
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö total_paid
    df['total_paid'] = df['total_paid'].where(pd.notna(df['total_paid']), None)

    print(f"üìä Calculated total_paid for {df['total_paid'].notna().sum()} records")

    # 8. payment_status
    df['due_date'] = pd.to_datetime(df['due_date'], errors='coerce')
    df['payment_date'] = pd.to_datetime(df['payment_date'], errors='coerce')
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ï‡πà‡∏≤‡∏á‡πÜ
    no_payment = df['payment_amount'].isna() & df['payment_date'].isna() & df['payment_proof'].isna()
    has_payment = df['payment_amount'].notna() | df['payment_proof'].notna()
    has_due_date = df['due_date'].notna()
    has_payment_date = df['payment_date'].notna()
    is_overdue = has_due_date & (datetime.now().date() > df['due_date'].dt.date)
    is_late_payment = has_payment_date & has_due_date & (df['payment_date'].dt.date > df['due_date'].dt.date)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î payment_status
    df['payment_status'] = '‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ä‡∏≥‡∏£‡∏∞'  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    df.loc[no_payment & is_overdue, 'payment_status'] = '‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏≥‡∏£‡∏∞'
    df.loc[has_payment & ~is_late_payment, 'payment_status'] = '‡∏ä‡∏≥‡∏£‡∏∞‡πÅ‡∏•‡πâ‡∏ß'
    df.loc[has_payment & is_late_payment, 'payment_status'] = '‡∏ä‡∏≥‡∏£‡∏∞‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤'

    # 9. ‡∏•‡πâ‡∏≤‡∏á test ‡πÅ‡∏•‡∏∞ undefined
    if not df_test.empty and 'quo_num' in df_test.columns:
        df = df[~df['quo_num'].isin(df_test['quo_num'])]
        print(f"üìä Filtered out {len(df_test)} test records")
    else:
        print("‚ö†Ô∏è Test DataFrame is empty or missing 'quo_num' column. Skipping test record filtering.")
    
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ quo_num ‡πÄ‡∏õ‡πá‡∏ô undefined
    df = df[df['quo_num'] != 'undefined']
    df = df[df['quo_num'].notna()]  # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ quo_num ‡πÄ‡∏õ‡πá‡∏ô null/NaN ‡∏î‡πâ‡∏ß‡∏¢
    
    df = df.rename(columns={'quo_num': 'quotation_num'})
    df['installment_number'] = df['installment_number'].replace({'0': '1'})
    df['installment_number'] = pd.to_numeric(df['installment_number'], errors='coerce')
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö installment_number
    df['installment_number'] = df['installment_number'].where(pd.notna(df['installment_number']), None)
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
    df['due_date'] = pd.to_datetime(df['due_date'], errors='coerce')
    df['due_date'] = df['due_date'].dt.strftime('%Y%m%d')
    df['due_date'] = df['due_date'].where(pd.notna(df['due_date']), None)
    
    df['payment_date'] = pd.to_datetime(df['payment_date'], errors='coerce')
    df['payment_date'] = df['payment_date'].dt.strftime('%Y%m%d')
    df['payment_date'] = df['payment_date'].where(pd.notna(df['payment_date']), None)
    
    # ‚úÖ ‡πÉ‡∏ä‡πâ sanitize_dataframe function ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°
    df = sanitize_dataframe(df.copy())

    # ‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
    final_columns = [
        'quotation_num', 'installment_number', 'due_date', 'installment_amount',
        'payment_date', 'payment_amount', 'late_fee', 'total_paid', 
        'payment_proof', 'payment_status', 'order_number'
    ]
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    available_columns = [col for col in final_columns if col in df.columns]
    missing_columns = [col for col in final_columns if col not in df.columns]
    
    if missing_columns:
        print(f"‚ö†Ô∏è Missing columns: {missing_columns}")
    
    df_final = df[available_columns].copy()
    print(f"üìä Final data ready: {df_final.shape[0]} records")
    
    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á NaN string ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PostgreSQL
    for col in df_final.columns:
        if df_final[col].dtype == 'object':
            df_final[col] = df_final[col].replace(['nan', 'null', 'none', 'undefined', 'NaN', 'NULL', 'NONE', 'UNDEFINED'], None)
    
    # ‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ - ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    for col in df_final.columns:
        if df_final[col].dtype in ['float64', 'int64']:
            # ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö numeric columns
            df_final[col] = df_final[col].where(pd.notna(df_final[col]), None)
        elif df_final[col].dtype == 'object':
            # ‡πÅ‡∏õ‡∏•‡∏á string 'nan', 'null' ‡πÄ‡∏õ‡πá‡∏ô None
            df_final[col] = df_final[col].astype(str)
            nan_mask = df_final[col].str.lower().isin(['nan', 'null', 'none', 'undefined'])
            df_final.loc[nan_mask, col] = None

    print("‚úÖ Data cleaning completed for PostgreSQL")

    return df_final

def sanitize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤ 'NaN', 'null', 'none' string ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô None ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á float NaN ‡πÄ‡∏õ‡πá‡∏ô None - ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
    
    # üîÅ ‡∏™‡∏£‡πâ‡∏≤‡∏á copy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
    df_clean = df.copy()
    
    # üîÅ ‡πÅ‡∏õ‡∏•‡∏á float NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡∏Å‡πà‡∏≠‡∏ô
    df_clean = df_clean.where(pd.notna(df_clean), None)
    
    # üîÅ ‡∏•‡πâ‡∏≤‡∏á string columns ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
    string_columns = df_clean.select_dtypes(include=['object']).columns
    
    for col in string_columns:
        if col in df_clean.columns:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            non_null_count_before = df_clean[col].notna().sum()
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô string ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            df_clean[col] = df_clean[col].astype(str)
            
            # ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            nan_mask = (
                df_clean[col].str.lower().isin(['nan', 'null', 'none', 'nonetype', 'nulltype', 'undefined']) |
                df_clean[col].str.strip().isin(['', '[null]', 'undefined']) |
                df_clean[col].str.contains('^\\[null\\]$', case=False, na=False) |
                df_clean[col].str.contains('^undefined$', case=False, na=False)
            )
            
            # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤ NaN string ‡∏î‡πâ‡∏ß‡∏¢ None
            df_clean.loc[nan_mask, col] = None
            
            # ‡∏•‡∏ö whitespace ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà None
            mask_not_none = df_clean[col].notna()
            if mask_not_none.any():
                df_clean.loc[mask_not_none, col] = df_clean.loc[mask_not_none, col].str.strip()
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å strip
                nan_mask_after = (
                    df_clean[col].str.lower().isin(['nan', 'null', 'none', '', 'undefined']) |
                    df_clean[col].str.contains('^\\[null\\]$', case=False, na=False) |
                    df_clean[col].str.contains('^undefined$', case=False, na=False)
                )
                df_clean.loc[nan_mask_after, col] = None
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            non_null_count_after = df_clean[col].notna().sum()
            if non_null_count_before != non_null_count_after:
                print(f"‚ö†Ô∏è Column {col}: {non_null_count_before} ‚Üí {non_null_count_after} non-null values")

    # üîÅ ‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏°‡∏µ comma - ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    numeric_cols = ['installment_amount', 'payment_amount', 'total_paid', 'late_fee']
    for col in numeric_cols:
        if col in df_clean.columns:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            non_null_count_before = df_clean[col].notna().sum()
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô numeric column ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if df_clean[col].dtype in ['int64', 'float64']:
                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô numeric ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None
                df_clean[col] = df_clean[col].where(pd.notna(df_clean[col]), None)
                print(f"üîç Column {col} is numeric, converted NaN to None")
                continue
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö comma
            df_clean[col] = df_clean[col].astype(str)
            
            # ‡∏•‡∏ö comma ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà NaN string
            mask_not_nan = ~df_clean[col].str.lower().isin(['nan', 'null', 'none', 'undefined'])
            mask_has_comma = df_clean[col].str.contains(',', na=False)
            mask_to_clean = mask_not_nan & mask_has_comma
            
            if mask_to_clean.any():
                df_clean.loc[mask_to_clean, col] = df_clean.loc[mask_to_clean, col].str.replace(',', '')
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numeric ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
            # ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None
            df_clean[col] = df_clean[col].where(pd.notna(df_clean[col]), None)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            non_null_count_after = df_clean[col].notna().sum()
            if non_null_count_before != non_null_count_after:
                print(f"‚ö†Ô∏è Numeric column {col}: {non_null_count_before} ‚Üí {non_null_count_after} non-null values")

    return df_clean

def clean_records_for_db(records: list) -> list:
    """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î records ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    cleaned_records = []
    
    for i, record in enumerate(records):
        cleaned_record = {}
        for key, value in record.items():
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡πà‡∏≤
            if pd.isna(value):
                cleaned_record[key] = None
            elif isinstance(value, str):
                if value.lower() in ['nan', 'null', 'none', 'undefined', '']:
                    cleaned_record[key] = None
                else:
                    cleaned_record[key] = value.strip()
            elif isinstance(value, (int, float)):
                if pd.isna(value) or value in [np.inf, -np.inf]:
                    cleaned_record[key] = None
                else:
                    cleaned_record[key] = value
            else:
                cleaned_record[key] = value
        
        cleaned_records.append(cleaned_record)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 3 records ‡πÅ‡∏£‡∏Å
        if i < 3:
            print(f"    üîç Record {i} cleaned: {cleaned_record}")
    
    return cleaned_records

def create_fresh_target_engine():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á fresh target engine ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PostgreSQL"""
    target_url = (
        f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:"
        f"{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:"
        f"{os.getenv('DB_PORT_test')}/fininsurance"
    )
    try:
        return create_engine(
            target_url,
            pool_size=5,
            max_overflow=10,
            pool_timeout=30,
            pool_recycle=1800,
            pool_pre_ping=True,
            echo=False,
            connect_args={
                "connect_timeout": 30,
                "application_name": "fact_installment_payments_etl",
                "options": "-c statement_timeout=300000 -c idle_in_transaction_session_timeout=300000"
            }
        )
    except Exception as e:
        print(f"‚ùå Error creating fresh target engine: {e}")
        return None


def chunker(df: pd.DataFrame, size: int = 5000):
    for i in range(0, len(df), size):
        yield df.iloc[i:i+size]


def clean_records_for_db(records: list[dict]) -> list[dict]:
    """‡πÅ‡∏õ‡∏•‡∏á NaN/NaT ‡πÅ‡∏•‡∏∞ numpy scalar ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏ô‡∏¥‡∏î Python + None ‡∏ó‡∏µ‡πà DB ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ"""
    def to_native(v):
        if v is None:
            return None
        if isinstance(v, float) and (np.isnan(v) if isinstance(v, float) else False):
            return None
        if pd.isna(v):
            return None
        # numpy scalar ‚Üí python
        if isinstance(v, (np.integer, )):
            return int(v)
        if isinstance(v, (np.floating, )):
            return float(v)
        if isinstance(v, (np.bool_, )):
            return bool(v)
        return v

    out = []
    for r in records:
        out.append({k: to_native(v) for k, v in r.items()})
    return out


def build_conditional_upsert(table, pk_cols: list[str], update_allow_cols: list[str], records: list[dict]):
    """
    UPSERT:
      - INSERT ‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡∏°‡πà
      - UPDATE ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡πà‡∏≤ '‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á ‡πÜ' (NULL-safe) ‡∏î‡πâ‡∏ß‡∏¢ IS DISTINCT FROM
      - ‡πÑ‡∏°‡πà‡∏ó‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢ NULL: COALESCE(EXCLUDED.col, table.col)
      - update_at = now() ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô UPDATE ‡∏à‡∏£‡∏¥‡∏á (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ WHERE)
    """
    stmt = pg_insert(table).values(records)
    excluded = stmt.excluded

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà NULL ‡∏°‡∏¥‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°
    set_map = {
        col: func.coalesce(getattr(excluded, col), getattr(table.c, col))
        for col in update_allow_cols
    }
    if 'update_at' in table.c:
        set_map['update_at'] = func.now()

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠ "‡∏Ñ‡πà‡∏≤‡∏´‡∏•‡∏±‡∏á COALESCE" ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (NULL-safe)
    change_conds = [
        func.coalesce(getattr(excluded, col), getattr(table.c, col))\
            .is_distinct_from(getattr(table.c, col))
        for col in update_allow_cols
    ]
    where_clause = or_(*change_conds) if change_conds else text("FALSE")

    return stmt.on_conflict_do_update(
        index_elements=pk_cols,  # ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ constraint="fact_installment_payments_unique" ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏ô‡∏™‡πÄ‡∏ï‡∏£‡∏ô‡∏ï‡πå
        set_=set_map,
        where=where_clause
    )

# ----------------------- Main OP -----------------------

@op
def load_installment_data(df: pd.DataFrame):
    table_name = 'fact_installment_payments'
    pk_column = ['quotation_num', 'installment_number']

    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î
    print(f"üîç Before loading - DataFrame shape: {df.shape}")
    print(f"üîç Before loading - Columns: {list(df.columns)}")

    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö NaN values ‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î (log ‡∏™‡∏±‡πâ‡∏ô ‡πÜ)
    print("\nüîç NaN check before loading:")
    for col in df.columns:
        nan_count = df[col].isna().sum()
        if nan_count > 0:
            print(f"  - {col}: {nan_count} NaN values")

    # ‚úÖ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
    print("\nüßπ Final data cleaning before loading...")
    df_clean = df.copy()

    # ‡πÅ‡∏õ‡∏•‡∏á object 'nan'/'null'/'none'/'undefined' ‚Üí None
    for col in df_clean.columns:
        if df_clean[col].dtype == 'object':
            s = df_clean[col].astype(str)
            mask = s.str.lower().isin(['nan', 'null', 'none', 'undefined'])
            if mask.any():
                print(f"  üîÑ Converting {mask.sum()} string NaN-like values to None in {col}")
                df_clean.loc[mask, col] = None

    # ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏Ñ‡∏µ‡∏¢‡πå‡∏ú‡∏™‡∏°‡∏ß‡πà‡∏≤‡∏á
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏ô‡∏¥‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏±‡∏î‡∏ó‡∏¥‡πâ‡∏á‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô NaN/None
    for col in pk_column:
        if col not in df_clean.columns:
            print(f"‚ùå Missing primary key column in DataFrame: {col}")
            print(f"Available columns: {list(df_clean.columns)}")
            return

    df_clean = df_clean[df_clean[pk_column].notna().all(axis=1)].copy()
    if df_clean.empty:
        print("‚ö†Ô∏è DataFrame is empty after filtering null primary key values. No data to process.")
        return

    # ‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏≠‡∏á (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏µ‡∏¢‡πå‡∏ú‡∏™‡∏°)
    before = len(df_clean)
    df_clean = df_clean.drop_duplicates(subset=pk_column, keep='last').copy()
    print(f"üîç After removing duplicate composite keys in batch: {before} -> {len(df_clean)} rows")

    # ‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏´‡∏•‡∏î
    fresh_target_ops = create_fresh_target_engine()
    if not fresh_target_ops:
        print("‚ùå Failed to create fresh target engine. Exiting.")
        return

    table = Table(table_name, MetaData(), autoload_with=fresh_target_ops)

    # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô PK ‡πÅ‡∏•‡∏∞ audit)
    update_cols = [
        c.name for c in table.columns
        if c.name not in pk_column + ['create_at', 'update_at']
    ]

    print("üì§ Loading with conditional UPSERT (insert new, update only when changed)...")

    total = len(df_clean)
    done = 0
    batch_size = 5000

    try:
        for batch in chunker(df_clean, batch_size):
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÉ‡∏´‡πâ DB-friendly
            records = clean_records_for_db(batch.to_dict(orient='records'))

            # ‡πÄ‡∏ï‡∏¥‡∏° create_at ‡∏ï‡∏≠‡∏ô INSERT (‡∏ñ‡πâ‡∏≤‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ default)
            # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: func.now() ‡πÄ‡∏õ‡πá‡∏ô SQL expression ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö executemany
            if 'create_at' in table.c:
                for r in records:
                    if 'create_at' not in r or r['create_at'] in (None, ''):
                        r['create_at'] = func.now()

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á statement UPSERT ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ WHERE ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà ‚Äú‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á‚Äù
            stmt = build_conditional_upsert(
                table=table,
                pk_cols=pk_column,
                update_allow_cols=update_cols,
                records=records
            )

            # ‡∏¢‡∏¥‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏£‡∏≤‡∏ô‡πÅ‡∏ã‡∏Å‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Ç‡∏≠‡∏á batch
            max_retries = 3
            attempt = 0
            while attempt < max_retries:
                attempt += 1
                try:
                    with fresh_target_ops.begin() as conn:
                        conn.execute(text("SET statement_timeout = 300000"))
                        conn.execute(text("SET idle_in_transaction_session_timeout = 300000"))
                        conn.execute(stmt)
                    break
                except Exception as e:
                    print(f"    ‚ùå Error upserting batch (attempt {attempt}/{max_retries}): {e}")
                    if attempt >= max_retries:
                        print("    ‚ö†Ô∏è Max retries reached for this batch. Skipping.")
                    else:
                        time.sleep(2 ** attempt)

            done += len(batch)
            print(f"   ‚úÖ upserted {done}/{total}")

        print("‚úÖ Insert/Update completed (conditional upsert)")

    finally:
        try:
            fresh_target_ops.dispose()
            print("‚úÖ Fresh target engine disposed successfully")
        except Exception as e:
            print(f"‚ö†Ô∏è Error disposing fresh target engine: {e}")
    
    # ‚úÖ ‡∏õ‡∏¥‡∏î fresh target engine ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô
    try:
        if 'fresh_target_ops' in locals() and fresh_target_ops:
            fresh_target_ops.dispose()
            print("‚úÖ Fresh target engine disposed successfully")
    except Exception as e:
        print(f"‚ö†Ô∏è Error disposing fresh target engine: {e}")
    
    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏¥‡∏î engines ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏õ‡∏¥‡∏î
    engines_to_check = []
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö engines ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô local scope
    for var_name in ['fresh_target', 'fresh_target_batch', 'fresh_target_update']:
        if var_name in locals():
            engine = locals()[var_name]
            if engine is not None:
                engines_to_check.append((var_name, engine))
    
    for engine_name, engine in engines_to_check:
        try:
            engine.dispose()
            print(f"‚úÖ {engine_name} engine disposed successfully")
        except Exception as dispose_error:
            print(f"‚ö†Ô∏è {engine_name} engine disposal failed: {dispose_error}")
    
    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏¥‡∏î engines ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏õ‡∏¥‡∏î‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö engines ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô local scope
        for var_name in ['fresh_target', 'fresh_target_batch', 'fresh_target_update', 'fresh_target_ops']:
            if var_name in locals():
                engine = locals()[var_name]
                if engine is not None:
                    try:
                        engine.dispose()
                        print(f"‚úÖ {var_name} engine disposed successfully")
                    except Exception as dispose_error:
                        print(f"‚ö†Ô∏è {var_name} engine disposal failed: {dispose_error}")
    except Exception as e:
        print(f"‚ö†Ô∏è Error during final engine cleanup: {e}")

@job
def fact_installment_payments_etl():
    load_installment_data(clean_installment_data(extract_installment_data()))
        
if __name__ == "__main__":
    df_raw = extract_installment_data()

    df_clean = clean_installment_data((df_raw))

    output_path = "fact_installment_payments.csv"
    df_clean.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"üíæ Saved to {output_path}")

    # load_installment_data(df_clean)
    print("üéâ completed! Data upserted to fact_installment_payments.")