from dagster import op, job
import pandas as pd
import numpy as np
import os
import time
import random
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from sqlalchemy.exc import OperationalError
from datetime import datetime

# ‚úÖ Load .env
load_dotenv()

# ‚úÖ DB Connections
# Source: MariaDB
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance"
)

# Target: PostgreSQL
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance"
)

@op
def extract_quotation_idcus():
    df = pd.read_sql("SELECT quo_num, id_cus FROM fin_system_select_plan", source_engine)
    df = df.rename(columns={'quo_num': 'quotation_num'})
    # üîß normalize key ‡πÉ‡∏ô‡∏ù‡∏±‡πà‡∏á pandas ‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô
    df['quotation_num'] = df['quotation_num'].astype(str).str.strip()
    df['id_cus'] = df['id_cus'].astype(str).str.strip()
    print(f"üì¶ df_plan: {df.shape}")
    return df

@op
def extract_fact_sales_quotation():
    # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà agent_id ‡∏¢‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏á
    df = pd.read_sql("SELECT quotation_num, payment_plan_id, agent_id FROM fact_sales_quotation WHERE agent_id IS NULL", target_engine)
    # üîß normalize key
    df['quotation_num'] = df['quotation_num'].astype(str).str.strip()
    print(f"üì¶ df_sales: {df.shape}")
    return df

@op
def extract_dim_agent():
    # dim_agent: ‡∏°‡∏µ agent_id (string/id_cus) ‡πÅ‡∏•‡∏∞ id_contact (uuid)
    df = pd.read_sql("SELECT agent_id AS id_cus, id_contact FROM dim_agent", target_engine)
    df['id_cus'] = df['id_cus'].astype(str).str.strip()
    print(f"üì¶ df_agent: {df.shape}")
    return df

@op
def join_and_clean_agent_data(df_plan: pd.DataFrame, df_sales: pd.DataFrame, df_agent: pd.DataFrame):
    # plan + sales (‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ quotation ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô sales)
    df_merge = pd.merge(df_plan, df_sales, on='quotation_num', how='right')
    # join ‡∏´‡∏≤ id_contact (uuid) ‡∏î‡πâ‡∏ß‡∏¢ id_cus
    df_merge = pd.merge(df_merge, df_agent, on='id_cus', how='inner')  # id_contact ‡∏°‡∏≤‡∏à‡∏≤‡∏Å dim_agent
    df_merge = df_merge.rename(columns={'id_contact': 'agent_uuid'})
    df_merge = df_merge[['quotation_num', 'payment_plan_id', 'agent_uuid']]

    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
    df_merge = df_merge.dropna(subset=['quotation_num', 'agent_uuid'])
    df_merge = df_merge.drop_duplicates(subset=['quotation_num'])
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô str ‡∏ä‡∏±‡∏î ‡πÜ
    df_merge['quotation_num'] = df_merge['quotation_num'].astype(str).str.strip()

    print(f"üì¶ df_merge(clean): {df_merge.shape}")
    return df_merge

@op
def update_agent_id(df_selected: pd.DataFrame, require_payment_plan_null: bool = True):
    if df_selected.empty:
        print("‚ÑπÔ∏è No rows to update (df_selected is empty).")
        return

    # ‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏∏‡∏î
    df_selected = df_selected.dropna(subset=["quotation_num", "agent_uuid"]).drop_duplicates(subset=["quotation_num"])

    with target_engine.begin() as conn:
        # ‡∏•‡∏î‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÅ‡∏Æ‡∏á‡∏Ñ‡πå‡πÅ‡∏•‡∏∞ deadlock
        conn.exec_driver_sql("SET lock_timeout = '3s'")
        conn.exec_driver_sql("SET deadlock_timeout = '200ms'")
        conn.exec_driver_sql("SET statement_timeout = '60s'")

        # 1) temp table ‡πÄ‡∏õ‡πá‡∏ô TEXT ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ uuid ‡∏ï‡∏≠‡∏ô insert
        conn.exec_driver_sql("""
            CREATE TEMP TABLE tmp_agent_updates(
                quotation_num text PRIMARY KEY,
                agent_uuid text NOT NULL
            ) ON COMMIT DROP
        """)

        # 2) bulk insert ‡∏•‡∏á temp table
        #    ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô str + trim ‡∏≠‡∏µ‡∏Å‡∏£‡∏≠‡∏ö
        df_tmp = df_selected.copy()
        df_tmp['quotation_num'] = df_tmp['quotation_num'].astype(str).str.strip()
        df_tmp['agent_uuid'] = df_tmp['agent_uuid'].astype(str).str.strip()
        df_tmp[['quotation_num', 'agent_uuid']].to_sql(
            "tmp_agent_updates",
            con=conn,
            if_exists="append",
            index=False,
            method="multi",
            chunksize=10_000
        )

        # 3) debug: ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô row ‡πÉ‡∏ô temp
        tmp_count = conn.execute(text("SELECT COUNT(*) FROM tmp_agent_updates")).scalar()
        print(f"üßÆ tmp rows: {tmp_count}")

        # 3.1) debug: ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà match ‡∏Å‡∏±‡∏ö fact ‡∏ï‡∏≤‡∏° key (‡πÅ‡∏•‡∏∞‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç payment_plan ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        match_sql = """
            SELECT COUNT(*)
            FROM fact_sales_quotation f
            JOIN tmp_agent_updates t
              ON btrim(f.quotation_num) = btrim(t.quotation_num)
        """
        if require_payment_plan_null:
            match_sql += " WHERE f.payment_plan_id IS NULL"
        matched = conn.execute(text(match_sql)).scalar()
        print(f"üß© matched rows (pre-check): {matched}")

        if matched == 0:
            hint = "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ quotation_num ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á/‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå ‡∏´‡∏£‡∏∑‡∏≠ payment_plan_id ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô NULL ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç"
            print(f"‚ö†Ô∏è No rows matched for update. {hint}")

        # 4) UPDATE ‡πÅ‡∏ö‡∏ö set-based
        where_payment_plan = "AND f.payment_plan_id IS NULL" if require_payment_plan_null else ""
        update_sql = text(f"""
            UPDATE fact_sales_quotation f
            SET agent_id = (t.agent_uuid::uuid)::text,
                update_at = NOW()
            FROM tmp_agent_updates t
            WHERE btrim(f.quotation_num) = btrim(t.quotation_num)
            {where_payment_plan}
            AND (f.agent_id IS NULL OR f.agent_id IS DISTINCT FROM (t.agent_uuid::uuid)::text)
        """)

        max_retries = 5
        for attempt in range(max_retries):
            try:
                result = conn.execute(update_sql)
                print(f"‚úÖ Updated rows: {result.rowcount}")
                if result.rowcount == 0 and not require_payment_plan_null:
                    print("‚ÑπÔ∏è Still 0 updated. ‡∏≠‡∏≤‡∏à‡∏°‡∏µ agent_id ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£‡∏∑‡∏≠ key ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á")
                print("‚úÖ Update agent_id completed successfully.")
                break
            except OperationalError as e:
                msg = str(getattr(e, "orig", e)).lower()
                if "deadlock detected" in msg and attempt < max_retries - 1:
                    sleep_s = (2 ** attempt) + random.random()
                    print(f"‚ö†Ô∏è Deadlock detected. Retrying in {sleep_s:.2f}s (attempt {attempt+1}/{max_retries})")
                    time.sleep(sleep_s)
                    continue
                raise

@job
def update_fact_sales_quotation_agent_id():
    df_joined = join_and_clean_agent_data(
        extract_quotation_idcus(),
        extract_fact_sales_quotation(),
        extract_dim_agent()
    )
    # ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö payment_plan_id ‡πÄ‡∏õ‡πá‡∏ô NULL ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á require_payment_plan_null=False
    update_agent_id(df_joined, require_payment_plan_null=True)


# üëá (‡∏ñ‡πâ‡∏≤‡∏à‡∏∞‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß)
# if __name__ == "__main__":
#     df_quotation = extract_quotation_idcus()
#     df_fact = extract_fact_sales_quotation()
#     df_agent = extract_dim_agent()
#     df_joined = join_and_clean_agent_data(df_quotation, df_fact, df_agent)
#     update_agent_id(df_joined)
#     print("üéâ completed! Data upserted to agent_id.")
