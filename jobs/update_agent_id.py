# %%
from dagster import op, job
import pandas as pd
import numpy as np
import os
import time
import random
import re
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from sqlalchemy.exc import OperationalError

# ‚úÖ Load .env
load_dotenv()

# ‚úÖ DB Connections
# Source: MariaDB
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance"
)

# Target: PostgreSQL
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance",
    connect_args={
        "keepalives": 1,
        "keepalives_idle": 30,
        "keepalives_interval": 10,
        "keepalives_count": 5,
        "options": "-c statement_timeout=300000"  # 5 ‡∏ô‡∏≤‡∏ó‡∏µ
    },
    pool_pre_ping=True
)

# ---------- helpers ----------
def base_id_series(s: pd.Series) -> pd.Series:
    """‡∏Ñ‡∏∑‡∏ô base id ‡πÇ‡∏î‡∏¢‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢ '-defect' ‡πÅ‡∏•‡∏∞ trim ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á"""
    return s.astype(str).str.strip().str.replace(r'-defect$', '', regex=True)

# ---------- EXTRACT ----------
@op
def extract_quotation_idcus_from_pay() -> pd.DataFrame:
    """‡∏î‡∏∂‡∏á quo_num, id_cus ‡∏à‡∏≤‡∏Å fin_system_pay (‡∏ù‡∏±‡πà‡∏á source)"""
    q = text("SELECT quo_num, id_cus FROM fin_system_pay")
    df = pd.read_sql(q, source_engine)
    df = df.rename(columns={'quo_num': 'quotation_num', 'id_cus': 'agent_id'})
    # strip ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
    df['agent_id'] = df['agent_id'].astype(str).str.strip()
    print(f"üì¶ df_pay (quo_num,id_cus): {df.shape}")
    return df

@op
def extract_fact_sales_quotation_null() -> pd.DataFrame:
    """‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ quotation_num ‡∏ó‡∏µ‡πà agent_id ‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô NULL (‡∏ù‡∏±‡πà‡∏á target)"""
    q = text("SELECT quotation_num FROM fact_sales_quotation")
    df = pd.read_sql(q, target_engine)
    print(f"üì¶ df_fsq_null: {df.shape}")
    return df

@op
def extract_dim_agent_for_normalization() -> pd.DataFrame:
    """
    ‡∏î‡∏∂‡∏á agent_id ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å dim_agent (‡∏ù‡∏±‡πà‡∏á target)
    ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠ normalize mapping (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á base ‡πÅ‡∏•‡∏∞ base-defect)
    """
    q = text("SELECT agent_id FROM dim_agent")
    df = pd.read_sql(q, target_engine)
    print(f"üì¶ df_dim_agent: {df.shape}")
    return df

# ---------- TRANSFORM / JOIN ----------
@op
def normalize_and_join(
    df_pay: pd.DataFrame,
    df_fsq_null: pd.DataFrame,
    df_dim_agent: pd.DataFrame
) -> pd.DataFrame:
    """
    1) ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ quotation_num ‡∏ó‡∏µ‡πà agent_id ‡πÉ‡∏ô FSQ ‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô NULL
    2) Normalize agent_id ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ base (‡∏ï‡∏±‡∏î -defect)
       - ‡∏£‡∏ß‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏° agent_id ‡∏à‡∏≤‡∏Å dim_agent ‡∏î‡πâ‡∏ß‡∏¢ base ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
       - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á non-defect ‡πÅ‡∏•‡∏∞ defect ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢ -defect (prefer defect)
    3) ‡πÅ‡∏°‡πá‡∏õ agent_id ‡∏Ç‡∏≠‡∏á‡∏ù‡∏±‡πà‡∏á pay ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô agent_id ‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß
    """
    # --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ù‡∏±‡πà‡∏á dim_agent: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô‡∏ï‡πà‡∏≠ base (prefer -defect) ---
    dm = df_dim_agent.copy()
    dm['__base'] = base_id_series(dm['agent_id'])
    dm['__is_defect'] = dm['agent_id'].str.contains(r'-defect$', case=False, na=False)

    dup_mask = dm['__base'].duplicated(keep=False)
    main_single = dm[~dup_mask].copy()  # base ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥
    main_dups = (
        dm[dup_mask]
        .sort_values(['__base', '__is_defect'])  # non-defect ‡∏Å‡πà‡∏≠‡∏ô, defect ‡∏´‡∏•‡∏±‡∏á
        .drop_duplicates('__base', keep='last')   # ‡πÄ‡∏Å‡πá‡∏ö defect ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    )
    dm_norm = pd.concat([main_single, main_dups], ignore_index=True)
    dm_norm = dm_norm[['agent_id', '__base']].rename(columns={'agent_id': 'agent_id_main'})

    # --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ù‡∏±‡πà‡∏á pay + fsq(null) ---
    m1 = pd.merge(
        df_pay[['quotation_num', 'agent_id']],
        df_fsq_null[['quotation_num']],
        on='quotation_num',
        how='right'
    )
    # ‡∏Ñ‡∏µ‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏°‡πá‡∏õ
    m1['__base'] = base_id_series(m1['agent_id'])

    # --- ‡πÅ‡∏°‡πá‡∏õ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô ---
    merged = pd.merge(
        m1,
        dm_norm,
        on='__base',
        how='left',
        suffixes=('_pay', '_main')
    )

    # agent_id_final: ‡∏ñ‡πâ‡∏≤‡πÅ‡∏°‡πá‡∏õ‡∏Å‡∏±‡∏ö main ‡πÑ‡∏î‡πâ -> ‡πÉ‡∏ä‡πâ agent_id_main, ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏á pay ‡πÄ‡∏î‡∏¥‡∏°
    merged['agent_id_final'] = np.where(
        merged['agent_id_main'].notna(), merged['agent_id_main'], merged['agent_id']
    )

    # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡πà‡∏ß‡∏¢
    cols_keep = ['quotation_num', 'agent_id_final']
    out = merged[cols_keep].rename(columns={'agent_id_final': 'agent_id'})

    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î & ‡∏•‡∏î‡∏ã‡πâ‡∏≥
    out = out.replace(['None', 'none', 'nan', 'NaN', 'NaT', ''], pd.NA)
    out = out.dropna(subset=['quotation_num', 'agent_id'])
    out['quotation_num'] = out['quotation_num'].astype('string').str.strip()
    out['agent_id'] = out['agent_id'].astype('string').str.strip()
    out = out.drop_duplicates(subset=['quotation_num'])

    print(f"üì¶ df_update_candidates (clean): {out.shape}")
    return out

# ---------- LOAD (UPDATE) ----------
@op
def update_agent_id(df_selected: pd.DataFrame) -> None:
    if df_selected.empty:
        print("‚ÑπÔ∏è No rows to update.")
        return

    # ‡∏Å‡∏±‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏´‡∏•‡∏∏‡∏î‡∏°‡∏≤
    df_selected = (
      df_selected
      .dropna(subset=["quotation_num", "agent_id"])
      .drop_duplicates(subset=["quotation_num"])
    )

    with target_engine.begin() as conn:
        # ‡∏•‡∏î‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÅ‡∏Æ‡∏á‡∏Ñ‡πå‡πÅ‡∏•‡∏∞ deadlock
        conn.exec_driver_sql("SET lock_timeout = '3s'")
        conn.exec_driver_sql("SET deadlock_timeout = '200ms'")
        conn.exec_driver_sql("SET statement_timeout = '60s'")

        # 1) ‡∏™‡∏£‡πâ‡∏≤‡∏á temp table (‡πÉ‡∏ä‡πâ TEXT ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ agent_id ‡∏≠‡∏≤‡∏à‡∏°‡∏µ '-defect')
        conn.exec_driver_sql("""
            CREATE TEMP TABLE tmp_agent_updates(
                quotation_num text PRIMARY KEY,
                agent_id text NOT NULL
            ) ON COMMIT DROP
        """)

        # 2) bulk insert ‡∏•‡∏á temp table
        df_selected.to_sql(
            "tmp_agent_updates",
            con=conn,
            if_exists="append",
            index=False,
            method="multi",
            chunksize=10_000
        )

        # 3) UPDATE ‡∏à‡∏£‡∏¥‡∏á (‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô/‡∏¢‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏á)
        update_sql = text("""
            UPDATE fact_sales_quotation f
            SET agent_id = d.agent_id,
                update_at = NOW()
            FROM tmp_agent_updates t
            JOIN dim_agent d
            ON lower(d.agent_id) = lower(t.agent_id)   -- join ‡πÅ‡∏ö‡∏ö lowercase
            WHERE f.quotation_num = t.quotation_num
            AND (f.agent_id IS NULL OR f.agent_id IS DISTINCT FROM d.agent_id);
        """)

        # 4) ‡πÉ‡∏™‡πà retry ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ deadlock
        max_retries = 5
        for attempt in range(max_retries):
            try:
                result = conn.execute(update_sql)
                print(f"‚úÖ Updated rows: {result.rowcount}")
                print("‚úÖ Update agent_id completed successfully.")
                break
            except OperationalError as e:
                msg = str(getattr(e, "orig", e)).lower()
                if "deadlock detected" in msg and attempt < max_retries - 1:
                    sleep_s = (2 ** attempt) + random.random()
                    print(f"‚ö†Ô∏è Deadlock detected. Retrying in {sleep_s:.2f}s (attempt {attempt+1}/{max_retries})")
                    time.sleep(sleep_s)
                    continue
                raise

# ---------- JOB ----------
@job
def update_fact_sales_quotation_agent_id():
    update_agent_id(
        normalize_and_join(
            extract_quotation_idcus_from_pay(),
            extract_fact_sales_quotation_null(),
            extract_dim_agent_for_normalization()
        )
    )

if __name__ == "__main__":
    df_pay = extract_quotation_idcus_from_pay()
    df_fsq = extract_fact_sales_quotation_null()
    df_dim = extract_dim_agent_for_normalization()
    df_join = normalize_and_join(df_pay, df_fsq, df_dim)
    update_agent_id(df_join)
    print("üéâ completed! agent_id updated.")
