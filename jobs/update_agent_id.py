from dagster import op, job
import pandas as pd
import numpy as np
import os
import re
from dotenv import load_dotenv
from sqlalchemy import create_engine, text, MetaData, Table, func
from sqlalchemy.dialects.postgresql import insert as pg_insert

# =========================
# ğŸ”§ ENV & DB CONNECTIONS
# =========================
load_dotenv()

# MariaDB (source)
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance",
    pool_pre_ping=True
)

# PostgreSQL (target)
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance",
    connect_args={
        "keepalives": 1,
        "keepalives_idle": 30,
        "keepalives_interval": 10,
        "keepalives_count": 5,
        "options": "-c statement_timeout=300000"  # 5 à¸™à¸²à¸—à¸µ
    },
    pool_pre_ping=True
)

# =========================
# ğŸ”§ HELPERS
# =========================
def base_id_series(s: pd.Series) -> pd.Series:
    """à¸„à¸·à¸™à¸„à¹ˆà¸² agent_id à¸—à¸µà¹ˆà¸•à¸±à¸” suffix '-defect' à¸­à¸­à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸³à¸„à¸µà¸¢à¹Œà¸à¸¥à¸²à¸‡"""
    return s.astype(str).str.strip().str.replace(r"-defect$", "", regex=True)

def normalize_str_col(s: pd.Series) -> pd.Series:
    s = s.astype("string")
    s = s.str.strip()
    s = s.mask(s.str.len() == 0)
    s = s.mask(s.str.lower().isin(["nan", "none", "null", "undefined"]))
    return s

# =========================
# ğŸ§² EXTRACT + TRANSFORM
# =========================
@op
def extract_agent_mapping() -> pd.DataFrame:
    """
    à¸”à¸¶à¸‡ agent à¸ˆà¸²à¸ fin_system_pay (source) + quotation à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸ˆà¸²à¸ fact_sales_quotation (target)
    à¹à¸¥à¹‰à¸§à¸¢à¸¸à¸š agent_id à¸à¸±à¹ˆà¸‡à¸¡à¸´à¸•à¸´ (dim_agent) à¹ƒà¸«à¹‰à¹€à¸«à¸¥à¸·à¸­ standard à¹€à¸”à¸µà¸¢à¸§à¸•à¹ˆà¸­ base_id
    à¹à¸¥à¹‰à¸§à¹€à¸¥à¸·à¸­à¸ agent_id à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸•à¹ˆà¸¥à¸° quotation_num
    """
    # 1) à¸”à¸¶à¸‡à¸ˆà¸²à¸ source: fin_system_pay
    df_career = pd.read_sql(text("SELECT quo_num, id_cus FROM fin_system_pay"), source_engine)
    df_career = df_career.rename(columns={"id_cus": "agent_id", "quo_num": "quotation_num"})
    df_career["agent_id"] = normalize_str_col(df_career["agent_id"])

    # 2) à¸”à¸¶à¸‡ quotation à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™ fact_sales_quotation (target)
    df_fact = pd.read_sql(text("SELECT quotation_num FROM fact_sales_quotation"), target_engine)

    # 3) right-join à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸¡à¸µà¸—à¸¸à¸ quotation à¹à¸¡à¹‰à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸™ pay
    df_m1 = pd.merge(df_career, df_fact, on="quotation_num", how="right")

    # 4) à¸¡à¸´à¸•à¸´ agent (target) à¹€à¸à¸·à¹ˆà¸­à¸—à¸³ standardization
    df_main = pd.read_sql(text("SELECT agent_id FROM dim_agent"), target_engine)
    df_main["agent_id"] = normalize_str_col(df_main["agent_id"]).dropna()

    # 4.1) à¸—à¸³à¸„à¸µà¸¢à¹Œ base à¹à¸¥à¸°à¹€à¸¥à¸·à¸­à¸à¸•à¸±à¸§à¹à¸—à¸™/à¸•à¸±à¸§ defect
    dfm = df_main.copy()
    dfm["__base"] = base_id_series(dfm["agent_id"])
    dfm["__is_defect"] = dfm["agent_id"].str.contains(r"-defect$", case=False, na=False)
    dup_mask = dfm["__base"].duplicated(keep=False)

    main_single = dfm[~dup_mask].copy()
    # sort: non-defect à¸à¹ˆà¸­à¸™, defect à¸«à¸¥à¸±à¸‡ â†’ keep='last' à¸ˆà¸°à¹„à¸”à¹‰ defect à¸–à¹‰à¸²à¸¡à¸µ
    main_dups = (
        dfm[dup_mask]
        .sort_values(["__base", "__is_defect"])
        .drop_duplicates("__base", keep="last")
    )
    df_main_norm = pd.concat([main_single, main_dups], ignore_index=True)

    # 5) à¸—à¸³à¸„à¸µà¸¢à¹Œà¸à¸¥à¸²à¸‡à¸—à¸µà¹ˆà¸”à¹‰à¸²à¸™ mapping
    df_m1["__base"] = base_id_series(df_m1["agent_id"])

    # 6) à¸ˆà¸±à¸šà¸„à¸¹à¹ˆà¸”à¹‰à¸§à¸¢ base
    df_join = pd.merge(
        df_m1,
        df_main_norm.drop(columns=["__is_defect"], errors="ignore"),
        on="__base",
        how="left",
        suffixes=("_m1", "_main"),
        indicator=False,
    )

    # 7) à¹€à¸¥à¸·à¸­à¸ agent_id_final: à¸–à¹‰à¸²à¹à¸¡à¸•à¸Šà¹Œà¸¡à¸´à¸•à¸´à¹„à¸”à¹‰à¹ƒà¸Šà¹‰à¸‚à¸­à¸‡à¸¡à¸´à¸•à¸´, à¹„à¸¡à¹ˆà¸‡à¸±à¹‰à¸™à¹ƒà¸Šà¹‰à¸‚à¸­à¸‡à¹€à¸”à¸´à¸¡
    df_join["agent_id_final"] = np.where(
        df_join["agent_id_main"].notna(), df_join["agent_id_main"], df_join["agent_id_m1"]
    )

    # 8) à¸„à¸·à¸™à¹€à¸‰à¸à¸²à¸° 2 à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ à¹à¸¥à¸° normalize à¸­à¸µà¸à¸£à¸­à¸š
    df_out = df_join[["quotation_num", "agent_id_final"]].rename(columns={"agent_id_final": "agent_id"})
    df_out["agent_id"] = normalize_str_col(df_out["agent_id"])

    # à¸à¸±à¸™à¸‹à¹‰à¸³ quotation_num (à¸–à¹‰à¸²à¸¡à¸µ) à¹‚à¸”à¸¢à¹ƒà¸«à¹‰à¹à¸–à¸§à¸—à¸µà¹ˆ agent_id à¹„à¸¡à¹ˆà¸§à¹ˆà¸²à¸‡à¸­à¸¢à¸¹à¹ˆà¸à¹ˆà¸­à¸™
    df_out["__has_agent"] = df_out["agent_id"].notna().astype(int)
    df_out = df_out.sort_values(["quotation_num", "__has_agent"], ascending=[True, False]) \
                   .drop_duplicates("quotation_num", keep="first") \
                   .drop(columns="__has_agent")
    return df_out


# =========================
# ğŸ§¹ STAGE TEMP TABLE
# =========================
@op
def stage_dim_agent_temp(df_map: pd.DataFrame) -> str:
    """
    à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸²à¸£à¸²à¸‡à¸Šà¸±à¹ˆà¸§à¸„à¸£à¸²à¸§ dim_agent_temp (quotation_num, agent_id)
    à¹à¸¥à¸° normalize à¸•à¸±à¸§à¸ªà¸°à¸à¸” agent_id à¸•à¸²à¸¡ dim_agent (case-insensitive)
    """
    if df_map.empty:
        # à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸²à¸£à¸²à¸‡à¸§à¹ˆà¸²à¸‡ (schema à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™) à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰ step à¸–à¸±à¸”à¹„à¸›à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰
        df_map = pd.DataFrame({"quotation_num": pd.Series(dtype="string"),
                               "agent_id": pd.Series(dtype="string")})

    # à¹‚à¸«à¸¥à¸”à¸¥à¸‡ PG (replace)
    df_tmp = df_map.copy()
    df_tmp["quotation_num"] = normalize_str_col(df_tmp["quotation_num"])
    df_tmp["agent_id"] = normalize_str_col(df_tmp["agent_id"])

    df_tmp.to_sql("dim_agent_temp", target_engine, if_exists="replace", index=False, method="multi", chunksize=20_000)
    print(f"âœ… staged to dim_agent_temp: {len(df_tmp):,} rows")

    # Normalize à¸•à¸±à¸§à¸ªà¸°à¸à¸” agent_id à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸š dim_agent
    normalize_query = text("""
        UPDATE dim_agent_temp t
        SET agent_id = da.agent_id
        FROM dim_agent da
        WHERE LOWER(da.agent_id) = LOWER(t.agent_id)
          AND t.agent_id IS DISTINCT FROM da.agent_id;
    """)
    with target_engine.begin() as conn:
        res = conn.execute(normalize_query)
        print(f"ğŸ”„ normalized agent_id casing: {res.rowcount} rows")

    return "dim_agent_temp"


# =========================
# ğŸš€ APPLY UPDATE TO FACT
# =========================
@op
def update_fact_from_temp(temp_table_name: str) -> int:
    """
    à¸­à¸±à¸›à¹€à¸”à¸• fact_sales_quotation.agent_id à¸ˆà¸²à¸ temp table (à¸ˆà¸±à¸šà¸„à¸¹à¹ˆ quotation_num)
    à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸•à¸±à¸§à¸ªà¸°à¸à¸”à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¸ˆà¸²à¸ dim_agent
    """
    if not temp_table_name:
        print("âš ï¸ temp table name missing, skip update.")
        return 0

    update_query = text(f"""
        UPDATE fact_sales_quotation fsq
        SET agent_id = da.agent_id
        FROM {temp_table_name} dc
        JOIN dim_agent da
          ON LOWER(da.agent_id) = LOWER(dc.agent_id)
        WHERE fsq.quotation_num = dc.quotation_num
          AND fsq.agent_id IS DISTINCT FROM da.agent_id;
    """)
    with target_engine.begin() as conn:
        res = conn.execute(update_query)
        print(f"âœ… fact_sales_quotation updated: {res.rowcount} rows")
        return res.rowcount or 0


# =========================
# ğŸ§¹ CLEANUP TEMP
# =========================
@op
def drop_dim_agent_temp(temp_table_name: str) -> None:
    if not temp_table_name:
        return
    with target_engine.begin() as conn:
        conn.execute(text(f"DROP TABLE IF EXISTS {temp_table_name};"))
    print("ğŸ—‘ï¸ dropped dim_agent_temp")


# =========================
# ğŸ§± DAGSTER JOB
# =========================
@job
def update_agent_id_on_fact():
    temp = stage_dim_agent_temp(extract_agent_mapping())
    _ = update_fact_from_temp(temp)
    drop_dim_agent_temp(temp)


# =========================
# â–¶ï¸ LOCAL RUN
# # =========================
# if __name__ == "__main__":
#     df_map = extract_agent_mapping()
#     tname = stage_dim_agent_temp(df_map)
#     updated = update_fact_from_temp(tname)
#     drop_dim_agent_temp(tname)
#     print(f"ğŸ‰ done. updated rows = {updated}")
