from dagster import op, job
import os
import re
import pandas as pd
import numpy as np
from dotenv import load_dotenv
from sqlalchemy import create_engine, text

# =========================
# ğŸ”§ ENV & DB CONNECTIONS
# =========================
load_dotenv()
PG_SCHEMA = os.getenv("PG_SCHEMA", "public")

# MariaDB (source)
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@"
    f"{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance",
    pool_pre_ping=True, pool_recycle=3600
)

# PostgreSQL (target) â€” set search_path + timeout
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@"
    f"{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance",
    connect_args={
        "keepalives": 1, "keepalives_idle": 30, "keepalives_interval": 10, "keepalives_count": 5,
        "options": f"-c search_path={PG_SCHEMA} -c statement_timeout=300000"
    },
    pool_pre_ping=True, pool_recycle=3600
)

# =========================
# ğŸ”§ HELPERS
# =========================
NULL_TOKENS = {"", "nan", "none", "null", "undefined"}

def normalize_str_col(s: pd.Series) -> pd.Series:
    s = s.astype("string").str.strip()
    s = s.mask(s.str.len() == 0)
    s = s.mask(s.str.lower().isin(NULL_TOKENS))
    return s

# =========================
# ğŸ§² EXTRACT + TRANSFORM
# =========================
@op
def extract_agent_mapping() -> pd.DataFrame:
    """
    à¸ªà¸£à¹‰à¸²à¸‡ mapping [quotation_num, agent_id] à¹‚à¸”à¸¢ join à¹à¸šà¸š 'à¸•à¸£à¸‡ à¹†' à¸à¸±à¸š dim_agent
    à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ base_id / à¹„à¸¡à¹ˆà¸ˆà¸±à¸”à¸à¸²à¸£ defect/non-defect â€” à¹ƒà¸Šà¹‰ agent_id à¸ˆà¸²à¸à¹à¸«à¸¥à¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸
    à¹à¸¥à¸°à¸–à¹‰à¸²à¸à¸šà¹ƒà¸™ dim_agent à¸ˆà¸°à¸¢à¸à¸•à¸±à¸§à¸ªà¸°à¸à¸” (casing) à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸•à¸²à¸¡ dim_agent
    """
    # source: fin_system_pay
    with source_engine.begin() as sconn:
        df_career = pd.read_sql(text("SELECT quo_num, id_cus FROM fin_system_pay"), sconn)
    df_career = df_career.rename(columns={"id_cus": "agent_id", "quo_num": "quotation_num"})
    df_career["agent_id"] = normalize_str_col(df_career["agent_id"])

    # fact quotations (à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”)
    with target_engine.begin() as tconn:
        df_fact = pd.read_sql(text(f"SELECT quotation_num FROM {PG_SCHEMA}.fact_sales_quotation"), tconn)

    # à¸„à¸‡ quotation à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
    df_m1 = pd.merge(df_career, df_fact, on="quotation_num", how="right")

    # dim_agent à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸±à¸š casing (join à¸•à¸£à¸‡ à¹† à¸•à¸²à¸¡ agent_id à¹à¸šà¸š case-insensitive)
    with target_engine.begin() as tconn:
        df_main = pd.read_sql(text(f"SELECT agent_id FROM {PG_SCHEMA}.dim_agent"), tconn)
    df_main["agent_id"] = normalize_str_col(df_main["agent_id"]).dropna()

    # à¹€à¸•à¸£à¸µà¸¢à¸¡ key à¸Šà¹ˆà¸§à¸¢à¸ªà¸³à¸«à¸£à¸±à¸š merge à¹à¸šà¸šà¹„à¸¡à¹ˆà¸ªà¸™à¹ƒà¸ˆà¸•à¸±à¸§à¹ƒà¸«à¸à¹ˆà¹€à¸¥à¹‡à¸
    df_m1["agent_id_l"]   = normalize_str_col(df_m1.get("agent_id", pd.Series(dtype="string"))).str.lower()
    df_main["agent_id_l"] = df_main["agent_id"].str.lower()

    # join à¹à¸šà¸šà¸•à¸£à¸‡ à¹† (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ base_id)
    df_join = pd.merge(
        df_m1,
        df_main[["agent_id_l", "agent_id"]].rename(columns={"agent_id": "agent_id_main"}),
        on="agent_id_l",
        how="left",
        suffixes=("_m1", "_main")
    )

    # à¹€à¸¥à¸·à¸­à¸ agent_id_final = à¸–à¹‰à¸²à¹€à¸ˆà¸­à¹ƒà¸™ dim_agent à¹ƒà¸Šà¹‰à¸‚à¸­à¸‡ dim_agent (à¸„à¸‡ casing) à¹„à¸¡à¹ˆà¹€à¸ˆà¸­à¹ƒà¸Šà¹‰à¸‚à¸­à¸‡à¹€à¸”à¸´à¸¡
    if "agent_id_m1" not in df_join.columns:  df_join["agent_id_m1"] = pd.NA
    if "agent_id_main" not in df_join.columns: df_join["agent_id_main"] = pd.NA

    df_join["agent_id_final"] = np.where(
        df_join["agent_id_main"].notna(), df_join["agent_id_main"], df_join["agent_id_m1"]
    )

    # à¸ªà¹ˆà¸‡à¸­à¸­à¸à¹€à¸‰à¸à¸²à¸°à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰
    df_out = df_join[["quotation_num", "agent_id_final"]].rename(columns={"agent_id_final": "agent_id"})
    df_out["agent_id"] = normalize_str_col(df_out["agent_id"])

    # à¹€à¸¥à¸·à¸­à¸à¸«à¸™à¸¶à¹ˆà¸‡à¹à¸–à¸§à¸•à¹ˆà¸­ quotation_num (à¹ƒà¸«à¹‰à¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µ agent_id à¸¡à¸²à¸à¹ˆà¸­à¸™)
    df_out["__has_agent"] = df_out["agent_id"].notna().astype(int)
    df_out = (
        df_out.sort_values(["quotation_num", "__has_agent"], ascending=[True, False])
              .drop_duplicates("quotation_num", keep="first")
              .drop(columns="__has_agent")
    )

    # à¸à¸±à¸™à¸„à¹ˆà¸²à¸§à¹ˆà¸²à¸‡ key
    df_out = df_out.dropna(subset=["quotation_num"])
    print(f"âœ… extract_agent_mapping â†’ {len(df_out):,} rows")
    return df_out

# =========================
# ğŸ§¼ STAGE TEMP (DDL à¹€à¸ªà¸¡à¸­)
# =========================
@op
def stage_dim_agent_temp(df_map: pd.DataFrame) -> str:
    """
    à¸ªà¸£à¹‰à¸²à¸‡ {schema}.dim_agent_temp à¸”à¹‰à¸§à¸¢ DDL à¹€à¸ªà¸¡à¸­ à¹à¸¥à¹‰à¸§ append à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (à¸–à¹‰à¸²à¸¡à¸µ)
    à¹à¸¥à¸° normalize agent_id casing à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸š dim_agent
    """
    tbl = "dim_agent_temp"
    full_tbl = f"{PG_SCHEMA}.{tbl}"

    # à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    if df_map is None:
        df_map = pd.DataFrame()
    tmp = (df_map.replace(["None","none","nan","NaN","NaT",""], pd.NA)).copy()
    tmp["quotation_num"] = normalize_str_col(tmp.get("quotation_num", pd.Series(dtype="string")))
    tmp["agent_id"]      = normalize_str_col(tmp.get("agent_id",      pd.Series(dtype="string")))

    # DDL: create table à¹€à¸ªà¸¡à¸­ + index
    with target_engine.begin() as conn:
        conn.execute(text(f"DROP TABLE IF EXISTS {full_tbl};"))
        conn.execute(text(f"""
            CREATE TABLE {full_tbl} (
                quotation_num text,
                agent_id      text
            );
        """))
        conn.execute(text(f"CREATE INDEX IF NOT EXISTS idx_dim_agent_temp_quo   ON {full_tbl} (quotation_num);"))
        conn.execute(text(f"CREATE INDEX IF NOT EXISTS idx_dim_agent_temp_agent ON {full_tbl} (LOWER(agent_id));"))

    # append à¹€à¸‰à¸à¸²à¸°à¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µ key
    to_append = tmp.dropna(subset=["quotation_num"])
    if not to_append.empty:
        with target_engine.begin() as conn:
            to_append.to_sql("dim_agent_temp", con=conn, schema=PG_SCHEMA,
                             if_exists="append", index=False, method="multi", chunksize=200_000)
        print(f"âœ… staged â†’ {len(to_append):,} rows into {full_tbl}")
    else:
        print(f"âš ï¸ no rows to stage, created empty table â†’ {full_tbl}")

    # normalize casing à¹ƒà¸«à¹‰à¸•à¸£à¸‡ dim_agent (à¸„à¸‡à¹„à¸§à¹‰ à¹€à¸œà¸·à¹ˆà¸­ source à¸ªà¹ˆà¸‡ casing à¹„à¸¡à¹ˆà¸•à¸£à¸‡)
    with target_engine.begin() as conn:
        res = conn.execute(text(f"""
            UPDATE {full_tbl} t
            SET agent_id = da.agent_id
            FROM {PG_SCHEMA}.dim_agent da
            WHERE LOWER(da.agent_id) = LOWER(t.agent_id)
              AND t.agent_id IS DISTINCT FROM da.agent_id;
        """))
        print(f"ğŸ”„ normalized agent_id casing: {res.rowcount} rows")

    return full_tbl  # à¸ªà¹ˆà¸‡à¸„à¸·à¸™à¸Šà¸·à¹ˆà¸­ fully-qualified

# =========================
# ğŸš€ UPDATE FACT (à¹€à¸Šà¹‡à¸„à¸•à¸²à¸£à¸²à¸‡à¸à¹ˆà¸­à¸™)
# =========================
@op
def update_fact_from_temp(temp_table_name: str) -> int:
    if not temp_table_name:
        print("âš ï¸ temp table name missing, skip update.")
        return 0

    # à¸•à¸£à¸§à¸ˆà¸§à¹ˆà¸²à¸¡à¸µà¸•à¸²à¸£à¸²à¸‡à¸ˆà¸£à¸´à¸‡ (à¸à¸±à¸™à¸à¸£à¸“à¸µà¸œà¸´à¸” schema/name)
    with target_engine.begin() as conn:
        exists = conn.execute(text("SELECT to_regclass(:fqname)"), {"fqname": temp_table_name}).scalar()
    if not exists:
        print(f"âŒ temp not found: {temp_table_name}")
        return 0

    with target_engine.begin() as conn:
        res = conn.execute(text(f"""
            UPDATE {PG_SCHEMA}.fact_sales_quotation fsq
            SET agent_id = da.agent_id
            FROM {temp_table_name} dc
            JOIN {PG_SCHEMA}.dim_agent da
              ON LOWER(da.agent_id) = LOWER(dc.agent_id)
            WHERE fsq.quotation_num = dc.quotation_num
              AND fsq.agent_id IS DISTINCT FROM da.agent_id;
        """))
        print(f"âœ… updated fact rows: {res.rowcount}")
        return res.rowcount or 0

# =========================
# ğŸ—‘ï¸ DROP TEMP (à¸šà¸±à¸‡à¸„à¸±à¸šà¹ƒà¸«à¹‰à¸£à¸­ update à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¸£à¸±à¸š updated_count)
# =========================
@op
def drop_dim_agent_temp(temp_table_name: str, updated_count: int) -> None:  # noqa: ARG002 (unused)
    if not temp_table_name:
        return
    with target_engine.begin() as conn:
        conn.execute(text(f"DROP TABLE IF EXISTS {temp_table_name}"))
    print(f"ğŸ—‘ï¸ dropped {temp_table_name}")

# =========================
# ğŸ§± DAGSTER JOB
# =========================
@job
def update_agent_id_on_fact():
    df = extract_agent_mapping()
    temp_full = stage_dim_agent_temp(df)
    updated = update_fact_from_temp(temp_full)
    drop_dim_agent_temp(temp_full, updated)

if __name__ == "__main__":
    df = extract_agent_mapping()
    temp_full = stage_dim_agent_temp(df)
    updated = update_fact_from_temp(temp_full)
    drop_dim_agent_temp(temp_full, updated)
    print(f"ğŸ‰ done. updated rows = {updated}")
