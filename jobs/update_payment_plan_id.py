# %%
from dagster import op, job
import pandas as pd
import numpy as np
import os, re, time, random
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from sqlalchemy.exc import OperationalError

# ‚úÖ Load .env
load_dotenv()

# ‚úÖ DB connections
# Sources (MariaDB)
src_fin = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance",
    pool_size=5, max_overflow=10, pool_pre_ping=True, pool_recycle=3600,
    connect_args={"connect_timeout": 30}
)
src_task = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance_task",
    pool_size=5, max_overflow=10, pool_pre_ping=True, pool_recycle=3600,
    connect_args={"connect_timeout": 30}
)

# Target (PostgreSQL)
tgt = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance",
    pool_size=5, max_overflow=10, pool_pre_ping=True, pool_recycle=3600,
    connect_args={"connect_timeout": 30, "application_name": "payment_plan_id_update"}
)

# ---------- helpers ----------
def _strip_lower(s):
    return "" if s is None or (isinstance(s, float) and pd.isna(s)) else str(s).strip().lower()

def _safe_to_int(series: pd.Series) -> pd.Series:
    out = pd.to_numeric(series, errors='coerce').fillna(0).astype(int)
    out = out.replace({0: 1})  # ‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡πÄ‡∏î‡∏¥‡∏°: 0 -> 1
    return out

def _nan_string_to_nan(df: pd.DataFrame) -> pd.DataFrame:
    return df.map(lambda x: np.nan if isinstance(x, str) and x.strip().lower() == "nan" else x)

# ---------- EXTRACT ----------
@op
def extract_select_plan_id() -> pd.DataFrame:
    with src_fin.connect() as conn:
        df = pd.read_sql("SELECT quo_num, type_insure FROM fin_system_select_plan", conn)
    print(f"üì¶ select_plan: {df.shape}")
    return df

@op
def extract_pay() -> pd.DataFrame:
    with src_fin.connect() as conn:
        df = pd.read_sql("""
            SELECT quo_num, chanel_main, clickbank, chanel, numpay, condition_install
            FROM fin_system_pay
        """, conn)
    print(f"üì¶ pay: {df.shape}")
    return df

@op
def extract_order_status() -> pd.DataFrame:
    with src_task.connect() as conn:
        df = pd.read_sql("SELECT quo_num, status_paybill FROM fin_order", conn)
    print(f"üì¶ order_status: {df.shape}")
    return df

@op
def extract_dim_payment_plan() -> pd.DataFrame:
    with tgt.connect() as conn:
        df = pd.read_sql(text("""
            SELECT payment_plan_id, payment_channel, payment_reciever, payment_type, installment_number
            FROM dim_payment_plan
        """), conn)
    print(f"üì¶ dim_payment_plan: {df.shape}")
    return df

@op
def extract_fsq_missing_payment_plan() -> pd.DataFrame:
    with tgt.connect() as conn:
        df = pd.read_sql(text("""
            SELECT quotation_num
            FROM fact_sales_quotation
            WHERE payment_plan_id IS NULL
        """), conn)
    print(f"üì¶ fsq missing payment_plan_id: {df.shape}")
    return df

# ---------- TRANSFORM ----------
@op
def build_payment_facts(df_plan: pd.DataFrame, df_pay: pd.DataFrame, df_orderstatus: pd.DataFrame) -> pd.DataFrame:
    # 1) pre-clean
    df_pay = df_pay.copy()
    df_pay['chanel'] = df_pay['chanel'].replace({'‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£': '‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏¥‡∏ô'})  # normalize
    merged = pd.merge(df_pay, df_orderstatus, on='quo_num', how='left')
    merged = _nan_string_to_nan(merged)

    # 2) strings cleanup
    for col in ['chanel', 'chanel_main', 'clickbank']:
        merged[col] = merged[col].fillna('').astype(str).str.strip()

    # 3) rewrite chanel ‡∏ï‡∏≤‡∏° rule (np.select)
    ch = merged['chanel'].str.lower()
    chm = merged['chanel_main'].str.lower()
    cb = merged['clickbank'].str.lower()

    conditions = [
        ch == '‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏¥‡∏ô',
        ch == '‡πÄ‡∏Ç‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô',
        (chm.isin(['‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï', '‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£']) & cb.isin(['creditcard', '']) & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£')),
        (chm.isin(['‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£']) & cb.isin(['creditcard', '']) & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.isin(['']) & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô') & cb.isin(['qrcode']) & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.isin(['creditcard', '']) & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.isin(['qrcode','creditcard','']) & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡πÇ‡∏≠‡∏ô‡πÄ‡∏á‡∏¥‡∏ô') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.eq('') & ch.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ä‡∏≥‡∏£‡∏∞') & (cb.isin(['qrcode', '']) | cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£')) & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô') & cb.str.startswith('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£') & ch.eq('‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.eq('') & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô') & cb.eq('') & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô')),
        (chm.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.eq('‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Å‡∏£‡∏∏‡∏á‡πÑ‡∏ó‡∏¢') & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.eq('creditcard') & ch.eq('‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£')),
        (chm.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï') & cb.eq('creditcard') & ch.eq('‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï')),
    ]
    choices = ['‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏¥‡∏ô', '‡πÄ‡∏Ç‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô'] + ['‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏¥‡∏ô'] * (len(conditions) - 2)
    merged['chanel'] = np.select(conditions, choices, default=merged['chanel'])

    # 4) derive payment_channel
    def determine_payment_channel(row):
        ch_main = _strip_lower(row['chanel_main'])
        cb_raw = row['clickbank']; cb = _strip_lower(cb_raw)
        is_cb_empty = (cb_raw is None) or (cb == '')
        if ch_main in ['‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï', '‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£', '‡∏ú‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï', '‡∏ú‡πà‡∏≠‡∏ô‡∏ä‡∏≥‡∏£‡∏∞']:
            if 'qrcode' in cb:  return 'QR Code'
            if 'creditcard' in cb: return '2C2P'
            return '‡∏ï‡∏±‡∏î‡∏ö‡∏±‡∏ï‡∏£‡∏Å‡∏±‡∏ö‡∏ü‡∏¥‡∏ô'
        if ch_main in ['‡πÇ‡∏≠‡∏ô‡πÄ‡∏á‡∏¥‡∏ô', '‡∏ú‡πà‡∏≠‡∏ô‡πÇ‡∏≠‡∏ô']:
            if 'qrcode' in cb: return 'QR Code'
            return '‡πÇ‡∏≠‡∏ô‡πÄ‡∏á‡∏¥‡∏ô'
        if ch_main and is_cb_empty:
            return row['chanel_main']
        if not ch_main and not is_cb_empty:
            if 'qrcode' in cb: return 'QR Code'
            if 'creditcard' in cb: return '2C2P'
            return row['clickbank']
        if not is_cb_empty:
            if 'qrcode' in cb: return 'QR Code'
            if 'creditcard' in cb: return '2C2P'
            return row['clickbank']
        return ''

    merged['payment_channel'] = merged.apply(determine_payment_channel, axis=1)

    # 5) tidy / rename to canonical columns for join
    merged = merged.drop(columns=['chanel_main', 'clickbank', 'condition_install'], errors='ignore')
    merged = merged.rename(columns={
        'quo_num': 'quotation_num',
        'type_insure': 'type_insurance',
        'chanel': 'payment_reciever',
        'status_paybill': 'payment_type',
        'numpay': 'installment_number',
    })
    merged['payment_reciever'] = merged['payment_reciever'].replace({'‡πÄ‡∏Ç‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô1': '‡πÄ‡∏Ç‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô', '‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏¥‡∏ô‡∏•‡∏¥‡∏õ': '‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏¥‡∏•‡∏•‡∏¥‡∏õ'})
    merged['installment_number'] = _safe_to_int(merged['installment_number'])

    # join type_insurance (optional: for diagnostic)
    merged = pd.merge(
        merged,
        df_plan.rename(columns={'quo_num': 'quotation_num', 'type_insure': 'type_insurance'}),
        on='quotation_num', how='left', suffixes=('', '_sp')
    )
    # prefer existing if not null else plan‚Äôs type
    merged['type_insurance'] = np.where(
        merged['type_insurance'].notna(), merged['type_insurance'], merged['type_insurance_sp']
    )
    merged.drop(columns=['type_insurance_sp'], inplace=True)

    keep = ['quotation_num', 'payment_channel', 'payment_reciever', 'payment_type', 'installment_number', 'type_insurance']
    merged = merged[keep].drop_duplicates()
    print(f"üßπ payment facts (for mapping): {merged.shape}")
    return merged

@op
def attach_payment_plan_id(df_payment_facts: pd.DataFrame, dim_payment_plan: pd.DataFrame) -> pd.DataFrame:
    df = pd.merge(
        df_payment_facts,
        dim_payment_plan,
        on=["payment_channel", "payment_reciever", "payment_type", "installment_number"],
        how="inner"
    )
    df = df[['quotation_num', 'payment_plan_id']].drop_duplicates()
    print(f"üîó mapped to dim_payment_plan: {df.shape}")
    return df

@op
def filter_to_missing_fsq(df_map: pd.DataFrame, fsq_missing: pd.DataFrame) -> pd.DataFrame:
    df = pd.merge(df_map, fsq_missing, on='quotation_num', how='right')
    # diagnostics
    if 'payment_plan_id' in df.columns:
        null_count = df['payment_plan_id'].isna().sum()
        print(f"‚ÑπÔ∏è NULL payment_plan_id after FSQ filter: {null_count} / {len(df)}")
        if null_count > 0:
            try:
                df[df['payment_plan_id'].isna()].head(1000).to_excel("payment_plan_id_null.xlsx", index=False)
                print("üíæ saved examples to payment_plan_id_null.xlsx")
            except Exception:
                pass
    else:
        print("‚ùå payment_plan_id column not found.")
    df = df[['quotation_num', 'payment_plan_id']].copy()
    for c in ['quotation_num', 'payment_plan_id']:
        df[c] = df[c].astype('string').str.strip()
    df = df.dropna(subset=['quotation_num']).drop_duplicates(subset=['quotation_num'])
    print(f"‚úÖ update candidates: {df.shape}")
    return df

# ---------- LOAD (UPDATE) ----------
@op
def update_payment_plan_id(df_updates: pd.DataFrame) -> None:
    if df_updates.empty:
        print("‚ÑπÔ∏è No rows to update.")
        return
    with tgt.begin() as conn:
        conn.exec_driver_sql("SET lock_timeout = '3s'")
        conn.exec_driver_sql("SET deadlock_timeout = '200ms'")
        conn.exec_driver_sql("SET statement_timeout = '60s'")

        conn.exec_driver_sql("""
            CREATE TEMP TABLE tmp_payment_plan_updates(
                quotation_num text PRIMARY KEY,
                payment_plan_id text
            ) ON COMMIT DROP
        """)

        df_updates.to_sql(
            "tmp_payment_plan_updates",
            con=conn, if_exists="append", index=False,
            method="multi", chunksize=10_000
        )

        update_sql = text("""
            UPDATE fact_sales_quotation f
            SET payment_plan_id = t.payment_plan_id,
                update_at       = NOW()
            FROM tmp_payment_plan_updates t
            WHERE f.quotation_num = t.quotation_num
              AND (f.payment_plan_id IS NULL OR f.payment_plan_id IS DISTINCT FROM t.payment_plan_id)
        """)

        max_retries = 5
        for attempt in range(max_retries):
            try:
                result = conn.execute(update_sql)
                print(f"üöÄ Updated rows: {result.rowcount}")
                break
            except OperationalError as e:
                msg = str(getattr(e, "orig", e)).lower()
                if "deadlock detected" in msg and attempt < max_retries - 1:
                    sleep_s = (2 ** attempt) + random.random()
                    print(f"‚ö†Ô∏è Deadlock detected. Retrying in {sleep_s:.2f}s (attempt {attempt+1}/{max_retries})")
                    time.sleep(sleep_s)
                    continue
                raise
        print("‚úÖ Update payment_plan_id completed.")

# ---------- JOB ----------
@job
def update_fact_sales_quotation_payment_plan_id():
    update_payment_plan_id(
        filter_to_missing_fsq(
            attach_payment_plan_id(
                build_payment_facts(
                    extract_select_plan_id(),
                    extract_pay(),
                    extract_order_status()
                ),
                extract_dim_payment_plan()
            ),
            extract_fsq_missing_payment_plan()
        )
    )

if __name__ == "__main__":
    sp = extract_select_plan_id()
    pay = extract_pay()
    st = extract_order_status()
    facts = build_payment_facts(sp, pay, st)
    dim = extract_dim_payment_plan()
    mapped = attach_payment_plan_id(facts, dim)
    fsq = extract_fsq_missing_payment_plan()
    updates = filter_to_missing_fsq(mapped, fsq)
    update_payment_plan_id(updates)
    print("üéâ completed! payment_plan_id updated.")
