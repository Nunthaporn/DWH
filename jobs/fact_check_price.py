from dagster import op, job
import pandas as pd
import numpy as np
import json
import re
import os
from dotenv import load_dotenv
from sqlalchemy import create_engine, MetaData, Table, text, func, update, bindparam
from sqlalchemy.sql import tuple_
from datetime import datetime, timedelta
from sqlalchemy.dialects.postgresql import insert as pg_insert

# py>=3.9
try:
    from zoneinfo import ZoneInfo
except Exception:
    ZoneInfo = None

# =========================
# üîß ENV & CONNECTIONS
# =========================
load_dotenv()

# ‚úÖ DB source (MariaDB)
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@"
    f"{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance",
    pool_pre_ping=True, pool_recycle=3600
)

# ‚úÖ DB target (PostgreSQL)
target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@"
    f"{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance",
    pool_pre_ping=True, pool_recycle=3600,
    connect_args={"connect_timeout": 30, "application_name": "fact_check_price_etl",
                  "options": "-c statement_timeout=300000"}
)

# =========================
# üß∞ Helpers
# =========================
THAI_DIGITS = str.maketrans("‡πê‡πë‡πí‡πì‡πî‡πï‡πñ‡πó‡πò‡πô", "0123456789")

def normalize_money(sr: pd.Series) -> pd.Series:
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô -> float (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡πÑ‡∏ó‡∏¢, ‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤, ‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤)
    """
    s = sr.astype(str).str.strip().str.translate(THAI_DIGITS)
    s = s.str.replace(r"[^\d\.\-,]", "", regex=True)   # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 0-9.-,
    s = s.str.replace(",", "", regex=False)            # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤
    s = s.str.extract(r"(-?\d+(?:\.\d+)?)", expand=False)
    return pd.to_numeric(s, errors="coerce").astype("Float64")

def _json_extract_names(results_json, limit=4):
    if pd.isna(results_json):
        return [None]*limit
    try:
        data = json.loads(results_json)
    except Exception:
        return [None]*limit
    names = []
    if isinstance(data, list):
        for d in data:
            if isinstance(d, dict):
                names.append(d.get("company_name"))
            if len(names) >= limit:
                break
    elif isinstance(data, dict):
        names.append(data.get("company_name"))
    names += [None]*(limit-len(names))
    return names[:limit]

def _json_extract_selected(selected_json):
    if pd.isna(selected_json):
        return None
    try:
        data = json.loads(selected_json)
    except Exception:
        return None
    if isinstance(data, list) and data:
        item0 = data[0]
        return item0.get("company_name") if isinstance(item0, dict) else None
    if isinstance(data, dict):
        return data.get("company_name")
    return None

def _extract_plate(text_val):
    if pd.isna(text_val) or str(text_val).strip() == "":
        return None
    text = str(text_val).strip()
    # ‡∏•‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏±‡∏ö‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô
    provinces = [
        "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£","‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà","‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ","‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå","‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£","‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô","‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ","‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤","‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ",
        "‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó","‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥","‡∏ä‡∏∏‡∏°‡∏û‡∏£","‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà","‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢","‡∏ï‡∏£‡∏±‡∏á","‡∏ï‡∏£‡∏≤‡∏î","‡∏ï‡∏≤‡∏Å","‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å","‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°","‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°",
        "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤","‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä","‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå","‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ","‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™","‡∏ô‡πà‡∏≤‡∏ô","‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨","‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå","‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ",
        "‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå","‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ","‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ","‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤","‡∏û‡∏±‡∏á‡∏á‡∏≤","‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á","‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£","‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å",
        "‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ","‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå","‡πÅ‡∏û‡∏£‡πà","‡∏û‡∏∞‡πÄ‡∏¢‡∏≤","‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï","‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°","‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£","‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô","‡∏¢‡∏∞‡∏•‡∏≤","‡∏¢‡πÇ‡∏™‡∏ò‡∏£",
        "‡∏£‡∏∞‡∏ô‡∏≠‡∏á","‡∏£‡∏∞‡∏¢‡∏≠‡∏á","‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ","‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î","‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ","‡∏•‡∏≥‡∏õ‡∏≤‡∏á","‡∏•‡∏≥‡∏û‡∏π‡∏ô","‡πÄ‡∏•‡∏¢","‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©","‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£","‡∏™‡∏á‡∏Ç‡∏•‡∏≤",
        "‡∏™‡∏ï‡∏π‡∏•","‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£","‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°","‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£","‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß","‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ","‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ","‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢","‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ",
        "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ","‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå","‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢","‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π","‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á","‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ","‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ","‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå",
        "‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ","‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç"
    ]
    for prov in provinces:
        text = text.replace(prov, "")
    if '//' in text:
        text = text.split('//')[0]
    elif '/' in text:
        text = text.split('/')[0]
    text = (text.replace('-', '')
                .replace('/', '')
                .replace(',', '')
                .replace('+', '')
                .replace(' ', ''))
    text = re.sub(r'^‡∏õ\d+‡πÅ‡∏•‡∏∞‡∏õ\d+\+?', '', text)
    text = re.sub(r'^‡∏õ\d+\+?', '', text)
    text = re.sub(r'^‡∏á‡∏≤‡∏ô‡∏õ\d+', '', text)
    m = re.match(r'(\d{1}[‡∏Å-‡∏Æ]{2}\d{1,4}|[‡∏Å-‡∏Æ]{1,3}\d{1,4})', text)
    if not m:
        return None
    plate = m.group(1)
    return plate if len(plate) > 3 else None

def _extract_province(text_val):
    if pd.isna(text_val) or str(text_val).strip() == "":
        return None
    s = str(text_val)
    for prov in [
        "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£","‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà","‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ","‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå","‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£","‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô","‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ","‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤","‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ",
        "‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó","‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥","‡∏ä‡∏∏‡∏°‡∏û‡∏£","‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà","‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢","‡∏ï‡∏£‡∏±‡∏á","‡∏ï‡∏£‡∏≤‡∏î","‡∏ï‡∏≤‡∏Å","‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å","‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°","‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°",
        "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤","‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä","‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå","‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ","‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™","‡∏ô‡πà‡∏≤‡∏ô","‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨","‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå","‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ",
        "‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå","‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ","‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ","‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤","‡∏û‡∏±‡∏á‡∏á‡∏≤","‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á","‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£","‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å",
        "‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ","‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå","‡πÅ‡∏û‡∏£‡πà","‡∏û‡∏∞‡πÄ‡∏¢‡∏≤","‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï","‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°","‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£","‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô","‡∏¢‡∏∞‡∏•‡∏≤","‡∏¢‡πÇ‡∏™‡∏ò‡∏£",
        "‡∏£‡∏∞‡∏ô‡∏≠‡∏á","‡∏£‡∏∞‡∏¢‡∏≠‡∏á","‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ","‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î","‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ","‡∏•‡∏≥‡∏õ‡∏≤‡∏á","‡∏•‡∏≥‡∏û‡∏π‡∏ô","‡πÄ‡∏•‡∏¢","‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©","‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£","‡∏™‡∏á‡∏Ç‡∏•‡∏≤",
        "‡∏™‡∏ï‡∏π‡∏•","‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£","‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°","‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£","‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß","‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ","‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ","‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢","‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ",
        "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ","‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå","‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢","‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π","‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á","‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ","‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ","‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå",
        "‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ","‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç"
    ]:
        if prov in s:
            return prov
    return None

def _bkk_today_range():
    """‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ start,end ‡∏Ç‡∏≠‡∏á '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ' (‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢) ‡πÅ‡∏ö‡∏ö naive (‡πÑ‡∏°‡πà‡∏°‡∏µ tz) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÉ‡∏ô SQL"""
    if ZoneInfo:
        tz = ZoneInfo("Asia/Bangkok")
        now_th = datetime.now(tz)
        start_th = now_th.replace(hour=0, minute=0, second=0, microsecond=0)
        end_th = start_th + timedelta(days=1)
        return start_th.replace(tzinfo=None), end_th.replace(tzinfo=None)
    # fallback UTC+7
    now = datetime.utcnow() + timedelta(hours=7)
    start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    end = start + timedelta(days=1)
    return start, end

# =========================
# üß≤ EXTRACT (‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ - ‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢)
# =========================
@op
def extract_check_price_data() -> pd.DataFrame:
    start, end = _bkk_today_range()

    # start = '2025-01-01 00:00:00'
    # end = '2025-10-31 25:59:59'

    q_logs = text("""
        SELECT cuscode, brand, series, subseries, year, no_car, type, repair_type,
               assured_insurance_capital1, camera, addon, quo_num, create_at,
               results, selected, carprovince
        FROM fin_customer_logs_B2B
        WHERE create_at >= :start AND create_at < :end
    """)
    q_check = text("""
        SELECT id_cus, datekey, brand, model, submodel, yearcar, idcar, nocar,
               type_ins, company, tunprakan, deduct, status, type_driver,
               type_camera, type_addon, status_send
        FROM fin_checkprice
        WHERE datekey >= :start AND datekey < :end
    """)
    with source_engine.begin() as conn:
        df_logs = pd.read_sql(q_logs, conn, params={"start": start, "end": end})
        df_check = pd.read_sql(q_check, conn, params={"start": start, "end": end})
    return pd.DataFrame({"logs": [df_logs], "check": [df_check]})

@op
def clean_check_price_data(raw: pd.DataFrame) -> pd.DataFrame:
    df = raw['logs'][0].copy()
    df1 = raw['check'][0].copy()

    # --- parse "results" ‡πÄ‡∏õ‡πá‡∏ô 4 ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ---
    def extract_company_names(x):
        if pd.isnull(x):
            return [None, None, None, None]
        try:
            data = json.loads(x)
        except Exception:
            return [None, None, None, None]
        names = []
        if isinstance(data, list):
            for d in data:
                if isinstance(d, dict):
                    names.append(d.get('company_name'))
                if len(names) == 4:
                    break
        elif isinstance(data, dict):
            names.append(data.get('company_name'))
        while len(names) < 4:
            names.append(None)
        return names[:4]

    company_names_df = df['results'].apply(extract_company_names).apply(pd.Series)
    company_names_df.columns = ['company_name1', 'company_name2', 'company_name3', 'company_name4']
    df = pd.concat([df.drop(columns=['results']), company_names_df], axis=1)

    # --- parse "selected" ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ---
    def extract_selected_name(x):
        if pd.isnull(x):
            return None
        try:
            data = json.loads(x)
        except Exception:
            return None
        if isinstance(data, list) and len(data) > 0:
            item0 = data[0]
            return item0.get('company_name') if isinstance(item0, dict) else None
        elif isinstance(data, dict):
            return data.get('company_name')
        else:
            return None

    df['selecteds'] = df['selected'].apply(extract_selected_name)
    df.drop(columns=['selected'], inplace=True)

    # --- map ‡∏Ñ‡πà‡∏≤ camera/addon ---
    df['camera'] = df['camera'].map({
        'yes': '‡∏°‡∏µ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏£‡∏ñ',
        'no': '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏£‡∏ñ'
    })
    df['addon'] = df['addon'].map({
        '‡πÑ‡∏°‡πà‡∏°‡∏µ': '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÄ‡∏ï‡∏¥‡∏°'
    })

    # --- rename ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ---
    df.rename(columns={
        'cuscode': 'id_cus',
        'series': 'model',
        'subseries': 'submodel',
        'year': 'yearcar',
        'no_car': 'car_code',
        'assured_insurance_capital1': 'sum_insured',
        'camera': 'type_camera',
        'addon': 'type_addon',
        'quo_num': 'select_quotation',
        'create_at': 'transaction_date',
        'carprovince': 'province_car'
    }, inplace=True)

    # --- type_insurance ‡∏à‡∏≤‡∏Å type + repair_type ---
    df['type_insurance'] = '‡∏ä‡∏±‡πâ‡∏ô' + df['type'].astype(str) + df['repair_type'].astype(str)
    df.drop(columns=['type', 'repair_type'], inplace=True)
    df['input_type'] = 'auto'

    # --- ‡πÅ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å fin_checkprice.company ---
    def split_company_names(x):
        if pd.isnull(x):
            return [None, None, None, None]
        names = [name.strip() for name in str(x).split('/')]
        while len(names) < 4:
            names.append(None)
        return names[:4]

    company_names_df = df1['company'].apply(split_company_names).apply(pd.Series)
    company_names_df.columns = ['company_name1', 'company_name2', 'company_name3', 'company_name4']
    df1 = pd.concat([df1.drop(columns=['company']), company_names_df], axis=1)

    # --- ‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å idcar ---
    province_list = [
        "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£", "‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà", "‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ", "‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå", "‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£", "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô", "‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ", "‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤",
        "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ", "‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó", "‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥", "‡∏ä‡∏∏‡∏°‡∏û‡∏£", "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà", "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢", "‡∏ï‡∏£‡∏±‡∏á", "‡∏ï‡∏£‡∏≤‡∏î", "‡∏ï‡∏≤‡∏Å", "‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å",
        "‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°", "‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°", "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤", "‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä", "‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå", "‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ", "‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™", "‡∏ô‡πà‡∏≤‡∏ô",
        "‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨", "‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå", "‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ", "‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå", "‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ", "‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ", "‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤",
        "‡∏û‡∏±‡∏á‡∏á‡∏≤", "‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á", "‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£", "‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å", "‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ", "‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå", "‡πÅ‡∏û‡∏£‡πà", "‡∏û‡∏∞‡πÄ‡∏¢‡∏≤", "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï",
        "‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°", "‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£", "‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô", "‡∏¢‡∏∞‡∏•‡∏≤", "‡∏¢‡πÇ‡∏™‡∏ò‡∏£", "‡∏£‡∏∞‡∏ô‡∏≠‡∏á", "‡∏£‡∏∞‡∏¢‡∏≠‡∏á", "‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ",
        "‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î", "‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ", "‡∏•‡∏≥‡∏õ‡∏≤‡∏á", "‡∏•‡∏≥‡∏û‡∏π‡∏ô", "‡πÄ‡∏•‡∏¢", "‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©", "‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£", "‡∏™‡∏á‡∏Ç‡∏•‡∏≤", "‡∏™‡∏ï‡∏π‡∏•",
        "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£", "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°", "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£", "‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß", "‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ", "‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ", "‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢",
        "‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ", "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ", "‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå", "‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢", "‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π", "‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á", "‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ",
        "‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ", "‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå", "‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ", "‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç"
    ]

    def extract_clean_plate(value):
        if pd.isnull(value) or str(value).strip() == "":
            return None
        text = str(value).strip()
        for prov in province_list:
            if prov in text:
                text = text.replace(prov, "").strip()
        if '//' in text:
            text = text.split('//')[0].strip()
        elif '/' in text:
            text = text.split('/')[0].strip()
        text_cleaned = text.replace('-', '').replace('/', '').replace(',', '').replace('+', '').replace(' ', '')
        text_cleaned = re.sub(r'^‡∏õ\d+‡πÅ‡∏•‡∏∞‡∏õ\d+\+?', '', text_cleaned)
        text_cleaned = re.sub(r'^‡∏õ\d+\+?', '', text_cleaned)
        text_cleaned = re.sub(r'^‡∏á‡∏≤‡∏ô‡∏õ\d+', '', text_cleaned)
        pattern_plate = r'(\d{1}[‡∏Å-‡∏Æ]{2}\d{1,4}|[‡∏Å-‡∏Æ]{1,3}\d{1,4})'
        match_plate = re.match(pattern_plate, text_cleaned)
        if match_plate:
            plate = match_plate.group(1)
            if len(plate) <= 3:
                return None
            return plate
        return None

    def extract_province(value):
        if pd.isnull(value) or str(value).strip() == "":
            return None
        for prov in province_list:
            if prov in str(value):
                return prov
        return None

    df1['id_car'] = df1['idcar'].apply(extract_clean_plate)
    df1['province_car'] = df1['idcar'].apply(extract_province)
    df1.drop(columns=['idcar'], inplace=True)

    df1 = df1[~df1['id_cus'].isin(['‡∏ó‡∏®‡∏û‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö', '‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö', 'FIN-TestApp'])]
    df1.rename(columns={
        'datekey': 'transaction_date',
        'nocar': 'car_code',
        'type_ins': 'type_insurance',
        'tunprakan': 'sum_insured',
        'deduct': 'deductible'
    }, inplace=True)
    df1['input_type'] = 'manual'

    # --- ‡∏£‡∏ß‡∏°‡∏™‡∏≠‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á ---
    df_combined = pd.concat([df, df1], ignore_index=True, sort=False)

    # --- ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô NaN/None ---
    for col in df_combined.columns:
        if df_combined[col].dtype == 'object':
            df_combined[col] = df_combined[col].replace(r'^\s*$', np.nan, regex=True)
    df_combined = df_combined.where(pd.notnull(df_combined), None)

    # --- ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏±‡∏ß‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏™‡∏ï‡∏£‡∏¥‡∏á ---
    for col in df_combined.columns:
        if df_combined[col].dtype == 'object':
            df_combined[col] = df_combined[col].apply(lambda x: x.lstrip() if isinstance(x, str) else x)

    # --- ‡∏ï‡∏±‡∏î test users ---
    df_combined = df_combined[~df_combined['id_cus'].isin([
        'FIN-TestApp', 'FIN-TestApp2', 'FIN-TestApp3',
        'FIN-TestApp6', 'FIN-TestApp-2025', 'FNGtest', '????‚ô°‚òÜumata‚òÜ??'
    ])]

    # --- ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏á‡∏¥‡∏ô: ‡πÄ‡∏≠‡∏≤‡∏•‡∏π‡∏Å‡∏ô‡πâ‡∏≥/‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ---
    for c in ["sum_insured", "deductible"]:
        if c in df_combined.columns:
            df_combined[c] = normalize_money(df_combined[c])

    # --- ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡∏ö vectorized ‡πÄ‡∏õ‡πá‡∏ô YYYYMMDD (Int64) ---
    date_columns = ['transaction_date']
    for col in date_columns:
        if col in df_combined.columns:
            df_combined[col] = pd.to_datetime(df_combined[col], errors='coerce')
            df_combined[col] = df_combined[col].dt.strftime('%Y%m%d').astype('Int64')

    # --- types ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ---
    df_combined['yearcar'] = pd.to_numeric(df_combined['yearcar'], errors='coerce').astype('Int64')
    df_combined['id_cus'] = df_combined['id_cus'].astype(str)

    # --- ‡πÅ‡∏õ‡∏•‡∏á NaN -> None ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ ---
    df_combined = df_combined.replace({np.nan: None})

    # --- ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å ---
    drop_cols = ['results', 'selected']
    for c in drop_cols:
        if c in df_combined.columns:
            df_combined.drop(columns=[c], inplace=True)

    # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å ---
    print("üßæ Columns before load:", df_combined.columns.tolist())

    return df_combined

@op
def load_check_price_data(df: pd.DataFrame):
    try:
        table_name = 'fact_check_price'
        tbl = Table(table_name, MetaData(), autoload_with=target_engine)

        # ‚úÖ ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á
        valid_cols = set(tbl.columns.keys())
        df = df[[c for c in df.columns if c in valid_cols]]

        df = df.replace({np.nan: None})
        records = df.to_dict(orient='records')

        if not records:
            print("‚ÑπÔ∏è No records to insert.")
            return

        with target_engine.begin() as conn:
            stmt = tbl.insert().values(records)
            conn.execute(stmt)

        print(f"‚úÖ Insert completed: {len(records)} rows inserted (duplicates allowed).")
    except Exception as e:
        print(f"‚ùå Error in load_check_price_data: {e}")
        raise

@job
def fact_check_price_etl():
    load_check_price_data(clean_check_price_data(extract_check_price_data()))

if __name__ == "__main__":
    df_raw = extract_check_price_data()
    # print("‚úÖ Extracted logs:", df_raw.shape)

    df_clean = clean_check_price_data(df_raw)
#     print("‚úÖ Cleaned columns:", df_clean.columns)

    # output_path = "fact_check_price.csv"
    # df_clean.to_csv(output_path, index=False, encoding='utf-8-sig')
    # print(f"üíæ Saved to {output_path}")

    # output_path = "fact_check_price1.xlsx"
    # df_clean.to_excel(output_path, index=False, engine='openpyxl')
    # print(f"üíæ Saved to {output_path}")

    load_check_price_data(df_clean)
    print("üéâ completed! Data upserted to fact_check_price.")
