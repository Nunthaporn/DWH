from dagster import op, job
import pandas as pd
import numpy as np
import re
import os
from datetime import date
from dotenv import load_dotenv
from sqlalchemy import create_engine, MetaData, Table, inspect
from sqlalchemy.dialects.postgresql import insert as pg_insert
from fuzzywuzzy import fuzz

# âœ… à¹‚à¸«à¸¥à¸” .env
load_dotenv()

# âœ… DB Connections
source_engine = create_engine(
    f"mysql+pymysql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/fininsurance"
)

target_engine = create_engine(
    f"postgresql+psycopg2://{os.getenv('DB_USER_test')}:{os.getenv('DB_PASSWORD_test')}@{os.getenv('DB_HOST_test')}:{os.getenv('DB_PORT_test')}/fininsurance"
)

@op
def extract_customer_data():
    query_pay = """
        SELECT quo_num, address, province, amphoe, district, zipcode, datestart
        FROM fin_system_pay
        WHERE datestart >= '2025-01-01' AND datestart < '2025-08-10'
    """
    df_pay = pd.read_sql(query_pay, source_engine)

    query_plan = """
        SELECT quo_num, idcard, title, name, lastname, birthDate, career, gender, tel, email, datestart
        FROM fin_system_select_plan
        WHERE datestart >= '2025-01-01' AND datestart < '2025-08-10'
    """
    df_plan = pd.read_sql(query_plan, source_engine)

    df_merged = pd.merge(df_pay, df_plan, on='quo_num', how='right')
    df_merged = df_merged.replace(r'NaN', np.nan, regex=True)
    return df_merged

@op
def clean_customer_data(df: pd.DataFrame):
    df = df.drop(columns=['datestart_x', 'datestart_y'], errors='ignore')

    df['full_name'] = df.apply(
        lambda row: row['name'] if str(row['name']).strip() == str(row['lastname']).strip()
        else f"{str(row['name']).strip()} {str(row['lastname']).strip()}",
        axis=1
    )

    df = df.drop(columns=['name', 'lastname', 'quo_num'])

    df['birthDate'] = pd.to_datetime(df['birthDate'], errors='coerce')
    df['birthDate'] = df['birthDate'].where(df['birthDate'].notna(), None)

    df['age'] = df['birthDate'].apply(
        lambda x: (
            date.today().year - x.year - ((date.today().month, date.today().day) < (x.month, x.day))
            if isinstance(x, pd.Timestamp) else pd.NA
        )
    ).astype('Int64')

    df = df.rename(columns={
        'idcard': 'customer_card',
        'title': 'title',
        'full_name': 'customer_name',
        'birthDate': 'customer_dob',
        'gender': 'customer_gender',
        'tel': 'customer_telnumber',
        'email': 'customer_email',
        'address': 'address',
        'province': 'province',
        'amphoe': 'district',
        'district': 'subdistrict',
        'zipcode': 'zipcode',
        'career': 'job'
    })

    df['customer_dob'] = df['customer_dob'].apply(lambda x: x if isinstance(x, pd.Timestamp) else None)
    df['customer_dob'] = df['customer_dob'].astype(object)
    df['customer_gender'] = df['customer_gender'].astype(str).str.strip().str.lower()
    df['customer_gender'] = df['customer_gender'].replace({
        'M': 'Male',
        'à¸Šà¸²à¸¢': 'Male',
        'F': 'Female',
        'à¸«à¸à¸´à¸‡': 'Female',
        'à¸­à¸·à¹ˆà¸™à¹†': 'Other',
        'O': 'Other'
    })

    valid_genders = ['Male', 'Female', 'Other']
    df['customer_gender'] = df['customer_gender'].where(df['customer_gender'].isin(valid_genders), None)

    df['customer_name'] = df['customer_name'].str.replace(r'\s*None$', '', regex=True)
    df['customer_telnumber'] = df['customer_telnumber'].str.replace('-', '', regex=False)
    df['address'] = df['address'].str.replace('-', '', regex=False).str.strip()
    df['address'] = df['address'].str.replace(r'^[à¸¸à¸¹à¸¶à¸·à¸´]+', '', regex=True)
    df['address'] = df['address'].str.replace(r'\([^)]*\)', '', regex=True)
    df['address'] = df['address'].str.lstrip(':').replace('/', pd.NA).replace('', pd.NA)
    df['customer_email'] = df['customer_email'].str.replace('_', '', regex=False)
    df['title'] = df['title'].str.replace('â€˜à¸™à¸²à¸¢', 'à¸™à¸²à¸¢', regex=False).str.strip()

    test_names = [
        'à¸—à¸”à¸ªà¸­à¸š', 'à¸—à¸”à¸ªà¸­à¸š ', 'à¸—à¸”à¸ªà¸­à¸š à¸ˆà¸²à¸à¸Ÿà¸´à¸™', 'à¸—à¸”à¸ªà¸­à¸š à¸.à¸£.à¸š.', 'à¸—à¸”à¸ªà¸­à¸š06',
        'à¸—à¸”à¸ªà¸­à¸šà¸£à¸°à¸šà¸š à¸›à¸£à¸°à¸à¸±à¸™+à¸.à¸£.à¸š.', 'à¸¥à¸¹à¸à¸„à¹‰à¸² à¸—à¸”à¸ªà¸­à¸š', 'à¸—à¸”à¸ªà¸­à¸š à¹€à¸Šà¹‡à¸„à¹€à¸šà¸µà¹‰à¸¢',
        'à¸—à¸”à¸ªà¸­à¸šà¸.à¸£.à¸š. à¸‡à¸²à¸™à¸„à¸µà¸¢à¹Œà¸¡à¸·à¸­', 'à¸—à¸”à¸ªà¸­à¸š à¸£à¸°à¸šà¸š', 'à¸—à¸”à¸ªà¸­à¸šà¸„à¸µà¸¢à¹Œà¸¡à¸·à¸­ à¸˜à¸™à¸Šà¸²à¸•à¸œà¸¹à¹‰à¸‚à¸±à¸šà¸‚à¸µà¹ˆ',
        'à¸—à¸”à¸ªà¸­à¸š04', 'test', 'test2', 'test tes', 'test à¸£à¸°à¸šà¸š', 'Tes à¸£à¸°à¸šà¸š'
    ]
    df = df[~df['customer_name'].isin(test_names)]

    def clean_tel(val):
        if pd.isnull(val) or val.strip() == "":
            return None
        digits = re.sub(r'\D', '', val)
        return digits if digits else None

    df['customer_telnumber'] = df['customer_telnumber'].apply(clean_tel)

    # âœ… à¸¥à¸š fuzzy duplicates à¹à¸šà¸šà¹€à¸¥à¸·à¸­à¸à¸Šà¸·à¹ˆà¸­à¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸° customer_card
    def remove_fuzzy_duplicates(df, threshold=90):
        df['customer_card_clean'] = df['customer_card'].astype(str).str.strip()
        df['customer_name_clean'] = df['customer_name'].astype(str).str.strip().str.lower()

        best_rows = []
        for card, group in df.groupby('customer_card_clean'):
            names = group['customer_name'].dropna().unique().tolist()
            if len(names) <= 1:
                best_rows.extend(group.index.tolist())
                continue
            best_name = max(names, key=lambda x: len(str(x).strip()))
            best_index = group[group['customer_name'] == best_name].index.tolist()
            best_rows.extend(best_index)

        return df.loc[best_rows].copy()

    df = remove_fuzzy_duplicates(df)

    # âœ… à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆ customer_card à¹à¸¥à¸° customer_name à¸‹à¹‰à¸³à¹à¸šà¸šà¹€à¸›à¹Šà¸°
    df = df.drop_duplicates(subset=['customer_card', 'customer_name']).copy()

    # âœ… à¸¥à¸šà¸­à¸±à¸à¸‚à¸£à¸°à¸—à¸µà¹ˆ Excel à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š
    def remove_illegal_excel_chars(text):
        if not isinstance(text, str):
            return text
        return re.sub(r'[\x00-\x1F\x7F]', '', text)

    for col in df.select_dtypes(include='object').columns:
        df[col] = df[col].apply(remove_illegal_excel_chars)

    df = df.drop(columns=['customer_card_clean', 'customer_name_clean'], errors='ignore')
    df = df.replace(r'NaN', np.nan, regex=True)
    return df

@op
def load_customer_data(df: pd.DataFrame):
    table_name = 'dim_customer'
    pk_columns = ['customer_card', 'customer_name']  # Composite key

    # âœ… à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸•à¸²à¸£à¸²à¸‡à¸¡à¸µ column 'quotation_num' à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ â€” à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸à¹‡à¸ªà¸£à¹‰à¸²à¸‡
    with target_engine.connect() as conn:
        inspector = inspect(conn)
        columns = [col['name'] for col in inspector.get_columns(table_name)]
        if 'quotation_num' not in columns:
            print("â• Adding missing column 'quotation_num' to dim_car")
            conn.execute(f'ALTER TABLE {table_name} ADD COLUMN quotation_num VARCHAR')

    # âœ… Drop duplicates à¸•à¸²à¸¡ composite key
    df = df.drop_duplicates(subset=pk_columns).copy()

    with target_engine.connect() as conn:
        df_existing = pd.read_sql(f"SELECT * FROM {table_name}", conn)

    df_existing = df_existing.drop_duplicates(subset=pk_columns).copy()

    # âœ… à¸ªà¸£à¹‰à¸²à¸‡ key à¹€à¸à¸·à¹ˆà¸­à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹à¸¥à¸°à¸ˆà¸±à¸”à¸à¸²à¸£ insert/update
    def make_key(df):
        return df[pk_columns].astype(str).agg('|'.join, axis=1)

    df['merge_key'] = make_key(df)
    df_existing['merge_key'] = make_key(df_existing)

    new_keys = set(df['merge_key']) - set(df_existing['merge_key'])
    common_keys = set(df['merge_key']) & set(df_existing['merge_key'])

    df_to_insert = df[df['merge_key'].isin(new_keys)].copy()
    df_common_new = df[df['merge_key'].isin(common_keys)].copy()
    df_common_old = df_existing[df_existing['merge_key'].isin(common_keys)].copy()

    # âœ… ğŸ”¥ à¹à¸›à¸¥à¸‡ NaT â†’ None à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸¸à¸ datetime column à¸à¹ˆà¸­à¸™ insert
    for col in df_to_insert.select_dtypes(include=['datetime64[ns]', 'datetimetz']).columns:
        df_to_insert[col] = df_to_insert[col].apply(lambda x: x if pd.notna(x) else None)

    merged = df_common_new.merge(df_common_old, on=pk_columns, suffixes=('_new', '_old'))

    exclude_columns = pk_columns + ['customer_sk', 'create_at', 'update_at']
    compare_cols = [
        col for col in df.columns
        if col not in exclude_columns
        and f"{col}_new" in merged.columns
        and f"{col}_old" in merged.columns
    ]

    def is_different(row):
        for col in compare_cols:
            if pd.isna(row[f"{col}_new"]) and pd.isna(row[f"{col}_old"]):
                continue
            if row[f"{col}_new"] != row[f"{col}_old"]:
                return True
        return False

    df_diff = merged[merged.apply(is_different, axis=1)].copy()
    update_cols = [f"{col}_new" for col in compare_cols]
    df_diff_renamed = df_diff[pk_columns + update_cols].copy()
    df_diff_renamed.columns = pk_columns + compare_cols

    metadata = Table(table_name, MetaData(), autoload_with=target_engine)

    if not df_to_insert.empty:
        with target_engine.begin() as conn:
            conn.execute(metadata.insert(), df_to_insert.drop(columns=['merge_key']).to_dict(orient='records'))

    if not df_diff_renamed.empty:
        with target_engine.begin() as conn:
            for record in df_diff_renamed.to_dict(orient='records'):
                stmt = pg_insert(metadata).values(**record)
                update_columns = {
                    c.name: stmt.excluded[c.name]
                    for c in metadata.columns
                    if c.name not in pk_columns
                }
                stmt = stmt.on_conflict_do_update(
                    index_elements=pk_columns,
                    set_=update_columns
                )
                conn.execute(stmt)

    print(f"ğŸ†• Insert: {len(df_to_insert)} rows")
    print(f"ğŸ”„ Update: {len(df_diff_renamed)} rows")

# âœ… Dagster job
@job
def dim_customer_etl():
    load_customer_data(clean_customer_data(extract_customer_data()))

if __name__ == "__main__":
    df_raw = extract_customer_data()
    print("âœ… Extracted logs:", df_raw.shape)

    df_clean = clean_customer_data((df_raw))
    print("âœ… Cleaned columns:", df_clean.columns)

    # print(df_clean.head(10))

    output_path = "dim_customer.csv"
    df_clean.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ Saved to {output_path}")

    # output_path = "dim_customer.xlsx"
    # df_clean.to_excel(output_path, index=False, engine='openpyxl')
    # print(f"ğŸ’¾ Saved to {output_path}")

    # load_customer_data(df_clean)
    # print("ğŸ‰ Test completed! Data upserted to dim_customer.")