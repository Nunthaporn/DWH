{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdde54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "\n",
    "# à¹‚à¸«à¸¥à¸”à¸•à¸±à¸§à¹à¸›à¸£à¸ˆà¸²à¸ .env\n",
    "load_dotenv()\n",
    "\n",
    "# à¸”à¸¶à¸‡à¸„à¹ˆà¸²à¸ˆà¸²à¸ environment\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')  \n",
    "database = 'fininsurance'\n",
    "\n",
    "# à¸ªà¸£à¹‰à¸²à¸‡ engine à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥\n",
    "engine = create_engine(f'mariadb+mariadbconnector://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# SQL query\n",
    "query = \"\"\"\n",
    "SELECT quo_num,type_insure,type_work,datestart,id_government_officer,status_gpf , quo_num_old, type_status , type_key , app_type, chanel_key,status as status_fssp\n",
    "FROM fin_system_select_plan \n",
    "WHERE datestart >= '2025-05-01' AND datestart < '2025-07-01'\n",
    "AND type_insure IN ('à¸›à¸£à¸°à¸à¸±à¸™à¸£à¸–', 'à¸•à¸£à¸­')\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, engine)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')  \n",
    "database = 'fininsurance_task'\n",
    "\n",
    "engine = create_engine(f'mariadb+mariadbconnector://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT quo_num,order_number,worksend, chanel, datekey,status as status_fo\n",
    "FROM fin_order\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(query, engine)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')  \n",
    "database = 'fininsurance'\n",
    "\n",
    "engine = create_engine(f'mariadb+mariadbconnector://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT quo_num,datestart, numpay, show_price_ins, show_price_prb, show_price_total, show_price_check, show_price_service, show_price_taxcar, show_price_fine, show_price_addon, show_price_payment, distax, show_ems_price, show_discount_ins, discount_mkt, discount_government, discount_government_fin, discount_government_ins, coupon_addon,status as status_fsp\n",
    "FROM fin_system_pay \n",
    "WHERE datestart >= '2025-05-01' AND datestart < '2025-07-01'\n",
    "AND type_insure IN ('à¸›à¸£à¸°à¸à¸±à¸™à¸£à¸–', 'à¸•à¸£à¸­')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df2 = pd.read_sql(query, engine)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117489c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, df1, on='quo_num', how='left')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b871b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1 = pd.merge(df_merged, df2, on='quo_num', how='left')\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fill_chanel_key(row):\n",
    "    chanel_key = row['chanel_key']\n",
    "    type_key = row['type_key']\n",
    "    app_type = row['app_type']\n",
    "    type_insure = row['type_insure']\n",
    "\n",
    "    # à¸–à¹‰à¸² chanel_key à¸¡à¸µà¸„à¹ˆà¸²à¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§\n",
    "    if pd.notnull(chanel_key) and str(chanel_key).strip() != \"\":\n",
    "        return chanel_key\n",
    "\n",
    "    # à¸–à¹‰à¸²à¸—à¸±à¹‰à¸‡ type_key à¹à¸¥à¸° app_type à¹„à¸¡à¹ˆ null\n",
    "    if pd.notnull(type_key) and pd.notnull(app_type):\n",
    "        if type_key == app_type:\n",
    "            if type_insure == 'à¸•à¸£à¸­':\n",
    "                return f\"{type_key} VIF\"\n",
    "            else:\n",
    "                return type_key\n",
    "        else:\n",
    "            if type_key in app_type:\n",
    "                base = app_type.replace(type_key, \"\").replace(\"-\", \"\").strip()\n",
    "                return f\"{type_key} {base}\" if base else type_key\n",
    "            elif app_type in type_key:\n",
    "                base = type_key.replace(app_type, \"\").replace(\"-\", \"\").strip()\n",
    "                return f\"{app_type} {base}\" if base else app_type\n",
    "            else:\n",
    "                return f\"{type_key} {app_type}\"\n",
    "\n",
    "    # à¸–à¹‰à¸²à¸¡à¸µà¹à¸„à¹ˆ type_key\n",
    "    if pd.notnull(type_key) and (pd.isnull(app_type) or str(app_type).strip() == \"\"):\n",
    "        if pd.notnull(type_insure) and str(type_insure).strip() != \"\":\n",
    "            return f\"{type_key} {type_insure}\"\n",
    "        else:\n",
    "            return type_key\n",
    "\n",
    "    # à¸–à¹‰à¸²à¸¡à¸µà¹à¸„à¹ˆ app_type\n",
    "    if pd.notnull(app_type) and (pd.isnull(type_key) or str(type_key).strip() == \"\"):\n",
    "        if pd.notnull(type_insure) and str(type_insure).strip() != \"\":\n",
    "            return f\"{app_type} {type_insure}\"\n",
    "        else:\n",
    "            return app_type\n",
    "\n",
    "    # à¹„à¸¡à¹ˆà¸¡à¸µà¸­à¸°à¹„à¸£à¹€à¸¥à¸¢\n",
    "    return None\n",
    "\n",
    "# apply à¸à¸¥à¸±à¸š\n",
    "df_merged1['chanel_key'] = df_merged1.apply(fill_chanel_key, axis=1)\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1['chanel_key'] = df_merged1['chanel_key'].replace({\n",
    "    'B2B': 'APP B2B',\n",
    "    'WEB à¸•à¸£à¸­': 'WEB VIF',\n",
    "    'TELE': 'APP TELE',\n",
    "    'APP-B2C': 'APP B2C',\n",
    "    'APP à¸›à¸£à¸°à¸à¸±à¸™à¸£à¸–' : 'APP B2B',\n",
    "    'WEB à¸›à¸£à¸°à¸à¸±à¸™à¸£à¸–': 'WEB'\n",
    "})\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1.drop(columns=['type_key', 'app_type'], inplace=True)\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791765e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1.rename(columns={\n",
    "    \"quo_num\": \"quotation_num\",\n",
    "    \"datestart_x\": \"quotation_date\",\n",
    "    \"datestart_y\": \"transaction_date\",\n",
    "    \"datekey\": \"order_time\",\n",
    "    \"type_insure\": \"type_insurance\",\n",
    "    \"type_work\": \"order_type\",\n",
    "    \"id_government_officer\": \"rights_government\",\n",
    "    \"status_gpf\": \"goverment_type\",\n",
    "    \"type_status\": \"check_type\",\n",
    "    \"type_key\": \"key_channel\",\n",
    "    \"quo_num_old\": \"quotation_num_old\",\n",
    "    \"numpay\": \"installment_number\",\n",
    "    \"show_price_ins\": \"ins_amount\",\n",
    "    \"show_price_prb\": \"prb_amount\",\n",
    "    \"show_price_total\": \"total_amount\",\n",
    "    \"show_price_check\": \"show_price_check\",\n",
    "    \"show_price_service\": \"service_price\",\n",
    "    \"show_price_taxcar\": \"tax_car_price\",\n",
    "    \"show_price_fine\": \"overdue_fine_price\",\n",
    "    \"show_price_addon\": \"price_addon\",\n",
    "    \"show_price_payment\": \"payment_amount\",\n",
    "    \"distax\": \"tax_amount\",\n",
    "    \"show_ems_price\": \"ems_amount\",\n",
    "    \"show_discount_ins\": \"ins_discount\",\n",
    "    \"discount_mkt\": \"mkt_discount\",\n",
    "    \"discount_government\": \"goverment_discount\",\n",
    "    \"discount_government_fin\": \"fin_goverment_discount\",\n",
    "    \"discount_government_ins\": \"ins_goverment_discount\",\n",
    "    \"coupon_addon\": \"discount_addon\",\n",
    "    \"worksend\": \"work_type\",\n",
    "    \"chanel\": \"contact_channel\",\n",
    "    \"chanel_key\": \"key_channel\"\n",
    "}, inplace=True)\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1252d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_merged1 = df_merged1.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "df_merged1 = df_merged1.where(pd.notnull(df_merged1), None)\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eecc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# à¹à¸›à¸¥à¸‡à¸—à¸¸à¸à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹ƒà¸™ df_merged1 à¸–à¹‰à¸²à¸¡à¸µà¸„à¹ˆà¸²à¹€à¸›à¹‡à¸™ string \"NAN\" à¹ƒà¸«à¹‰à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™ np.nan\n",
    "df_merged1 = df_merged1.replace(\"NaN\", np.nan)\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1 = df_merged1.drop_duplicates(subset=['quotation_num'], keep='first')\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1['installment_number'] = df_merged1['installment_number'].replace({\n",
    "    '0': '1',\n",
    "    '03': '3',\n",
    "    '06': '6',\n",
    "    '08': '8'\n",
    "})\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e461855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# à¸ªà¸¡à¸¡à¸•à¸´ df_merged1 à¸¡à¸µà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ status_fssp, status_fsp, status_fo\n",
    "# df_merged1 = pd.DataFrame(...)\n",
    "\n",
    "def map_status(row):\n",
    "    # à¸–à¹‰à¸²à¸¡à¸µ status_fo à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸à¹ˆà¸­à¸™\n",
    "    if pd.notnull(row['status_fo']):\n",
    "        if row['status_fo'] == '88':\n",
    "            return 'cancel'\n",
    "        else:\n",
    "            return row['status_fo']\n",
    "    # à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ status_fo à¹ƒà¸«à¹‰à¸”à¸¹à¸„à¸¹à¹ˆ status_fssp, status_fsp\n",
    "    s1 = row.get('status_fssp')\n",
    "    s2 = row.get('status_fsp')\n",
    "    \n",
    "    if pd.isnull(s1): s1 = ''\n",
    "    if pd.isnull(s2): s2 = ''\n",
    "    \n",
    "    key = (s1.strip(), s2.strip())\n",
    "    \n",
    "    mapping = {\n",
    "        ('wait', ''): '1',\n",
    "        ('wait-key', ''): '1',\n",
    "        ('sendpay', 'sendpay'): '2',\n",
    "        ('sendpay', 'verify-wait'): '2',\n",
    "        ('tran-succ', 'sendpay'): '2',\n",
    "        ('tran-succ', 'verify-wait'): '2',\n",
    "        ('cancel', '88'): 'cancel',\n",
    "        ('delete', ''): 'delete',\n",
    "        ('wait', 'sendpay'): '2',\n",
    "        ('delete', 'sendpay'): 'delete',\n",
    "        ('delete', 'wait'): 'delete',\n",
    "        ('delete', 'wait-key'): 'delete',\n",
    "        ('wait', 'wait'): '1',\n",
    "        ('wait', 'wait-key'): '1',\n",
    "        ('', 'wait'): '1',\n",
    "        ('tran-succ', 'sendpay'): '2',\n",
    "        ('cancel', 'cancel'): 'cancel',\n",
    "        ('delete', 'delete'): 'delete',\n",
    "        ('active', 'verify'): '6',\n",
    "        ('active', 'success'): '8',\n",
    "        ('active', ''): '8',\n",
    "        ('cancel', ''): 'cancel'\n",
    "    }\n",
    "    \n",
    "    # à¸–à¹‰à¸²à¹„à¸¡à¹ˆ match à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ None à¸«à¸£à¸·à¸­à¸„à¹ˆà¸² default à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£\n",
    "    return mapping.get(key, None)\n",
    "\n",
    "# à¹€à¸à¸´à¹ˆà¸¡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹ƒà¸«à¸¡à¹ˆ\n",
    "df_merged1['status'] = df_merged1.apply(map_status, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1 = df_merged1[['quotation_num', 'status_fssp', 'status_fsp', 'status_fo', 'status']]\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged1.drop(columns=['status_fssp', 'status_fsp', 'status_fo'], inplace=True)\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da143195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "\n",
    "# à¹‚à¸«à¸¥à¸”à¸•à¸±à¸§à¹à¸›à¸£à¸ˆà¸²à¸ .env\n",
    "load_dotenv()\n",
    "\n",
    "# à¸”à¸¶à¸‡à¸„à¹ˆà¸²à¸ˆà¸²à¸ environment\n",
    "user = os.getenv('DB_USER_test')\n",
    "password = os.getenv('DB_PASSWORD_test')\n",
    "host = os.getenv('DB_HOST_test')\n",
    "port = os.getenv('DB_PORT_test')  \n",
    "database = 'fininsurance'\n",
    "\n",
    "# à¸ªà¸£à¹‰à¸²à¸‡ engine à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# SQL query\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM fact_sales_quotation \n",
    "\"\"\"\n",
    "\n",
    "df6 = pd.read_sql(query, engine)\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df6.drop(columns=['create_at', 'update_at', 'status'])\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7adbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result1 = pd.merge(df_merged1, df6, on=['quotation_num'], how='right')\n",
    "df_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result1 = df_result1.drop_duplicates(subset=['quotation_num'], keep='last')\n",
    "df_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result1 = df_result1[['quotation_num', 'status']]\n",
    "df_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# à¹à¸à¹‰ NaT, NaN à¸—à¸±à¹‰à¸‡ dataframe à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ None\n",
    "df_result1 = df_result1.where(pd.notnull(df_result1), None)\n",
    "df_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b62374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, MetaData, Table, update\n",
    "from sqlalchemy import text\n",
    "\n",
    "user = os.getenv('DB_USER_test')\n",
    "password = os.getenv('DB_PASSWORD_test')\n",
    "host = os.getenv('DB_HOST_test')\n",
    "port = os.getenv('DB_PORT_test')\n",
    "database = 'fininsurance'\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "metadata = MetaData()\n",
    "table = Table('fact_sales_quotation', metadata, autoload_with=engine)\n",
    "\n",
    "records = df_result1.to_dict(orient='records')\n",
    "\n",
    "chunk_size = 5000\n",
    "\n",
    "for start in range(0, len(records), chunk_size):\n",
    "    end = start + chunk_size\n",
    "    chunk = records[start:end]\n",
    "\n",
    "    print(f\"ğŸ”„ Updating chunk {start // chunk_size + 1}: records {start} to {end - 1}\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        for record in chunk:\n",
    "            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µ quotation_num à¹à¸¥à¸° status à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ\n",
    "            if 'quotation_num' not in record or pd.isna(record['quotation_num']):\n",
    "                print(f\"âš ï¸ Skip row: no quotation_num: {record}\")\n",
    "                continue\n",
    "            if 'status' not in record or pd.isna(record['status']):\n",
    "                print(f\"âš ï¸ Skip row: no status: {record}\")\n",
    "                continue\n",
    "\n",
    "            # âœ… Update à¹€à¸‰à¸à¸²à¸°à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¹€à¸”à¸µà¸¢à¸§\n",
    "            stmt = (\n",
    "                update(table)\n",
    "                .where(table.c.quotation_num == record['quotation_num'])\n",
    "                .values(status=record['status'])\n",
    "            ) \n",
    "            conn.execute(stmt)\n",
    "\n",
    "print(\"âœ… Update status completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_save = ['status_fssp', 'status_fsp', 'status_fo']\n",
    "# df_selected = df_merged1[columns_to_save]\n",
    "# df_selected.to_excel('status.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9874c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged2.to_excel('quo.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a3f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
