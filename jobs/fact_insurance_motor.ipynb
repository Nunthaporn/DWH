{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdde54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "\n",
    "# โหลดตัวแปรจาก .env\n",
    "load_dotenv()\n",
    "\n",
    "# ดึงค่าจาก environment\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')  \n",
    "database = 'fininsurance'\n",
    "\n",
    "# สร้าง engine สำหรับเชื่อมต่อฐานข้อมูล\n",
    "engine = create_engine(f'mariadb+mariadbconnector://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# SQL query\n",
    "query = \"\"\"\n",
    "SELECT quo_num,company, company_prb,assured_insurance_capital1,is_addon,type,repair_type\n",
    "FROM fin_system_select_plan WHERE datestart >= '2025-06-01' AND datestart < '2025-07-01' and type_insure = 'ประกันรถ'\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# โหลดข้อมูลจากฐานข้อมูล\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# แปลงให้ pandas เข้าใจได้แน่นอน\n",
    "# df['user_registered'] = pd.to_datetime(df['user_registered'].astype(str), errors='coerce')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')  \n",
    "database = 'fininsurance_task'\n",
    "\n",
    "engine = create_engine(f'mariadb+mariadbconnector://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT quo_num,responsibility1,responsibility2,responsibility3,responsibility4,damage1,damage2,damage3,damage4,protect1,protect2,protect3,protect4,\n",
    "if(sendtype = 'ที่อยู่ใหม่',provincenew,province) as delivery_province,\n",
    "show_ems_price,show_ems_type\n",
    "\n",
    "FROM fin_order WHERE datekey >= '2025-06-01' AND datekey < '2025-07-01'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(query, engine)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')  \n",
    "database = 'fininsurance'\n",
    "\n",
    "engine = create_engine(f'mariadb+mariadbconnector://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT quo_num,date_warranty,date_exp\n",
    "\n",
    "FROM fin_system_pay WHERE datestart >= '2025-06-01' AND datestart < '2025-07-01'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df2 = pd.read_sql(query, engine)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117489c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.copy()\n",
    "\n",
    "df_merged = pd.merge(df_merged, df1, on='quo_num', how='left')\n",
    "df_merged = pd.merge(df_merged, df2, on='quo_num', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(a, b):\n",
    "    a_str = str(a).strip() if pd.notna(a) else ''\n",
    "    b_str = str(b).strip() if pd.notna(b) else ''\n",
    "    \n",
    "    if a_str == '' and b_str == '':\n",
    "        return ''\n",
    "    elif a_str == '':\n",
    "        return b_str\n",
    "    elif b_str == '':\n",
    "        return a_str\n",
    "    elif a_str == b_str:\n",
    "        return a_str\n",
    "    else:\n",
    "        return f\"ชั้น{a_str} {b_str}\"\n",
    "\n",
    "df_merged['insurance_class'] = df_merged.apply(lambda row: combine_columns(row['type'], row['repair_type']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971aafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_merged.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeefa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop(columns=['type','repair_type'])\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f639c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)\n",
    "##car_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e545c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_columns = {\n",
    "    \"quo_num\": \"quotation_num\",\n",
    "    \"responsibility1\": \"human_coverage_person\",\n",
    "    \"responsibility2\": \"human_coverage_atime\",\n",
    "    \"responsibility3\": \"property_coverage\",\n",
    "    \"responsibility4\": \"deductible\",\n",
    "    \"damage1\": \"vehicle_damage\",\n",
    "    \"damage2\": \"deductible_amount\",\n",
    "    \"damage3\": \"vehicle_theft_fire\",\n",
    "    \"damage4\": \"vehicle_flood_damage\",\n",
    "    \"protect1\": \"personal_accident_driver\",\n",
    "    \"protect2\": \"personal_accident_passengers\",\n",
    "    \"protect3\": \"medical_coverage\",\n",
    "    \"protect4\": \"driver_coverage\",\n",
    "    \"company\": \"ins_company\",\n",
    "    \"company_prb\": \"act_ins_company\",\n",
    "    \"assured_insurance_capital1\": \"sum_insured\",\n",
    "    \"date_warranty\": \"date_warranty\",\n",
    "    \"date_exp\": \"date_expired\",\n",
    "    \"insurance_class\": \"insurance_class\",\n",
    "    \"show_ems_price\": \"ems_amount\",\n",
    "    \"show_ems_type\": \"delivery_type\",\n",
    "    \"is_addon\": \"income_comp_ins\"\n",
    "}\n",
    "\n",
    "df = df_merged.rename(columns=rename_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['insurance_class'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(df_cleaned.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308dd74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cleaned.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(r'^\\s*$', pd.NA, regex=True)  \n",
    "df = df[df.count(axis=1) > 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# แปลงช่องว่างทุกแบบเป็น NaN ชั่วคราว เพื่อการนับข้อมูล\n",
    "df_temp = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# เพิ่มคอลัมน์ช่วยนับจำนวนข้อมูล (non-null)\n",
    "df['non_empty_count'] = df_temp.notnull().sum(axis=1)\n",
    "\n",
    "# >>>> ส่วนที่แก้ไขตรงนี้ <<<<\n",
    "# ตรวจสอบ agent_id ที่ไม่ว่าง (ไม่ใช่ NaN และไม่ใช่ช่องว่าง)\n",
    "valid_agent_id_mask = df['quotation_num'].astype(str).str.strip().ne('') & df['quotation_num'].notna()\n",
    "\n",
    "# แยกกลุ่มที่ agent_id ไม่ว่างและ agent_id ว่าง\n",
    "df_with_id = df[valid_agent_id_mask]\n",
    "df_without_id = df[~valid_agent_id_mask]\n",
    "\n",
    "# คัดแถวที่ agent_id ซ้ำ โดยเก็บแถวที่มีข้อมูลมากที่สุด\n",
    "df_with_id_cleaned = df_with_id.sort_values('non_empty_count', ascending=False).drop_duplicates(subset='quotation_num', keep='first')\n",
    "\n",
    "# รวมกลับ\n",
    "df_cleaned = pd.concat([df_with_id_cleaned, df_without_id], ignore_index=True)\n",
    "\n",
    "# ลบคอลัมน์ช่วย\n",
    "df_cleaned = df_cleaned.drop(columns=['non_empty_count'])\n",
    "df_cleaned = df_cleaned.replace(\n",
    "    to_replace=r'^\\s*$|(?i:^none$)|^-$',  # << แก้ตรงนี้\n",
    "    value=np.nan,\n",
    "    regex=True\n",
    ")\n",
    "\n",
    "\n",
    "df_cleaned.columns = df_cleaned.columns.str.lower()\n",
    "df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.replace(np.nan, \"NaN\").isin([\"none\", \"-\", \"None\"]).sum()\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned.to_csv('dim_car1.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aecaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.replace(r'^\\.$', np.nan, regex=True)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['income_comp_ins'] = df_cleaned['income_comp_ins'].apply(lambda x: True if x == 1 else False if x == 0 else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_clean = [\n",
    "    'sum_insured', 'human_coverage_person', 'human_coverage_atime',\n",
    "    'property_coverage', 'deductible', 'vehicle_damage', 'deductible_amount',\n",
    "    'vehicle_theft_fire', 'vehicle_flood_damage', 'personal_accident_driver',\n",
    "    'personal_accident_passengers', 'medical_coverage', 'driver_coverage',\n",
    "    'ems_amount'\n",
    "]\n",
    "for col in cols_to_clean:\n",
    "    df_cleaned[col] = (\n",
    "        df_cleaned[col]\n",
    "        .astype(str)\n",
    "        .str.replace(',', '', regex=False)\n",
    "        .str.strip()\n",
    "        .apply(lambda x: float(x) if x not in ['', 'None', 'nan', 'NaN'] else None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.where(pd.notnull(df_cleaned), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_cleaned['insurance_class'] = df_cleaned['insurance_class'].replace({\n",
    "    'ซ่อมอู่': np.nan  # ใช้ NaN ซึ่งจะกลายเป็น NULL ตอนเขียนลง PostgreSQL\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50238049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['date_warranty'] = pd.to_datetime(df_cleaned['date_warranty'], errors='coerce')\n",
    "df_cleaned['date_expired'] = pd.to_datetime(df_cleaned['date_expired'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "int_columns = [\n",
    "    \"sum_insured\", \"human_coverage_person\", \"human_coverage_atime\", \"property_coverage\",\n",
    "    \"deductible\", \"vehicle_damage\", \"deductible_amount\", \"vehicle_theft_fire\",\n",
    "    \"vehicle_flood_damage\", \"personal_accident_driver\", \"personal_accident_passengers\",\n",
    "    \"medical_coverage\", \"driver_coverage\", \"ems_amount\"\n",
    "]\n",
    "\n",
    "for col in int_columns:\n",
    "    if col in df_cleaned.columns:\n",
    "        # แปลงเป็น numeric coercing error เป็น NaN\n",
    "        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "        # ถ้าอยากเก็บ NULL ในฐานข้อมูล → ใช้ dtype \"Int64\" ของ Pandas\n",
    "        df_cleaned[col] = df_cleaned[col].astype(\"Int64\")\n",
    "\n",
    "# แปลง NaN เป็น None เพื่อเตรียม insert\n",
    "df_cleaned = df_cleaned.where(pd.notnull(df_cleaned), None)\n",
    "df_cleaned = df_cleaned.replace({np.nan: None})\n",
    "\n",
    "print(\"✅ จัดการ column int เรียบร้อยแล้ว\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from sqlalchemy.dialects.postgresql import insert  # ✅ ใช้ insert แบบ Postgres\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "host = os.getenv('DB_HOST_test')\n",
    "user = os.getenv('DB_USER_test')\n",
    "password = os.getenv('DB_PASSWORD_test')\n",
    "port = os.getenv('DB_PORT_test')\n",
    "database = 'fininsurance'\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# ✅ ทำให้ NaN เป็น None\n",
    "df_cleaned = df_cleaned.where(pd.notnull(df_cleaned), None)\n",
    "df_cleaned = df_cleaned.replace({np.nan: None})\n",
    "\n",
    "# ✅ กำหนด columns int ถ้ามี\n",
    "int_columns = [\n",
    "    \"deductible\", \"human_coverage_person\", \"human_coverage_atime\", \"property_coverage\",\n",
    "    \"personal_accident_driver\", \"personal_accident_passengers\", \"medical_coverage\",\n",
    "    \"driver_coverage\", \"sum_insured\", \"ems_amount\", \"vehicle_damage\", \"deductible_amount\",\n",
    "    \"vehicle_theft_fire\", \"vehicle_flood_damage\"\n",
    "]\n",
    "for col in int_columns:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce').round()\n",
    "\n",
    "df_cleaned = df_cleaned.where(pd.notnull(df_cleaned), None)\n",
    "\n",
    "# ✅ Upsert function\n",
    "def upsert_df_chunk_force(df: pd.DataFrame, table_name: str, key_column: str, chunk_size: int = 2000, schema: str = 'public'):\n",
    "    metadata = MetaData(schema=schema)\n",
    "    table = Table(table_name, metadata, autoload_with=engine)\n",
    "\n",
    "    df = df[df[key_column].notna()]\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    total_chunks = (total_rows // chunk_size) + (1 if total_rows % chunk_size else 0)\n",
    "\n",
    "    print(f\"🎯 Row ทั้งหมด: {total_rows:,} (แบ่ง {total_chunks} ชุด, chunk size: {chunk_size})\")\n",
    "\n",
    "    for i in range(0, total_rows, chunk_size):\n",
    "        df_chunk = df.iloc[i:i+chunk_size]\n",
    "        rows = df_chunk.to_dict(orient='records')\n",
    "        \n",
    "        stmt = insert(table).values(rows)\n",
    "        update_dict = {c.name: getattr(stmt.excluded, c.name) for c in table.columns if c.name != key_column}\n",
    "\n",
    "        stmt = stmt.on_conflict_do_update(\n",
    "            index_elements=[key_column],\n",
    "            set_=update_dict\n",
    "        )\n",
    "\n",
    "        with engine.begin() as conn:\n",
    "            result = conn.execute(stmt)\n",
    "            affected_rows = result.rowcount\n",
    "\n",
    "        print(f\"   🚀 Chunk {i//chunk_size+1}/{total_chunks} ✔️ affected: {affected_rows:,}\")\n",
    "\n",
    "    print(\"✅🎯 Upsert ทุก row เสร็จสมบูรณ์!\")\n",
    "\n",
    "# ✅ เรียกใช้\n",
    "upsert_df_chunk_force(df_cleaned, 'fact_insurance_motor', 'quotation_num')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
