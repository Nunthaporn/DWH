{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdde54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏à‡∏≤‡∏Å .env\n",
    "load_dotenv()\n",
    "\n",
    "# ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å environment\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')  \n",
    "database = 'fininsurance'\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á engine ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "engine = create_engine(f'mariadb+mariadbconnector://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# SQL query\n",
    "query = \"\"\"\n",
    "SELECT quo_num,company, company_prb,assured_insurance_capital1,is_addon,type,repair_type\n",
    "FROM fin_system_select_plan WHERE datestart >= '2025-06-01' AND datestart < '2025-07-01' and type_insure = '‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏£‡∏ñ'\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ pandas ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏î‡πâ‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô\n",
    "# df['user_registered'] = pd.to_datetime(df['user_registered'].astype(str), errors='coerce')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')  \n",
    "database = 'fininsurance_task'\n",
    "\n",
    "engine = create_engine(f'mariadb+mariadbconnector://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT quo_num,responsibility1,responsibility2,responsibility3,responsibility4,damage1,damage2,damage3,damage4,protect1,protect2,protect3,protect4,\n",
    "if(sendtype = '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏´‡∏°‡πà',provincenew,province) as delivery_province,\n",
    "show_ems_price,show_ems_type\n",
    "\n",
    "FROM fin_order WHERE datekey >= '2025-06-01' AND datekey < '2025-07-01'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df1 = pd.read_sql(query, engine)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "port = os.getenv('DB_PORT')  \n",
    "database = 'fininsurance'\n",
    "\n",
    "engine = create_engine(f'mariadb+mariadbconnector://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT quo_num,date_warranty,date_exp\n",
    "\n",
    "FROM fin_system_pay WHERE datestart >= '2025-06-01' AND datestart < '2025-07-01'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df2 = pd.read_sql(query, engine)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117489c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.copy()\n",
    "\n",
    "df_merged = pd.merge(df_merged, df1, on='quo_num', how='left')\n",
    "df_merged = pd.merge(df_merged, df2, on='quo_num', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(a, b):\n",
    "    a_str = str(a).strip() if pd.notna(a) else ''\n",
    "    b_str = str(b).strip() if pd.notna(b) else ''\n",
    "    \n",
    "    if a_str == '' and b_str == '':\n",
    "        return ''\n",
    "    elif a_str == '':\n",
    "        return b_str\n",
    "    elif b_str == '':\n",
    "        return a_str\n",
    "    elif a_str == b_str:\n",
    "        return a_str\n",
    "    else:\n",
    "        return f\"‡∏ä‡∏±‡πâ‡∏ô{a_str} {b_str}\"\n",
    "\n",
    "df_merged['insurance_class'] = df_merged.apply(lambda row: combine_columns(row['type'], row['repair_type']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971aafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_merged.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeefa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop(columns=['type','repair_type'])\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f639c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)\n",
    "##car_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e545c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_columns = {\n",
    "    \"quo_num\": \"quotation_num\",\n",
    "    \"responsibility1\": \"human_coverage_person\",\n",
    "    \"responsibility2\": \"human_coverage_atime\",\n",
    "    \"responsibility3\": \"property_coverage\",\n",
    "    \"responsibility4\": \"deductible\",\n",
    "    \"damage1\": \"vehicle_damage\",\n",
    "    \"damage2\": \"deductible_amount\",\n",
    "    \"damage3\": \"vehicle_theft_fire\",\n",
    "    \"damage4\": \"vehicle_flood_damage\",\n",
    "    \"protect1\": \"personal_accident_driver\",\n",
    "    \"protect2\": \"personal_accident_passengers\",\n",
    "    \"protect3\": \"medical_coverage\",\n",
    "    \"protect4\": \"driver_coverage\",\n",
    "    \"company\": \"ins_company\",\n",
    "    \"company_prb\": \"act_ins_company\",\n",
    "    \"assured_insurance_capital1\": \"sum_insured\",\n",
    "    \"date_warranty\": \"date_warranty\",\n",
    "    \"date_exp\": \"date_expired\",\n",
    "    \"insurance_class\": \"insurance_class\",\n",
    "    \"show_ems_price\": \"ems_amount\",\n",
    "    \"show_ems_type\": \"delivery_type\",\n",
    "    \"is_addon\": \"income_comp_ins\"\n",
    "}\n",
    "\n",
    "df = df_merged.rename(columns=rename_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['insurance_class'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(df_cleaned.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308dd74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cleaned.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(r'^\\s*$', pd.NA, regex=True)  \n",
    "df = df[df.count(axis=1) > 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏∏‡∏Å‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "df_temp = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡πà‡∏ß‡∏¢‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (non-null)\n",
    "df['non_empty_count'] = df_temp.notnull().sum(axis=1)\n",
    "\n",
    "# >>>> ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ <<<<\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö agent_id ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà NaN ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á)\n",
    "valid_agent_id_mask = df['quotation_num'].astype(str).str.strip().ne('') & df['quotation_num'].notna()\n",
    "\n",
    "# ‡πÅ‡∏¢‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà agent_id ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞ agent_id ‡∏ß‡πà‡∏≤‡∏á\n",
    "df_with_id = df[valid_agent_id_mask]\n",
    "df_without_id = df[~valid_agent_id_mask]\n",
    "\n",
    "# ‡∏Ñ‡∏±‡∏î‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà agent_id ‡∏ã‡πâ‡∏≥ ‡πÇ‡∏î‡∏¢‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "df_with_id_cleaned = df_with_id.sort_values('non_empty_count', ascending=False).drop_duplicates(subset='quotation_num', keep='first')\n",
    "\n",
    "# ‡∏£‡∏ß‡∏°‡∏Å‡∏•‡∏±‡∏ö\n",
    "df_cleaned = pd.concat([df_with_id_cleaned, df_without_id], ignore_index=True)\n",
    "\n",
    "# ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡πà‡∏ß‡∏¢\n",
    "df_cleaned = df_cleaned.drop(columns=['non_empty_count'])\n",
    "df_cleaned = df_cleaned.replace(\n",
    "    to_replace=r'^\\s*$|(?i:^none$)|^-$',  # << ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ\n",
    "    value=np.nan,\n",
    "    regex=True\n",
    ")\n",
    "\n",
    "\n",
    "df_cleaned.columns = df_cleaned.columns.str.lower()\n",
    "df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.replace(np.nan, \"NaN\").isin([\"none\", \"-\", \"None\"]).sum()\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned.to_csv('dim_car1.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aecaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.replace(r'^\\.$', np.nan, regex=True)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['income_comp_ins'] = df_cleaned['income_comp_ins'].apply(lambda x: True if x == 1 else False if x == 0 else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_clean = [\n",
    "    'sum_insured', 'human_coverage_person', 'human_coverage_atime',\n",
    "    'property_coverage', 'deductible', 'vehicle_damage', 'deductible_amount',\n",
    "    'vehicle_theft_fire', 'vehicle_flood_damage', 'personal_accident_driver',\n",
    "    'personal_accident_passengers', 'medical_coverage', 'driver_coverage',\n",
    "    'ems_amount'\n",
    "]\n",
    "for col in cols_to_clean:\n",
    "    df_cleaned[col] = (\n",
    "        df_cleaned[col]\n",
    "        .astype(str)\n",
    "        .str.replace(',', '', regex=False)\n",
    "        .str.strip()\n",
    "        .apply(lambda x: float(x) if x not in ['', 'None', 'nan', 'NaN'] else None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.where(pd.notnull(df_cleaned), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_cleaned['insurance_class'] = df_cleaned['insurance_class'].replace({\n",
    "    '‡∏ã‡πà‡∏≠‡∏°‡∏≠‡∏π‡πà': np.nan  # ‡πÉ‡∏ä‡πâ NaN ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô NULL ‡∏ï‡∏≠‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏•‡∏á PostgreSQL\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50238049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['date_warranty'] = pd.to_datetime(df_cleaned['date_warranty'], errors='coerce')\n",
    "df_cleaned['date_expired'] = pd.to_datetime(df_cleaned['date_expired'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "int_columns = [\n",
    "    \"sum_insured\", \"human_coverage_person\", \"human_coverage_atime\", \"property_coverage\",\n",
    "    \"deductible\", \"vehicle_damage\", \"deductible_amount\", \"vehicle_theft_fire\",\n",
    "    \"vehicle_flood_damage\", \"personal_accident_driver\", \"personal_accident_passengers\",\n",
    "    \"medical_coverage\", \"driver_coverage\", \"ems_amount\"\n",
    "]\n",
    "\n",
    "for col in int_columns:\n",
    "    if col in df_cleaned.columns:\n",
    "        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numeric coercing error ‡πÄ‡∏õ‡πá‡∏ô NaN\n",
    "        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "        # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏Å‡πá‡∏ö NULL ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí ‡πÉ‡∏ä‡πâ dtype \"Int64\" ‡∏Ç‡∏≠‡∏á Pandas\n",
    "        df_cleaned[col] = df_cleaned[col].astype(\"Int64\")\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á NaN ‡πÄ‡∏õ‡πá‡∏ô None ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° insert\n",
    "df_cleaned = df_cleaned.where(pd.notnull(df_cleaned), None)\n",
    "df_cleaned = df_cleaned.replace({np.nan: None})\n",
    "\n",
    "print(\"‚úÖ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ column int ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from sqlalchemy.dialects.postgresql import insert  # ‚úÖ ‡πÉ‡∏ä‡πâ insert ‡πÅ‡∏ö‡∏ö Postgres\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "host = os.getenv('DB_HOST_test')\n",
    "user = os.getenv('DB_USER_test')\n",
    "password = os.getenv('DB_PASSWORD_test')\n",
    "port = os.getenv('DB_PORT_test')\n",
    "database = 'fininsurance'\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# ‚úÖ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ NaN ‡πÄ‡∏õ‡πá‡∏ô None\n",
    "df_cleaned = df_cleaned.where(pd.notnull(df_cleaned), None)\n",
    "df_cleaned = df_cleaned.replace({np.nan: None})\n",
    "\n",
    "# ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î columns int ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\n",
    "int_columns = [\n",
    "    \"deductible\", \"human_coverage_person\", \"human_coverage_atime\", \"property_coverage\",\n",
    "    \"personal_accident_driver\", \"personal_accident_passengers\", \"medical_coverage\",\n",
    "    \"driver_coverage\", \"sum_insured\", \"ems_amount\", \"vehicle_damage\", \"deductible_amount\",\n",
    "    \"vehicle_theft_fire\", \"vehicle_flood_damage\"\n",
    "]\n",
    "for col in int_columns:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce').round()\n",
    "\n",
    "df_cleaned = df_cleaned.where(pd.notnull(df_cleaned), None)\n",
    "\n",
    "# ‚úÖ Upsert function\n",
    "def upsert_df_chunk_force(df: pd.DataFrame, table_name: str, key_column: str, chunk_size: int = 2000, schema: str = 'public'):\n",
    "    metadata = MetaData(schema=schema)\n",
    "    table = Table(table_name, metadata, autoload_with=engine)\n",
    "\n",
    "    df = df[df[key_column].notna()]\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    total_chunks = (total_rows // chunk_size) + (1 if total_rows % chunk_size else 0)\n",
    "\n",
    "    print(f\"üéØ Row ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_rows:,} (‡πÅ‡∏ö‡πà‡∏á {total_chunks} ‡∏ä‡∏∏‡∏î, chunk size: {chunk_size})\")\n",
    "\n",
    "    for i in range(0, total_rows, chunk_size):\n",
    "        df_chunk = df.iloc[i:i+chunk_size]\n",
    "        rows = df_chunk.to_dict(orient='records')\n",
    "        \n",
    "        stmt = insert(table).values(rows)\n",
    "        update_dict = {c.name: getattr(stmt.excluded, c.name) for c in table.columns if c.name != key_column}\n",
    "\n",
    "        stmt = stmt.on_conflict_do_update(\n",
    "            index_elements=[key_column],\n",
    "            set_=update_dict\n",
    "        )\n",
    "\n",
    "        with engine.begin() as conn:\n",
    "            result = conn.execute(stmt)\n",
    "            affected_rows = result.rowcount\n",
    "\n",
    "        print(f\"   üöÄ Chunk {i//chunk_size+1}/{total_chunks} ‚úîÔ∏è affected: {affected_rows:,}\")\n",
    "\n",
    "    print(\"‚úÖüéØ Upsert ‡∏ó‡∏∏‡∏Å row ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!\")\n",
    "\n",
    "# ‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ\n",
    "upsert_df_chunk_force(df_cleaned, 'fact_insurance_motor', 'quotation_num')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
